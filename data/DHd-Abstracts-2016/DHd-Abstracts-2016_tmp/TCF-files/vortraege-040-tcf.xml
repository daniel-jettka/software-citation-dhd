<?xml version='1.0' encoding='UTF-8'?><D-Spin xmlns="http://www.dspin.de/data" version="5">
  <MetaData xmlns="http://www.dspin.de/data/metadata"><Services><cmd:CMD xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:cmd="http://www.clarin.eu/cmd/1" CMDVersion="1.2" xsi:schemaLocation="http://www.clarin.eu/cmd/1 http://catalog.clarin.eu/ds/ComponentRegistry/rest/registry/profiles/clarin.eu:cr1:p_1320657629623/xsd"><cmd:Resources><cmd:ResourceProxyList/><cmd:JournalFileProxyList/><cmd:ResourceRelationList/></cmd:Resources><cmd:Components><cmd:WebServiceToolChain><cmd:GeneralInfo><cmd:Descriptions><cmd:Description/></cmd:Descriptions><cmd:ResourceName>Custom chain</cmd:ResourceName><cmd:ResourceClass>Toolchain</cmd:ResourceClass></cmd:GeneralInfo><cmd:Toolchain><cmd:ToolInChain><cmd:PID>https://hdl.handle.net/21.11120/0000-0008-319A-3</cmd:PID><cmd:Parameter value="de" name="lang"/></cmd:ToolInChain><cmd:ToolInChain><cmd:PID>https://hdl.handle.net/21.11120/0000-0008-3183-C</cmd:PID><cmd:Parameter value="5" name="version"/></cmd:ToolInChain><cmd:ToolInChain><cmd:PID>http://hdl.handle.net/11022/0000-0007-DA29-6</cmd:PID><cmd:Parameter value="de" name="lang"/><cmd:Parameter value="5" name="version"/></cmd:ToolInChain></cmd:Toolchain></cmd:WebServiceToolChain></cmd:Components></cmd:CMD></Services></MetaData>
  <TextCorpus xmlns="http://www.dspin.de/data/textcorpus" lang="de">
    <textSource type="application/tei+xml;format-variant=tei-dta;tokenized=0">&lt;?xml version="1.0" encoding="UTF-8"?>
&lt;TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="vortraege-040">
&lt;teiHeader>
&lt;fileDesc>
&lt;titleStmt>
&lt;title>Attribuierung direkter Reden in deutschen Romanen des 18.-20. Jahrhunderts. Methoden zur Bestimmung des Sprechers und des Angesprochenen&lt;/title>
&lt;author>
&lt;name>
&lt;surname>Krug&lt;/surname>
&lt;forename>Markus&lt;/forename>
&lt;/name>
&lt;affiliation>Universität Würzburg, Deutschland&lt;/affiliation>
&lt;email>markus.krug@uni-wuerzburg.de&lt;/email>
&lt;/author>
&lt;author>
&lt;name>
&lt;surname>Jannidis&lt;/surname>
&lt;forename>Fotis&lt;/forename>
&lt;/name>
&lt;affiliation>Universität Würzburg, Deutschland&lt;/affiliation>
&lt;email>fotis.jannidis@uni-wuerzburg.de&lt;/email>
&lt;/author>
&lt;author>
&lt;name>
&lt;surname>Reger&lt;/surname>
&lt;forename>Isabella&lt;/forename>
&lt;/name>
&lt;affiliation>Universität Würzburg, Deutschland&lt;/affiliation>
&lt;email>isabella.reger@uni-wuerzburg.de&lt;/email>
&lt;/author>
&lt;author>
&lt;name>
&lt;surname>Macharowsky&lt;/surname>
&lt;forename>Luisa&lt;/forename>
&lt;/name>
&lt;affiliation>Universität Würzburg, Deutschland&lt;/affiliation>
&lt;email>luisa.macharowsky@stud-mail.uni-wuerzburg.de&lt;/email>
&lt;/author>
&lt;author>
&lt;name>
&lt;surname>Weimer&lt;/surname>
&lt;forename>Lukas&lt;/forename>
&lt;/name>
&lt;affiliation>Universität Würzburg, Deutschland&lt;/affiliation>
&lt;email>lukas.weimer@stud-mail.uni-wuerzburg.de&lt;/email>
&lt;/author>
&lt;author>
&lt;name>
&lt;surname>Puppe&lt;/surname>
&lt;forename>Frank&lt;/forename>
&lt;/name>
&lt;affiliation>Universität Würzburg, Deutschland&lt;/affiliation>
&lt;email>frank.puppe@uni-wuerzburg.de&lt;/email>
&lt;/author>
&lt;/titleStmt>
&lt;editionStmt>
&lt;edition>
&lt;date>2015-10-10T15:06:00.76&lt;/date>
&lt;/edition>
&lt;/editionStmt>
&lt;publicationStmt>
&lt;publisher>Elisabeth Burr, Universität Leipzig&lt;/publisher>
&lt;address>
&lt;addrLine>Beethovenstr. 15&lt;/addrLine>
&lt;addrLine>04107 Leipzig&lt;/addrLine>
&lt;addrLine>Deutschland&lt;/addrLine>
&lt;addrLine>Elisabeth Burr&lt;/addrLine>
&lt;/address>
&lt;/publicationStmt>
&lt;sourceDesc>
&lt;p>Converted from an OASIS Open Document&lt;/p>
&lt;/sourceDesc>
&lt;/fileDesc>
&lt;encodingDesc>
&lt;appInfo>
&lt;application ident="DHCONVALIDATOR" version="1.14">
&lt;label>DHConvalidator&lt;/label>
&lt;/application>
&lt;/appInfo>
&lt;/encodingDesc>
&lt;profileDesc>
&lt;textClass>
&lt;keywords scheme="ConfTool" n="category">
&lt;term>Vortrag&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="subcategory">
&lt;term>&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="keywords">
&lt;term>Sprechererkennung&lt;/term>
&lt;term>NLP&lt;/term>
&lt;term>Quantitative Textanalyse&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="topics">
&lt;term>Programmierung&lt;/term>
&lt;term>Inhaltsanalyse&lt;/term>
&lt;term>Strukturanalyse&lt;/term>
&lt;term>Modellierung&lt;/term>
&lt;term>Annotieren&lt;/term>
&lt;term>Literatur&lt;/term>
&lt;term>Personen&lt;/term>
&lt;/keywords>
&lt;/textClass>
&lt;/profileDesc>
&lt;/teiHeader>
&lt;text>
&lt;body>
&lt;div type="div1">
&lt;head>&lt;anchor xml:id="id_docs-internal-guid-4378e1fa-6ca5-cc9e-2c63-ec95391fd4ab"

          />Problembeschreibung &lt;/head>
&lt;p>
&lt;anchor xml:id="id_docs-internal-guid-1f47a959-6ca3-8fa1-004e-73ced1fafd05"/>Im

            Folgenden wird ein Verfahren vorgestellt, das die automatische Zuordnung von

            direkter Rede in Erzähltexten sowohl zur sprechenden als auch zur angesprochenen

            Figur ermöglicht. Kann man eine solche automatische Zuordnung vornehmen,

            ermöglicht dies die Extraktion eines sozialen Netzwerks aus einem Text, wobei

            die Figuren als Knoten und die direkte Rede als Kanten modelliert werden (Elson

            / Dames 2010), aber sie kann auch eine wichtige Informationsquelle für andere

            analytische Schritte sein, z.B. zur Verbesserung der Koreferenzresolution oder

            zur Analyse der Quelle der Zuschreibung von Figurenattributen. &lt;/p>
&lt;/div>
&lt;div type="div1">
&lt;head>Stand der Forschung&lt;/head>
&lt;p>Eine der ersten Arbeiten auf diesem Gebiet ist das System ESPER (Zhang et al.

              2003), das direkte Reden innerhalb von Kindergeschichten erkennen soll. Das

              System extrahiert zunächst die direkten Reden im Text und klassifiziert diese

              mit einem Entscheidungsbaum in zwei Kategorien, Sprecherwechsel bzw. kein

              Sprecherwechsel. Evaluiert werden die Ergebnisse mit zwei manuell annotierten,

              sehr unterschiedlichen Geschichten. Sie berichten eine Genauigkeit, gemeint ist

              hier die Anzahl der korrekt bestimmten Sprecher für alle direkten Reden, von

              47.6% und 86.7%. Glass und Bangay (2006), ebenfalls regelbasiert, bestimmen

              zunächst für eine direkte Rede das Kommunikationsverb und anschließend eine

              Menge von Akteuren, woraus letztendlich der Sprecher bestimmt wird. Sie

              evaluieren ihre Techniken auf 13 englischsprachigen fiktionalen Werken und

              berichten eine Genauigkeit von 79.4% (Glass / Bangay 2007). Iosif und Mishra

              (2014)  folgen im Prinzip dem Schema von Glass und Bangay (2007), ergänzen es

              aber durch eine aufwendigere Vorverarbeitung einschließlich

              Koreferenzresolution. Sie erreichen eine Genauigkeit von ca 84.5% und zählen

              damit zu den besten bisher veröffentlichten Ergebnissen. Ruppenhofer und andere

              (Ruppenhofer et al. 2010) berichten einen F-Score von 79% in der Zuordnung von

              Politikern zu ihren Aussagen in deutschsprachigen Kabinettsprotokollen aus den

              Jahren 1949-1960.&lt;/p>
&lt;p> Neben diesen regelbasierten Ansätzen werden auch maschinelle Lernverfahren

                eingesetzt. Zu den ersten erfolgreichen Systemen zählt das von Elson und McKeown

                (2010). Ihre Daten für die Sprecherzuordnung ließen sie über Amazons  &lt;hi

                rend="italic">Mechanical Turk &lt;/hi>

                System bearbeiten. Ihr System klassifiziert zunächst

                regelbasiert eine direkte Rede in eine von fünf syntaktischen Kategorien.

                Für jede dieser Kategorien wurden anschließend eigenständige maschinelle

                Lernverfahren trainiert. Insgesamt erreichen sie eine Genauigkeit von etwa

                83%, ausgewertet anhand von englischen Romanen des 19 Jahrhunderts. O’Keefe

                und andere (O’Keefe et al. 2012), die an Elson und McKeowns Ansatz die

                Erstellung des Goldstandards und auch die praxisferne Verwendung von

                Informationen aus dem Goldstandard kritisieren,  betrachten die Zuordnung

                als Sequenzproblem. Sie nutzen die Klassifikationsangaben von vorhergehenden

                direkten Reden als Features für die gesamte Sequenz. In ihrer Evaluation

                vergleichen Sie drei Verfahren mit einer sehr einfachen regelbasierten

                Baseline. Ihre Ergebnisse bei der Anwendung des Systems auf zwei

                Zeitungskorpora - Wall Street Journal und Sydney Morning Herald - sowie die

                Sammlung literarischer Texte aus der Arbeit von Elson und McKeown zeigen

                einen großen Unterschied zwischen den Domänen. Sie erreichen auf den beiden

                Zeitungskorpora 84.1% (WSJ) bzw. 91.7% (SMH) Genauigkeit. Auf dem

                literarischen Korpus erreichen sie dagegen lediglich eine maximale

                Genauigkeit von 49%. (He et al. 2013) erreichen mit einem auf Ranking

                basierten maschinellem Lernverfahren unter der Ausnutzung von Features des

                Actor-Topic Modells (Celikyilmaz et al. 2010) auf dem Elson und

                McKeown-Korpus eine Genauigkeit zwischen 74.8% und 80.3%. Almeida und andere

                gehen von einer engen Verflechtung von Koreferenzresolution und

                Sprecherattribution aus und integrieren dabei beide Verfahren in ihrem

                Ansatz; die Ergebnisse der beiden einzelnen Lernverfahren werden in einem

                dritten Schritt verbunden. Sie erreichen damit 88.1% Genauigkeit (Almeida et

                al. 2014). Neuere Versuche mit Deep Learning-Verfahren aufgrund der Sprache

                der Figuren haben nur Genauigkeiten  von unter 50% erreicht (Chaganty /

                Muzny 2014).
&lt;/p>
&lt;p>Die Zuordnung einer angesprochenen Figur wurde unserer Wissens noch in keiner anderen Arbeit untersucht.&lt;/p>
&lt;/div>
&lt;div type="div1">
&lt;head>Daten und Annotation&lt;/head>
&lt;p> Für diese Arbeit verwenden wir Abschnitte des frei zugänglichen Korpus DROC.

                DROC besteht aus 89 Romanausschnitten, jeweils 130 Sätze lang, in denen alle

                Figurenreferenzen (mit und ohne Namen) und Koreferenzen annotiert sind. Aus dem

                Korpus wurden 77 Ausschnitte ausgewählt und mit einem eigens entwickelten Tool

                alle direkten Reden sowie die zugehörigen Sprecher und angesprochenen Figuren

                eingetragen. Jeder Text wurde von einem Annotator bearbeitet; eine zweite

                Annotation ist vorgesehen. Insgesamt wurden so 2264 direkte Reden mit Sprecher

                und Angesprochenen annotiert. Für die in Abschnitt 5 diskutierten Experimente

                wurde das Korpus in drei zufällige Mengen aufgeteilt:  &lt;/p>
&lt;figure>
&lt;graphic url="v40-table1.png" rend="inline">&lt;/graphic>
&lt;p rend="figure">&lt;hi rend="bold">Tab. 1&lt;/hi>: Überblick über die Auftrennung des in dieser Arbeit

                  verwendeten Korpus.&lt;/p>
&lt;/figure>
&lt;/div>
&lt;div type="div1">
&lt;head>Methoden&lt;/head>
&lt;p>Wir verwenden regelbasierte Verfahren und maschinelle Lernverfahren, aber anders

                  als in (He et al. 2013) oder (O’Keefe et al. 2012) dienen erstere nicht nur als

                  Baseline-Verfahren, sondern wurden soweit wie möglich optimiert. &lt;/p>
&lt;p>Wir verwenden die Techniken 2-Way Klassifikation und N-Way Klassifikation wie in

                    (O’Keefe et al. 2012) vorgeschlagen. Zusätzlich evaluieren wir

                    MaxEnt2WayToMatch, bei dem Kandidaten nur bis zum ersten tatsächlichen

                    Sprecherkandidaten erzeugt werden.&lt;/p>
&lt;p>Für die Sprecherzuordnung und Zuordnung eines Angesprochenen sind die in dieser Arbeit verwendeten Features in Tabelle A1 im Anhang zusammengefasst. &lt;/p>
&lt;p> Für diese Aufgabe haben sich regelbasierte Verfahren als konkurrenzfähig mit den

                      aktuellen ML-Verfahren erwiesen. Sie besitzen außerden den Vorteil, dass sie

                      nicht so viele Trainingsbeispiele benötigen. Die Grundstruktur des Algorithmus

                      ist der Idee des regelbasierten Koreferenzsystems von Stanford (Lee et al. 2011)

                      angelehnt. Es werden eine Reihe von Regelpässen nacheinander ausgeführt. Die

                      Regelpässe sind gemäß ihrer &lt;hi rend="italic">Precision&lt;/hi> geordnet, d. h.

                      Regeln mit einer hohen &lt;hi rend="italic">Precision&lt;/hi> werden zuerst

                      ausgeführt. Eine spätere Regel kann eine Entscheidung einer früheren Regel nicht

                      revidieren. Tabelle A2 im Anhang zeigt die in dieser Arbeit verwendeten

                      Regelpässe.  &lt;/p>
&lt;p>Mit Hilfe der Trainingsdaten konnte eine optimale Reihenfolge der Ausführung der Regeln empirisch ermittelt werden, bei der einige Regeln auch mehrfach angewendet werden. &lt;/p>
&lt;p>(1)→(2)→(3)→(4)→(5)→(6)→(7)→(5)→(6)→(8) →(9)→(5)→(6)→(7)→(10).&lt;/p>
&lt;/div>
&lt;div type="div1">
&lt;head>Evaluation&lt;/head>
&lt;p>Die Parameter für die ML-Verfahren wurden auf dem Development-Anteil der Daten optimiert und anschließend gegen die Testmenge evaluiert. Für die regelbasierten Verfahren gibt es keine Unterscheidung zwischen Trainings- und Development-Korpus. Ein Sprecher gilt als korrekt bestimmt, wenn sich der vom System bestimmte Kandidat in der selben Koreferenzkette befindet, wie die Entität, die von unserem Annotator als korrekt markiert wurde. Tabelle 2 beschreibt die Ergebnisse bei der Anwendung der Verfahren auf das Testkorpus.&lt;/p>
&lt;figure>
&lt;graphic url="v40-table2.png" rend="inline">&lt;/graphic>
&lt;p rend="figure">&lt;hi rend="bold">Tab. 2&lt;/hi>: Ergebnisse der einzelnen Verfahren auf dem

                        Testkorpus, bestehend aus 20 zufällig gewählten Romanfragmenten. &lt;/p>
&lt;/figure>
&lt;p>Unsere Experimente bestätigen die Aussagen von O’Keefe (O’Keefe et al. 2012),

                        dass 2Way ML-Verfahren bessere Ergebnisse in der Sprechererkennung liefern, als

                        korrespondierende NWay Verfahren. Analoges gilt für die Evaluation der CRFs, die

                        sogar beinahe den selben Wert für die Sprechererkennung liefern wie in (O’Keefe

                        et al. 2012). Sowohl auf dem Developmentkorpus, als auch auf dem Testkorpus

                        zeigen regelbasierte Ansätze deutliche Vorteile gegenüber den in dieser Arbeit

                        verwendeten ML-Verfahren. Es ist weiterhin ersichtlich, dass die Bestimmung des

                        Sprechers einfacher ist, als die Bestimmung des Angesprochenen. Wahrscheinlich

                        liegt das daran, dass im Fall der Sprecherzuschreibung mehr Information

                        vorliegt, nämlich die direkte Rede und der Kontext, während bei der Ermittlung

                        des Angesprochenen die direkte Rede selbst nur hilfreich ist, wenn ein

                        Angesprochener direkt darin vermerkt ist.&lt;/p>
&lt;p>Ein direkter Vergleich mit dem besten in der Literatur zu findenden Verfahren

                          (Almeida et al. 2014) kann direkt nicht durchgeführt werden. Berücksichtigt man

                          den Unterschied, der Verfahren von O’Keefe auf den Texten des WSJ und den

                          literarischen Texten, könnte eine Qualität von 90% Genauigkeit erreicht werden

                          und damit ein mit der state of the art vergleichbares, sogar möglicherweise

                          besseres Ergebnis. Im Gegensatz zu ihrem Verfahren ermitteln wir zudem auch noch

                          eine angesprochene Entität. &lt;/p>
&lt;/div>
&lt;div type="div1">
&lt;head>Diskussion und Ausblick&lt;/head>
&lt;p> Die Ergebnisse zeigen, dass das regelbasierte Verfahren für diese Aufgabe

                            deutlich bessere Ergebnisse erzielen kann als alle ML-Verfahren, die in dieser

                            Arbeit getestet wurden. Es ist geplant, die hier erstellte Zuordnung in die

                            regelbasierte Koreferenzauflösung von (Krug et al. 2015) einzuarbeiten, um diese

                            damit zu verbessern. Weil unsere Hauptmotivation die Verbesserung der

                            Koreferenzresolution ist, diese aber im Ansatz von Almeida nicht wirksam

                            verbessert werden konnte, haben wir darauf verzichtet, deren komplexes

                            Lernverfahren nachzuvollziehen. Gerade die Ergebnisse, die in Tabelle 2 zu sehen

                            sind, zeigen, dass mögliche Dialogsequenzen genauer untersucht werden müssen, um

                            diese zuverlässig erkennen und auflösen zu können. Eine genaue Dialoganalyse

                            vereinfacht wiederum die Korefenzauflösung, so dass eine Extraktion von

                            Beziehungen zwischen Personen und Attributen zu Entitäten innerhalb der Romane

                            möglicher erscheint. &lt;/p>
&lt;/div>
&lt;div type="div1">
&lt;head>
&lt;anchor xml:id="id_docs-internal-guid-1f47a959-6ca4-c170-f3ac-c04e907df805"/>Anhang
&lt;/head>
&lt;table rend="frame" xml:id="Tabelle3">
&lt;row>
&lt;cell>Featurebeschrei-bung (zwischen Kandidat und direkten Rede)&lt;/cell>
&lt;cell>

                                  Verwendung für Sprecherzuord-nung
&lt;/cell>
&lt;cell>

                                  Zuordnung des Angesprochenen
&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>1. Ist der Kandidat Subjekt&lt;/cell>
&lt;cell>+&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>2. Das Verb in der Dependenzstruk-tur, auf das sich der Kandidat  bezieht&lt;/cell>
&lt;cell>+&lt;/cell>
&lt;cell>+&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>3. Das POS-Tag des Kandidaten&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>4. Ist der Kandidat ein Pronomen&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>5-6. Befindet sich der Kandidat im Akkusativ/Dativ&lt;/cell>
&lt;cell>+/+&lt;/cell>
&lt;cell>+/+&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>7. Kandidat befindet sich in einer direkten Rede&lt;/cell>
&lt;cell>+&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>8. Kandidat erscheint in der aktuellen direkten Rede&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>9. Kandidat befindet sich im selben Satz wie die direkte Rede&lt;/cell>
&lt;cell>+&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>10. Die Direkte Rede beginnt mit einem kleingeschriebe-nem Wort&lt;/cell>
&lt;cell>+&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>11. Zwischen Kandidat und direkter Rede befindet sich ein Doppelpunkt&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;cell>-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>12-14. Distanz zw. Kandidat und direkter Rede in Sätze/Wörter/Entitäten&lt;/cell>
&lt;cell>-/-/+&lt;/cell>
&lt;cell>-/-/-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>15-16. Wort an Position +1/-1&lt;/cell>
&lt;cell>-/-&lt;/cell>
&lt;cell>-/-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>17-18. Wort an Position +1/-1 ist Satzzeichen&lt;/cell>
&lt;cell>+/+&lt;/cell>
&lt;cell>-/-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>19-20. Wort an Position +1/-1 ist in direkter Rede&lt;/cell>
&lt;cell>+/+&lt;/cell>
&lt;cell>-/-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>19-20. Kandidat ist Sprecher der direkten Rede an Position -1/-2&lt;/cell>
&lt;cell>-/-&lt;/cell>
&lt;cell>+/-&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>21-22. Kandidat ist Angesprochener der direkten Rede an Position -1/-2&lt;/cell>
&lt;cell>-/-&lt;/cell>
&lt;cell>-/-&lt;/cell>
&lt;/row>
&lt;/table>
&lt;p>
&lt;hi rend="bold">Tab. A1&lt;/hi>: Ein Überblick über die

                              in dieser Arbeit verwendeten Features. Durch + und - ist angegeben, ob

                              dieses Feature gewinnbringend eingesetzt werden konnte. Zur Wahl der

                              Features vgl. auch  (Elson / McKeown 2010) und (He et al. 2013). &lt;lb/>
&lt;/p>
&lt;table rend="frame" xml:id="Tabelle4">
&lt;row>
&lt;cell>Regelbezeichnung&lt;/cell>
&lt;cell>Regelbeschreibung&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(1) Explizite Sprechererkennung&lt;/cell>
&lt;cell>Nutzt Pattern-Matching und grammatikalische Regeln um explizite Erwähnungen eines Sprechers im direkten Umfeld einer direkten Rede zu erkennen.&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(2) Explizite Erkennung des  Angesprochenen&lt;/cell>
&lt;cell>Nutzt Pattern-Matching und grammatikalische Regeln um explizite Erwähnungen eines Angesprochenen innerhalb der direkten Rede zu erkennen.&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(3) Explizite Erkennung des Angesprochenen II&lt;/cell>
&lt;cell>Wie (1) nur für den Angesprochenen&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(4) Explizite Sprechererkennung II&lt;/cell>
&lt;cell>Wie (1), nur der Kontext wird um 1 Satz außerhalb der direkten Rede erweitert.&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(5) Vorwärtspropagierung&lt;/cell>
&lt;cell>Zwei direkt aufeinanderfolgenden direkten Reden wird der Sprecher/Angesprochener der ersten direkten Rede zugeordnet, wenn beide direkte Reden innerhalb des selben Satzes liegen&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(6) Rückwärtspropagierung&lt;/cell>
&lt;cell>wie (5) nur mit entgegengesetzter Richtung der Ausführung&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(7) Nachbarschafts-propagierung&lt;/cell>
&lt;cell>Direkten Reden, die keinen eingeschobenen Kontext aufzeigen, wechseln den Sprecher/Angesprochenen ( falls vorhanden)&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(8) Fragenpropagierung&lt;/cell>
&lt;cell>Nach einer Frage wechseln Sprecher/Angesprochener&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(9) Dialogpropagierung&lt;/cell>
&lt;cell>Direkte Rede mit maximal einem zwischenliegenden Satz wechseln ihren Sprecher/Angesprochenen&lt;/cell>
&lt;/row>
&lt;row>
&lt;cell>(10) Default-Sprecher/ Angesprochener&lt;/cell>
&lt;cell>Als Sprecher wird das letzte Subjekt außerhalb direkter Reden gesetzt, als Angesprochener das letzte Subjekt, das nicht Sprecher der aktuellen direkten Rede ist.&lt;/cell>
&lt;/row>
&lt;/table>
&lt;p>&lt;hi rend="italic">&lt;hi rend="bold">Tab. A2&lt;/hi>: Überblick über die Regelpäse für das in dieser

                            Arbeit vorgestellte regelbasierte Verfahren zur Sprecherzuordnung bzw. Zuordnung

                            eines Angesprochenen. Optimale Reihenfolge der Ausführung der Regeln aufgrund

                            der Auswertung des Trainingssatzes:&lt;/hi>&lt;/p>
&lt;p>(1)→(2)→(3)→(4)→(5)→(6)→(7)→(5)→(6)→(8) →(9)→(5)→(6)→(7)→(10).&lt;/p>
&lt;figure>
&lt;graphic url="040-1000000000000331000001BBE3C72D0D.png"/>
&lt;p>
&lt;hi rend="bold">Abb. A3&lt;/hi>: Auszug aus Aston Louise “Lydia”: Beispiel für die

                                Erkennung von Sprecher und Angesprochenem in direkten Reden gemäß den Regeln in

                                Tabelle A2. Im ersten Durchlauf wird mit der Regel (1) die Sprecherin für die

                                direkten Reden &lt;hi rend="bold">1&lt;/hi> und &lt;hi rend="bold">5&lt;/hi> erkannt.

                                Anschließend erkennt Regel (7) in Rückwärtsrichtung jeweils abwechselnd

                                Sprecherin &lt;hi rend="bold">4&lt;/hi> und &lt;hi rend="bold">2&lt;/hi> und Angesprochene

                                in &lt;hi rend="bold">3&lt;/hi>. Schließlich erkennt Regel (7) in Vorwärtsrichtung die

                                Sprecherin in &lt;hi rend="bold">3&lt;/hi> und die Angesprochene in &lt;hi rend="bold"
>4&lt;/hi> und &lt;hi rend="bold">2&lt;/hi>. &lt;/p>
&lt;/figure>
&lt;/div>
&lt;/body>
&lt;back>
&lt;div type="bibliogr">
&lt;listBibl>
&lt;head>Bibliographie&lt;/head>
&lt;bibl>
&lt;anchor xml:id="id_docs-internal-guid-1f47a959-6ca4-35e7-7fb1-f0e048431e41"/>
&lt;hi rend="bold">Almeida, Mariana S.C. / Almeida, Miguel B. / Martins, André

                                    F.T.&lt;/hi> (2014): "A joint model for quotation attribution and

                                    coreference resolution", in: &lt;hi rend="italic">Proceedings of the 14th

                                    Conference of the European Chapter of the Association for Computational

                                    Linguistics, Gothenburg, Sweden&lt;/hi> 39-48. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Bohnet, Bernd / Kuhn, Jonas&lt;/hi> (2012): "The best of both

                                      worlds: a graph-based completion model for transition-based parsers." In:
&lt;hi rend="italic">Proceedings of the 13th Conference of the European

                                        Chapter of the Association for Computational Linguistics&lt;/hi>. Avignon,

                                        France: 77-87. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Chaganty, Arun / Muzny, Grace&lt;/hi> (2015): &lt;hi rend="italic"
>Quote Attribution for Literary Text with Neural Networks&lt;/hi>
&lt;ref target="https://cs224d.stanford.edu/reports/ChagantyArun.pdf"
>https://cs224d.stanford.edu/reports/ChagantyArun.pdf&lt;/ref> [letzter

                                            Zugriff 08. Februar 2016].&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Celikyilmaz, Asli / Hakkani-Tur, Dilek / He, Hua / Kondrak,

                                                Greg / Barbosa, Denilson&lt;/hi> (2010): "The actortopic model for

                                                extracting social networks in literary narrative.", in: &lt;hi rend="italic"
>Proceedings of the NIPS 2010 Workshop Machine Learning for Social

                                                Computing&lt;/hi>
&lt;ref

                                                  target="https://webdocs.cs.ualberta.ca/~denilson/files/publications/nips2010.pdf"
>https://webdocs.cs.ualberta.ca/~denilson/files/publications/nips2010.pdf&lt;/ref>

                                                  [letzter Zugriff 08. Februar 2016].&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Elson, David K. / Dames, Nicholas / McKeown, Kathleen

                                                      R.&lt;/hi> (2010a): "Extracting social networks from literary fiction", in:
&lt;hi rend="italic">Proceedings of the 48th annual meeting of the

                                                        association for computational linguistics&lt;/hi>. Association for

                                                        Computational Linguistics &lt;ref

                                                        target="http://www1.cs.columbia.edu/~delson/pubs/ACL2010-ElsonDamesMcKeown.pdf"
>http://www1.cs.columbia.edu/~delson/pubs/ACL2010-ElsonDamesMcKeown.pdf&lt;/ref>

                                                        [letzter Zugriff 08. Februar 2016]. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Elson, David K. / McKeown, Kathleen R.&lt;/hi> (2010b):

                                                          "Automatic Attribution of Quoted Speech in Literary Narrative", in: &lt;hi

                                                          rend="italic">Proceedings of AAAI&lt;/hi> 1013-1019.&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Glass, Kevin / Bangay, Shaun&lt;/hi> (2006): "Hierarchical rule

                                                            generalisation for speaker identification in fiction books", in: &lt;hi

                                                            rend="italic">Proceedings of the 2006 annual research conference of the

                                                            South African institute of computer scientists and information

                                                            technologists on IT research in developing countries&lt;/hi>. South African

                                                            Institute for Computer Scientists and Information Technologists:

                                                            31-40.&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Glass, Kevin / Bangay, Shaun&lt;/hi> (2007): "A naive

                                                              salience-based method for speaker identification in fiction books", in: &lt;hi

                                                              rend="italic">Proceedings of the 18th Annual Symposium of the Pattern

                                                              Recognition Association of South Africa (PRASA’07)&lt;/hi>
&lt;ref

                                                                target="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.494.3729&amp;amp;rep=rep1&amp;amp;type=pdf"
>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.494.3729&amp;amp;rep=rep1&amp;amp;type=pdf&lt;/ref>

                                                                [letzter Zugriff 16. Februar 2016].&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">He, Hua / Barbosa, Denilson / Kondrak, Grzegorz&lt;/hi> (2013):

                                                                  "Identification of Speakers in Novels", in: &lt;hi rend="italic">Proceedings of

                                                                  the 51st Annual Meeting of the Association for Computational
                                                      Linguistics&lt;/hi>. Sofia, Bulgaria: 1312-1320.&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Iosif, Elias / Mishra, Taniya&lt;/hi> (2014): "From Speaker

                                                                    Identification to Affective Analysis: A Multi-Step System for Analyzing

                                                                    Children’s Stories", in: &lt;hi rend="italic">EACL&lt;/hi> 2014: 40-49. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Jannidis, Fotis / Krug, Markus / Reger, Isabella / Toepfer,

                                                                        Martin / Weimer, Lukas / Puppe, Frank&lt;/hi> (2015): “Automatische

                                                                        Erkennung von Figuren in deutschsprachigen Romanen”, in: &lt;hi rend="italic"
>Digital Humanities im deutschsprachigen Raum (Dhd 2015), Graz,

                                                                        Austria&lt;/hi>. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Joachims, Thorsten&lt;/hi> (2002): &lt;hi rend="italic">Learning

                                                                          to classify text using support vector machines&lt;/hi>. Methods, theory and

                                                                          algorithms (= The Springer International Series in Engineering and Computer

                                                                          Science 668). New York: Springer.&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Krug, Markus / Puppe, Frank / Jannidis, Fotis / Macharowsky,

                                                                              Luisa / Reger, Isabella / Weimer, Lukas&lt;/hi> (2015): "Rule-based

                                                                              Coreference Resolution in German Historic Novels", in: &lt;hi rend="italic"
>Proceedings of the Fourth Workshop on Computational Linguistics for

                                                                              Literature&lt;/hi> 98-104. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Lee, Heeyoung / Peirsman, Yves / Chang, Angel / Chambers,

                                                                                  Nathanael / Surdeanu, Mihai / Jurafsky, Dan&lt;/hi> (2011): "Stanford's

                                                                                  multi-pass sieve coreference resolution system at the CoNLL-2011 shared

                                                                                  task", in: &lt;hi rend="italic">Proceedings of the Fifteenth Conference on

                                                                                  Computational Natural Language Learning: Shared Task&lt;/hi>. Association

                                                                                  for Computational Linguistics &lt;ref

                                                                                  target="http://nlp.stanford.edu/pubs/conllst2011-coref.pdf"
>http://nlp.stanford.edu/pubs/conllst2011-coref.pdf&lt;/ref> [letzter

                                                                                  Zugriff 08. Februar 2016]. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">McCallum, Andrew Kachites&lt;/hi> (2002): &lt;hi rend="italic"
>MALLET: A Machine Learning for Language Toolkit&lt;/hi> &lt;ref

                                                                                    target="http://mallet.cs.umass.edu">http://mallet.cs.umass.edu&lt;/ref>

                                                                                    [letzter Zugriff 08. Februar 2016].&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Mikolov, Tomas / Sutskever, Ilya / Chen, Kai / Corrado, Greg

                                                                                        / Dean Jeffrey&lt;/hi> (2013): "Distributed representations of words and

                                                                                        phrases and their compositionality", in: &lt;hi rend="italic">Advances in

                                                                                        neural information processing systems&lt;/hi> 26 &lt;ref

                                                                                        target="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
>http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf&lt;/ref>

                                                                                        [letzter Zugriff 08. Februar 2016].&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">O'Keefe, Tim / Pareti, Silvia / Curran, James R. /

                                                                                            Koprinska, Irena / Honnibal, Matthew&lt;/hi> (2012): "A sequence labelling

                                                                                            approach to quote attribution", in: &lt;hi rend="italic">Proceedings of the

                                                                                            2012 Joint Conference on Empirical Methods in Natural Language

                                                                                            Processing and Computational Natural Language Learning&lt;/hi>. Association

                                                                                            for Computational Linguistics, 2012: 790–799. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Rahman, Altaf / Ng, Vincent &lt;/hi> (2011): "Narrowing the

                                                                                              modeling gap: a cluster-ranking approach to coreference resolution", in: &lt;hi

                                                                                              rend="italic">Journal of Artificial Intelligence Research&lt;/hi> 40:

                                                                                              469-521.&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Ruppenhofer, Josef / Sporleder, Caroline / Shirokov,

                                                                                                  Fabian&lt;/hi> (2010): "Speaker Attribution in Cabinet Protocols", in: &lt;hi

                                                                                                  rend="italic">The seventh international conference on Language Resources

                                                                                                  and Evaluation (LREC)&lt;/hi> 2510-2515. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Schmid, Helmut&lt;/hi> (1999): "Improvements in part-of-speech

                                                                                                    tagging with an application to German", in: Armstrong, Susan / Church,

                                                                                                    Kenneth / Isabelle, Pierre / Manzi, Sandra / Tzoukermann, Evelyne /

                                                                                                    Yarowsky, David (eds.): &lt;hi rend="italic">Natural language processing using

                                                                                                    very large corpora&lt;/hi> (= Text, Speech and Language Technology 11). New

                                                                                                    York: Springer 13-25.&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Schmid, Helmut / Laws, Florian&lt;/hi> (2008): "Estimation of

                                                                                                      conditional probabilities with decision trees and an application to

                                                                                                      fine-grained POS tagging", in: &lt;hi rend="italic">Proceedings of the 22nd

                                                                                                      International Conference on Computational Linguistics (Coling 2008)&lt;/hi>

                                                                                                      777–784.&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Sutton, Charles / McCallum, Andrew&lt;/hi> (2006): "An

                                                                                                        introduction to conditional random fields for relational learning", in:

                                                                                                        Getoor, Lise / Taskar, Ben (eds.):&lt;hi rend="italic">Introduction to

                                                                                                        statistical relational learning&lt;/hi>. Cambridge, MA / London: The MIT

                                                                                                        Press 93-128. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Zhang, Jason Y. / Black Alan W. / Sproat, Richard&lt;/hi>

                                                                                                          (2003): "Identifying speakers in children's stories for speech synthesis",

                                                                                                          in: &lt;hi rend="italic">EUROSPEECH&lt;/hi> 2041-2044. &lt;/bibl>
&lt;/listBibl>
&lt;/div>
&lt;/back>
&lt;/text>
&lt;/TEI>
    </textSource>
    <text>


  Im             Folgenden wird ein Verfahren vorgestellt, das die automatische Zuordnung von             direkter Rede in Erzähltexten sowohl zur sprechenden als auch zur angesprochenen             Figur ermöglicht. Kann man eine solche automatische Zuordnung vornehmen,             ermöglicht dies die Extraktion eines sozialen Netzwerks aus einem Text, wobei             die Figuren als Knoten und die direkte Rede als Kanten modelliert werden (Elson             / Dames 2010), aber sie kann auch eine wichtige Informationsquelle für andere             analytische Schritte sein, z.B. zur Verbesserung der Koreferenzresolution oder             zur Analyse der Quelle der Zuschreibung von Figurenattributen. 

  


Eine der ersten Arbeiten auf diesem Gebiet ist das System ESPER (Zhang et al.               2003), das direkte Reden innerhalb von Kindergeschichten erkennen soll. Das               System extrahiert zunächst die direkten Reden im Text und klassifiziert diese               mit einem Entscheidungsbaum in zwei Kategorien, Sprecherwechsel bzw. kein               Sprecherwechsel. Evaluiert werden die Ergebnisse mit zwei manuell annotierten,               sehr unterschiedlichen Geschichten. Sie berichten eine Genauigkeit, gemeint ist               hier die Anzahl der korrekt bestimmten Sprecher für alle direkten Reden, von               47.6% und 86.7%. Glass und Bangay (2006), ebenfalls regelbasiert, bestimmen               zunächst für eine direkte Rede das Kommunikationsverb und anschließend eine               Menge von Akteuren, woraus letztendlich der Sprecher bestimmt wird. Sie               evaluieren ihre Techniken auf 13 englischsprachigen fiktionalen Werken und               berichten eine Genauigkeit von 79.4% (Glass / Bangay 2007). Iosif und Mishra               (2014)  folgen im Prinzip dem Schema von Glass und Bangay (2007), ergänzen es               aber durch eine aufwendigere Vorverarbeitung einschließlich               Koreferenzresolution. Sie erreichen eine Genauigkeit von ca 84.5% und zählen               damit zu den besten bisher veröffentlichten Ergebnissen. Ruppenhofer und andere               (Ruppenhofer et al. 2010) berichten einen F-Score von 79% in der Zuordnung von               Politikern zu ihren Aussagen in deutschsprachigen Kabinettsprotokollen aus den               Jahren 1949-1960.

  

 Neben diesen regelbasierten Ansätzen werden auch maschinelle Lernverfahren                 eingesetzt. Zu den ersten erfolgreichen Systemen zählt das von Elson und McKeown                 (2010). Ihre Daten für die Sprecherzuordnung ließen sie über Amazons  Mechanical Turk                  System bearbeiten. Ihr System klassifiziert zunächst                 regelbasiert eine direkte Rede in eine von fünf syntaktischen Kategorien.                 Für jede dieser Kategorien wurden anschließend eigenständige maschinelle                 Lernverfahren trainiert. Insgesamt erreichen sie eine Genauigkeit von etwa                 83%, ausgewertet anhand von englischen Romanen des 19 Jahrhunderts. O’Keefe                 und andere (O’Keefe et al. 2012), die an Elson und McKeowns Ansatz die                 Erstellung des Goldstandards und auch die praxisferne Verwendung von                 Informationen aus dem Goldstandard kritisieren,  betrachten die Zuordnung                 als Sequenzproblem. Sie nutzen die Klassifikationsangaben von vorhergehenden                 direkten Reden als Features für die gesamte Sequenz. In ihrer Evaluation                 vergleichen Sie drei Verfahren mit einer sehr einfachen regelbasierten                 Baseline. Ihre Ergebnisse bei der Anwendung des Systems auf zwei                 Zeitungskorpora - Wall Street Journal und Sydney Morning Herald - sowie die                 Sammlung literarischer Texte aus der Arbeit von Elson und McKeown zeigen                 einen großen Unterschied zwischen den Domänen. Sie erreichen auf den beiden                 Zeitungskorpora 84.1% (WSJ) bzw. 91.7% (SMH) Genauigkeit. Auf dem                 literarischen Korpus erreichen sie dagegen lediglich eine maximale                 Genauigkeit von 49%. (He et al. 2013) erreichen mit einem auf Ranking                 basierten maschinellem Lernverfahren unter der Ausnutzung von Features des                 Actor-Topic Modells (Celikyilmaz et al. 2010) auf dem Elson und                 McKeown-Korpus eine Genauigkeit zwischen 74.8% und 80.3%. Almeida und andere                 gehen von einer engen Verflechtung von Koreferenzresolution und                 Sprecherattribution aus und integrieren dabei beide Verfahren in ihrem                 Ansatz; die Ergebnisse der beiden einzelnen Lernverfahren werden in einem                 dritten Schritt verbunden. Sie erreichen damit 88.1% Genauigkeit (Almeida et                 al. 2014). Neuere Versuche mit Deep Learning-Verfahren aufgrund der Sprache                 der Figuren haben nur Genauigkeiten  von unter 50% erreicht (Chaganty /                 Muzny 2014).  

  

Die Zuordnung einer angesprochenen Figur wurde unserer Wissens noch in keiner anderen Arbeit untersucht.


    

 Für diese Arbeit verwenden wir Abschnitte des frei zugänglichen Korpus DROC.                 DROC besteht aus 89 Romanausschnitten, jeweils 130 Sätze lang, in denen alle                 Figurenreferenzen (mit und ohne Namen) und Koreferenzen annotiert sind. Aus dem                 Korpus wurden 77 Ausschnitte ausgewählt und mit einem eigens entwickelten Tool                 alle direkten Reden sowie die zugehörigen Sprecher und angesprochenen Figuren                 eingetragen. Jeder Text wurde von einem Annotator bearbeitet; eine zweite                 Annotation ist vorgesehen. Insgesamt wurden so 2264 direkte Reden mit Sprecher                 und Angesprochenen annotiert. Für die in Abschnitt 5 diskutierten Experimente                 wurde das Korpus in drei zufällige Mengen aufgeteilt:  


    

Wir verwenden regelbasierte Verfahren und maschinelle Lernverfahren, aber anders                   als in (He et al. 2013) oder (O’Keefe et al. 2012) dienen erstere nicht nur als                   Baseline-Verfahren, sondern wurden soweit wie möglich optimiert. 

  

Wir verwenden die Techniken 2-Way Klassifikation und N-Way Klassifikation wie in                     (O’Keefe et al. 2012) vorgeschlagen. Zusätzlich evaluieren wir                     MaxEnt2WayToMatch, bei dem Kandidaten nur bis zum ersten tatsächlichen                     Sprecherkandidaten erzeugt werden.

  

Für die Sprecherzuordnung und Zuordnung eines Angesprochenen sind die in dieser Arbeit verwendeten Features in Tabelle A1 im Anhang zusammengefasst. 

  

 Für diese Aufgabe haben sich regelbasierte Verfahren als konkurrenzfähig mit den                       aktuellen ML-Verfahren erwiesen. Sie besitzen außerden den Vorteil, dass sie                       nicht so viele Trainingsbeispiele benötigen. Die Grundstruktur des Algorithmus                       ist der Idee des regelbasierten Koreferenzsystems von Stanford (Lee et al. 2011)                       angelehnt. Es werden eine Reihe von Regelpässen nacheinander ausgeführt. Die                       Regelpässe sind gemäß ihrer Precision geordnet, d. h.                       Regeln mit einer hohen Precision werden zuerst                       ausgeführt. Eine spätere Regel kann eine Entscheidung einer früheren Regel nicht                       revidieren. Tabelle A2 im Anhang zeigt die in dieser Arbeit verwendeten                       Regelpässe.  

  

Mit Hilfe der Trainingsdaten konnte eine optimale Reihenfolge der Ausführung der Regeln empirisch ermittelt werden, bei der einige Regeln auch mehrfach angewendet werden. 

  

(1)→(2)→(3)→(4)→(5)→(6)→(7)→(5)→(6)→(8) →(9)→(5)→(6)→(7)→(10).


    

Die Parameter für die ML-Verfahren wurden auf dem Development-Anteil der Daten optimiert und anschließend gegen die Testmenge evaluiert. Für die regelbasierten Verfahren gibt es keine Unterscheidung zwischen Trainings- und Development-Korpus. Ein Sprecher gilt als korrekt bestimmt, wenn sich der vom System bestimmte Kandidat in der selben Koreferenzkette befindet, wie die Entität, die von unserem Annotator als korrekt markiert wurde. Tabelle 2 beschreibt die Ergebnisse bei der Anwendung der Verfahren auf das Testkorpus.

    

Unsere Experimente bestätigen die Aussagen von O’Keefe (O’Keefe et al. 2012),                         dass 2Way ML-Verfahren bessere Ergebnisse in der Sprechererkennung liefern, als                         korrespondierende NWay Verfahren. Analoges gilt für die Evaluation der CRFs, die                         sogar beinahe den selben Wert für die Sprechererkennung liefern wie in (O’Keefe                         et al. 2012). Sowohl auf dem Developmentkorpus, als auch auf dem Testkorpus                         zeigen regelbasierte Ansätze deutliche Vorteile gegenüber den in dieser Arbeit                         verwendeten ML-Verfahren. Es ist weiterhin ersichtlich, dass die Bestimmung des                         Sprechers einfacher ist, als die Bestimmung des Angesprochenen. Wahrscheinlich                         liegt das daran, dass im Fall der Sprecherzuschreibung mehr Information                         vorliegt, nämlich die direkte Rede und der Kontext, während bei der Ermittlung                         des Angesprochenen die direkte Rede selbst nur hilfreich ist, wenn ein                         Angesprochener direkt darin vermerkt ist.

  

Ein direkter Vergleich mit dem besten in der Literatur zu findenden Verfahren                           (Almeida et al. 2014) kann direkt nicht durchgeführt werden. Berücksichtigt man                           den Unterschied, der Verfahren von O’Keefe auf den Texten des WSJ und den                           literarischen Texten, könnte eine Qualität von 90% Genauigkeit erreicht werden                           und damit ein mit der state of the art vergleichbares, sogar möglicherweise                           besseres Ergebnis. Im Gegensatz zu ihrem Verfahren ermitteln wir zudem auch noch                           eine angesprochene Entität. 


    

 Die Ergebnisse zeigen, dass das regelbasierte Verfahren für diese Aufgabe                             deutlich bessere Ergebnisse erzielen kann als alle ML-Verfahren, die in dieser                             Arbeit getestet wurden. Es ist geplant, die hier erstellte Zuordnung in die                             regelbasierte Koreferenzauflösung von (Krug et al. 2015) einzuarbeiten, um diese                             damit zu verbessern. Weil unsere Hauptmotivation die Verbesserung der                             Koreferenzresolution ist, diese aber im Ansatz von Almeida nicht wirksam                             verbessert werden konnte, haben wir darauf verzichtet, deren komplexes                             Lernverfahren nachzuvollziehen. Gerade die Ergebnisse, die in Tabelle 2 zu sehen                             sind, zeigen, dass mögliche Dialogsequenzen genauer untersucht werden müssen, um                             diese zuverlässig erkennen und auflösen zu können. Eine genaue Dialoganalyse                             vereinfacht wiederum die Korefenzauflösung, so dass eine Extraktion von                             Beziehungen zwischen Personen und Attributen zu Entitäten innerhalb der Romane                             möglicher erscheint. 

  


  Tab. A1: Ein Überblick über die                               in dieser Arbeit verwendeten Features. Durch + und - ist angegeben, ob                               dieses Feature gewinnbringend eingesetzt werden konnte. Zur Wahl der                               Features vgl. auch  (Elson / McKeown 2010) und (He et al. 2013). 


  

Tab. A2: Überblick über die Regelpäse für das in dieser                             Arbeit vorgestellte regelbasierte Verfahren zur Sprecherzuordnung bzw. Zuordnung                             eines Angesprochenen. Optimale Reihenfolge der Ausführung der Regeln aufgrund                             der Auswertung des Trainingssatzes:

  

(1)→(2)→(3)→(4)→(5)→(6)→(7)→(5)→(6)→(8) →(9)→(5)→(6)→(7)→(10).

    

  



Problembeschreibung 



Stand der Forschung



Daten und Annotation



    

Tab. 1: Überblick über die Auftrennung des in dieser Arbeit                   verwendeten Korpus.

  



Methoden



Evaluation



    

Tab. 2: Ergebnisse der einzelnen Verfahren auf dem                         Testkorpus, bestehend aus 20 zufällig gewählten Romanfragmenten. 

  



Diskussion und Ausblick



  Anhang  

Featurebeschrei-bung (zwischen Kandidat und direkten Rede)
  
                                   Verwendung für Sprecherzuord-nung  
  
                                   Zuordnung des Angesprochenen  
  

1. Ist der Kandidat Subjekt
  
+
  
-
  

2. Das Verb in der Dependenzstruk-tur, auf das sich der Kandidat  bezieht
  
+
  
+
  

3. Das POS-Tag des Kandidaten
  
-
  
-
  

4. Ist der Kandidat ein Pronomen
  
-
  
-
  

5-6. Befindet sich der Kandidat im Akkusativ/Dativ
  
+/+
  
+/+
  

7. Kandidat befindet sich in einer direkten Rede
  
+
  
-
  

8. Kandidat erscheint in der aktuellen direkten Rede
  
-
  
-
  

9. Kandidat befindet sich im selben Satz wie die direkte Rede
  
+
  
-
  

10. Die Direkte Rede beginnt mit einem kleingeschriebe-nem Wort
  
+
  
-
  

11. Zwischen Kandidat und direkter Rede befindet sich ein Doppelpunkt
  
-
  
-
  

12-14. Distanz zw. Kandidat und direkter Rede in Sätze/Wörter/Entitäten
  
-/-/+
  
-/-/-
  

15-16. Wort an Position +1/-1
  
-/-
  
-/-
  

17-18. Wort an Position +1/-1 ist Satzzeichen
  
+/+
  
-/-
  

19-20. Wort an Position +1/-1 ist in direkter Rede
  
+/+
  
-/-
  

19-20. Kandidat ist Sprecher der direkten Rede an Position -1/-2
  
-/-
  
+/-
  

21-22. Kandidat ist Angesprochener der direkten Rede an Position -1/-2
  
-/-
  
-/-
  
  





Regelbezeichnung
  
Regelbeschreibung

  
(1) Explizite Sprechererkennung
  
Nutzt Pattern-Matching und grammatikalische Regeln um explizite Erwähnungen eines Sprechers im direkten Umfeld einer direkten Rede zu erkennen.

  
(2) Explizite Erkennung des  Angesprochenen
  
Nutzt Pattern-Matching und grammatikalische Regeln um explizite Erwähnungen eines Angesprochenen innerhalb der direkten Rede zu erkennen.

  
(3) Explizite Erkennung des Angesprochenen II
  
Wie (1) nur für den Angesprochenen

  
(4) Explizite Sprechererkennung II
  
Wie (1), nur der Kontext wird um 1 Satz außerhalb der direkten Rede erweitert.

  
(5) Vorwärtspropagierung
  
Zwei direkt aufeinanderfolgenden direkten Reden wird der Sprecher/Angesprochener der ersten direkten Rede zugeordnet, wenn beide direkte Reden innerhalb des selben Satzes liegen

  
(6) Rückwärtspropagierung
  
wie (5) nur mit entgegengesetzter Richtung der Ausführung

  
(7) Nachbarschafts-propagierung
  
Direkten Reden, die keinen eingeschobenen Kontext aufzeigen, wechseln den Sprecher/Angesprochenen ( falls vorhanden)

  
(8) Fragenpropagierung
  
Nach einer Frage wechseln Sprecher/Angesprochener

  
(9) Dialogpropagierung
  
Direkte Rede mit maximal einem zwischenliegenden Satz wechseln ihren Sprecher/Angesprochenen

  
(10) Default-Sprecher/ Angesprochener
  
Als Sprecher wird das letzte Subjekt außerhalb direkter Reden gesetzt, als Angesprochener das letzte Subjekt, das nicht Sprecher der aktuellen direkten Rede ist.




    

  Abb. A3: Auszug aus Aston Louise “Lydia”: Beispiel für die                                 Erkennung von Sprecher und Angesprochenem in direkten Reden gemäß den Regeln in                                 Tabelle A2. Im ersten Durchlauf wird mit der Regel (1) die Sprecherin für die                                 direkten Reden 1 und 5 erkannt.                                 Anschließend erkennt Regel (7) in Rückwärtsrichtung jeweils abwechselnd                                 Sprecherin 4 und 2 und Angesprochene                                 in 3. Schließlich erkennt Regel (7) in Vorwärtsrichtung die                                 Sprecherin in 3 und die Angesprochene in 4 und 2. 


          Almeida, Mariana S.C. / Almeida, Miguel B. / Martins, André                                     F.T. (2014): "A joint model for quotation attribution and                                     coreference resolution", in: Proceedings of the 14th                                     Conference of the European Chapter of the Association for Computational                                     Linguistics, Gothenburg, Sweden 39-48.     Bohnet, Bernd / Kuhn, Jonas (2012): "The best of both                                       worlds: a graph-based completion model for transition-based parsers." In:  Proceedings of the 13th Conference of the European                                         Chapter of the Association for Computational Linguistics. Avignon,                                         France: 77-87.     Chaganty, Arun / Muzny, Grace (2015): Quote Attribution for Literary Text with Neural Networks  
https://cs224d.stanford.edu/reports/ChagantyArun.pdf
 [letzter                                             Zugriff 08. Februar 2016].    Celikyilmaz, Asli / Hakkani-Tur, Dilek / He, Hua / Kondrak,                                                 Greg / Barbosa, Denilson (2010): "The actortopic model for                                                 extracting social networks in literary narrative.", in: Proceedings of the NIPS 2010 Workshop Machine Learning for Social                                                 Computing  
https://webdocs.cs.ualberta.ca/~denilson/files/publications/nips2010.pdf
                                                   [letzter Zugriff 08. Februar 2016].    Elson, David K. / Dames, Nicholas / McKeown, Kathleen                                                       R. (2010a): "Extracting social networks from literary fiction", in:  Proceedings of the 48th annual meeting of the                                                         association for computational linguistics. Association for                                                         Computational Linguistics 
http://www1.cs.columbia.edu/~delson/pubs/ACL2010-ElsonDamesMcKeown.pdf
                                                         [letzter Zugriff 08. Februar 2016].     Elson, David K. / McKeown, Kathleen R. (2010b):                                                           "Automatic Attribution of Quoted Speech in Literary Narrative", in: Proceedings of AAAI 1013-1019.    Glass, Kevin / Bangay, Shaun (2006): "Hierarchical rule                                                             generalisation for speaker identification in fiction books", in: Proceedings of the 2006 annual research conference of the                                                             South African institute of computer scientists and information                                                             technologists on IT research in developing countries. South African                                                             Institute for Computer Scientists and Information Technologists:                                                             31-40.    Glass, Kevin / Bangay, Shaun (2007): "A naive                                                               salience-based method for speaker identification in fiction books", in: Proceedings of the 18th Annual Symposium of the Pattern                                                               Recognition Association of South Africa (PRASA’07)  
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.494.3729&amp;rep=rep1&amp;type=pdf
                                                                 [letzter Zugriff 16. Februar 2016].    He, Hua / Barbosa, Denilson / Kondrak, Grzegorz (2013):                                                                   "Identification of Speakers in Novels", in: Proceedings of                                                                   the 51st Annual Meeting of the Association for Computational                                                                   Linguistics. Sofia, Bulgaria: 1312-1320.    Iosif, Elias / Mishra, Taniya (2014): "From Speaker                                                                     Identification to Affective Analysis: A Multi-Step System for Analyzing                                                                     Children’s Stories", in: EACL 2014: 40-49.     Jannidis, Fotis / Krug, Markus / Reger, Isabella / Toepfer,                                                                         Martin / Weimer, Lukas / Puppe, Frank (2015): “Automatische                                                                         Erkennung von Figuren in deutschsprachigen Romanen”, in: Digital Humanities im deutschsprachigen Raum (Dhd 2015), Graz,                                                                         Austria.     Joachims, Thorsten (2002): Learning                                                                           to classify text using support vector machines. Methods, theory and                                                                           algorithms (= The Springer International Series in Engineering and Computer                                                                           Science 668). New York: Springer.    Krug, Markus / Puppe, Frank / Jannidis, Fotis / Macharowsky,                                                                               Luisa / Reger, Isabella / Weimer, Lukas (2015): "Rule-based                                                                               Coreference Resolution in German Historic Novels", in: Proceedings of the Fourth Workshop on Computational Linguistics for                                                                               Literature 98-104.     Lee, Heeyoung / Peirsman, Yves / Chang, Angel / Chambers,                                                                                   Nathanael / Surdeanu, Mihai / Jurafsky, Dan (2011): "Stanford's                                                                                   multi-pass sieve coreference resolution system at the CoNLL-2011 shared                                                                                   task", in: Proceedings of the Fifteenth Conference on                                                                                   Computational Natural Language Learning: Shared Task. Association                                                                                   for Computational Linguistics 
http://nlp.stanford.edu/pubs/conllst2011-coref.pdf
 [letzter                                                                                   Zugriff 08. Februar 2016].     McCallum, Andrew Kachites (2002): MALLET: A Machine Learning for Language Toolkit 
http://mallet.cs.umass.edu
                                                                                     [letzter Zugriff 08. Februar 2016].    Mikolov, Tomas / Sutskever, Ilya / Chen, Kai / Corrado, Greg                                                                                         / Dean Jeffrey (2013): "Distributed representations of words and                                                                                         phrases and their compositionality", in: Advances in                                                                                         neural information processing systems 26 
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
                                                                                         [letzter Zugriff 08. Februar 2016].    O'Keefe, Tim / Pareti, Silvia / Curran, James R. /                                                                                             Koprinska, Irena / Honnibal, Matthew (2012): "A sequence labelling                                                                                             approach to quote attribution", in: Proceedings of the                                                                                             2012 Joint Conference on Empirical Methods in Natural Language                                                                                             Processing and Computational Natural Language Learning. Association                                                                                             for Computational Linguistics, 2012: 790–799.     Rahman, Altaf / Ng, Vincent  (2011): "Narrowing the                                                                                               modeling gap: a cluster-ranking approach to coreference resolution", in: Journal of Artificial Intelligence Research 40:                                                                                               469-521.    Ruppenhofer, Josef / Sporleder, Caroline / Shirokov,                                                                                                   Fabian (2010): "Speaker Attribution in Cabinet Protocols", in: The seventh international conference on Language Resources                                                                                                   and Evaluation (LREC) 2510-2515.     Schmid, Helmut (1999): "Improvements in part-of-speech                                                                                                     tagging with an application to German", in: Armstrong, Susan / Church,                                                                                                     Kenneth / Isabelle, Pierre / Manzi, Sandra / Tzoukermann, Evelyne /                                                                                                     Yarowsky, David (eds.): Natural language processing using                                                                                                     very large corpora (= Text, Speech and Language Technology 11). New                                                                                                     York: Springer 13-25.    Schmid, Helmut / Laws, Florian (2008): "Estimation of                                                                                                       conditional probabilities with decision trees and an application to                                                                                                       fine-grained POS tagging", in: Proceedings of the 22nd                                                                                                       International Conference on Computational Linguistics (Coling 2008)                                                                                                       777–784.    Sutton, Charles / McCallum, Andrew (2006): "An                                                                                                         introduction to conditional random fields for relational learning", in:                                                                                                         Getoor, Lise / Taskar, Ben (eds.):Introduction to                                                                                                         statistical relational learning. Cambridge, MA / London: The MIT                                                                                                         Press 93-128.     Zhang, Jason Y. / Black Alan W. / Sproat, Richard                                                                                                           (2003): "Identifying speakers in children's stories for speech synthesis",                                                                                                           in: EUROSPEECH 2041-2044.     

  



Bibliographie

</text>
    <tc:tokens xmlns:tc="http://www.dspin.de/data/textcorpus">
      <tc:token ID="w1">Im</tc:token>
      <tc:token ID="w2">Folgenden</tc:token>
      <tc:token ID="w3">wird</tc:token>
      <tc:token ID="w4">ein</tc:token>
      <tc:token ID="w5">Verfahren</tc:token>
      <tc:token ID="w6">vorgestellt</tc:token>
      <tc:token ID="w7">,</tc:token>
      <tc:token ID="w8">das</tc:token>
      <tc:token ID="w9">die</tc:token>
      <tc:token ID="wa">automatische</tc:token>
      <tc:token ID="wb">Zuordnung</tc:token>
      <tc:token ID="wc">von</tc:token>
      <tc:token ID="wd">direkter</tc:token>
      <tc:token ID="we">Rede</tc:token>
      <tc:token ID="wf">in</tc:token>
      <tc:token ID="w10">Erzähltexten</tc:token>
      <tc:token ID="w11">sowohl</tc:token>
      <tc:token ID="w12">zur</tc:token>
      <tc:token ID="w13">sprechenden</tc:token>
      <tc:token ID="w14">als</tc:token>
      <tc:token ID="w15">auch</tc:token>
      <tc:token ID="w16">zur</tc:token>
      <tc:token ID="w17">angesprochenen</tc:token>
      <tc:token ID="w18">Figur</tc:token>
      <tc:token ID="w19">ermöglicht</tc:token>
      <tc:token ID="w1a">.</tc:token>
      <tc:token ID="w1b">Kann</tc:token>
      <tc:token ID="w1c">man</tc:token>
      <tc:token ID="w1d">eine</tc:token>
      <tc:token ID="w1e">solche</tc:token>
      <tc:token ID="w1f">automatische</tc:token>
      <tc:token ID="w20">Zuordnung</tc:token>
      <tc:token ID="w21">vornehmen</tc:token>
      <tc:token ID="w22">,</tc:token>
      <tc:token ID="w23">ermöglicht</tc:token>
      <tc:token ID="w24">dies</tc:token>
      <tc:token ID="w25">die</tc:token>
      <tc:token ID="w26">Extraktion</tc:token>
      <tc:token ID="w27">eines</tc:token>
      <tc:token ID="w28">sozialen</tc:token>
      <tc:token ID="w29">Netzwerks</tc:token>
      <tc:token ID="w2a">aus</tc:token>
      <tc:token ID="w2b">einem</tc:token>
      <tc:token ID="w2c">Text</tc:token>
      <tc:token ID="w2d">,</tc:token>
      <tc:token ID="w2e">wobei</tc:token>
      <tc:token ID="w2f">die</tc:token>
      <tc:token ID="w30">Figuren</tc:token>
      <tc:token ID="w31">als</tc:token>
      <tc:token ID="w32">Knoten</tc:token>
      <tc:token ID="w33">und</tc:token>
      <tc:token ID="w34">die</tc:token>
      <tc:token ID="w35">direkte</tc:token>
      <tc:token ID="w36">Rede</tc:token>
      <tc:token ID="w37">als</tc:token>
      <tc:token ID="w38">Kanten</tc:token>
      <tc:token ID="w39">modelliert</tc:token>
      <tc:token ID="w3a">werden</tc:token>
      <tc:token ID="w3b">(</tc:token>
      <tc:token ID="w3c">Elson</tc:token>
      <tc:token ID="w3d">/</tc:token>
      <tc:token ID="w3e">Dames</tc:token>
      <tc:token ID="w3f">2010</tc:token>
      <tc:token ID="w40">)</tc:token>
      <tc:token ID="w41">,</tc:token>
      <tc:token ID="w42">aber</tc:token>
      <tc:token ID="w43">sie</tc:token>
      <tc:token ID="w44">kann</tc:token>
      <tc:token ID="w45">auch</tc:token>
      <tc:token ID="w46">eine</tc:token>
      <tc:token ID="w47">wichtige</tc:token>
      <tc:token ID="w48">Informationsquelle</tc:token>
      <tc:token ID="w49">für</tc:token>
      <tc:token ID="w4a">andere</tc:token>
      <tc:token ID="w4b">analytische</tc:token>
      <tc:token ID="w4c">Schritte</tc:token>
      <tc:token ID="w4d">sein</tc:token>
      <tc:token ID="w4e">,</tc:token>
      <tc:token ID="w4f">z.B.</tc:token>
      <tc:token ID="w50">zur</tc:token>
      <tc:token ID="w51">Verbesserung</tc:token>
      <tc:token ID="w52">der</tc:token>
      <tc:token ID="w53">Koreferenzresolution</tc:token>
      <tc:token ID="w54">oder</tc:token>
      <tc:token ID="w55">zur</tc:token>
      <tc:token ID="w56">Analyse</tc:token>
      <tc:token ID="w57">der</tc:token>
      <tc:token ID="w58">Quelle</tc:token>
      <tc:token ID="w59">der</tc:token>
      <tc:token ID="w5a">Zuschreibung</tc:token>
      <tc:token ID="w5b">von</tc:token>
      <tc:token ID="w5c">Figurenattributen</tc:token>
      <tc:token ID="w5d">.</tc:token>
      <tc:token ID="w5e">Eine</tc:token>
      <tc:token ID="w5f">der</tc:token>
      <tc:token ID="w60">ersten</tc:token>
      <tc:token ID="w61">Arbeiten</tc:token>
      <tc:token ID="w62">auf</tc:token>
      <tc:token ID="w63">diesem</tc:token>
      <tc:token ID="w64">Gebiet</tc:token>
      <tc:token ID="w65">ist</tc:token>
      <tc:token ID="w66">das</tc:token>
      <tc:token ID="w67">System</tc:token>
      <tc:token ID="w68">ESPER</tc:token>
      <tc:token ID="w69">(</tc:token>
      <tc:token ID="w6a">Zhang</tc:token>
      <tc:token ID="w6b">et</tc:token>
      <tc:token ID="w6c">al.</tc:token>
      <tc:token ID="w6d">2003</tc:token>
      <tc:token ID="w6e">)</tc:token>
      <tc:token ID="w6f">,</tc:token>
      <tc:token ID="w70">das</tc:token>
      <tc:token ID="w71">direkte</tc:token>
      <tc:token ID="w72">Reden</tc:token>
      <tc:token ID="w73">innerhalb</tc:token>
      <tc:token ID="w74">von</tc:token>
      <tc:token ID="w75">Kindergeschichten</tc:token>
      <tc:token ID="w76">erkennen</tc:token>
      <tc:token ID="w77">soll</tc:token>
      <tc:token ID="w78">.</tc:token>
      <tc:token ID="w79">Das</tc:token>
      <tc:token ID="w7a">System</tc:token>
      <tc:token ID="w7b">extrahiert</tc:token>
      <tc:token ID="w7c">zunächst</tc:token>
      <tc:token ID="w7d">die</tc:token>
      <tc:token ID="w7e">direkten</tc:token>
      <tc:token ID="w7f">Reden</tc:token>
      <tc:token ID="w80">im</tc:token>
      <tc:token ID="w81">Text</tc:token>
      <tc:token ID="w82">und</tc:token>
      <tc:token ID="w83">klassifiziert</tc:token>
      <tc:token ID="w84">diese</tc:token>
      <tc:token ID="w85">mit</tc:token>
      <tc:token ID="w86">einem</tc:token>
      <tc:token ID="w87">Entscheidungsbaum</tc:token>
      <tc:token ID="w88">in</tc:token>
      <tc:token ID="w89">zwei</tc:token>
      <tc:token ID="w8a">Kategorien</tc:token>
      <tc:token ID="w8b">,</tc:token>
      <tc:token ID="w8c">Sprecherwechsel</tc:token>
      <tc:token ID="w8d">bzw.</tc:token>
      <tc:token ID="w8e">kein</tc:token>
      <tc:token ID="w8f">Sprecherwechsel</tc:token>
      <tc:token ID="w90">.</tc:token>
      <tc:token ID="w91">Evaluiert</tc:token>
      <tc:token ID="w92">werden</tc:token>
      <tc:token ID="w93">die</tc:token>
      <tc:token ID="w94">Ergebnisse</tc:token>
      <tc:token ID="w95">mit</tc:token>
      <tc:token ID="w96">zwei</tc:token>
      <tc:token ID="w97">manuell</tc:token>
      <tc:token ID="w98">annotierten</tc:token>
      <tc:token ID="w99">,</tc:token>
      <tc:token ID="w9a">sehr</tc:token>
      <tc:token ID="w9b">unterschiedlichen</tc:token>
      <tc:token ID="w9c">Geschichten</tc:token>
      <tc:token ID="w9d">.</tc:token>
      <tc:token ID="w9e">Sie</tc:token>
      <tc:token ID="w9f">berichten</tc:token>
      <tc:token ID="wa0">eine</tc:token>
      <tc:token ID="wa1">Genauigkeit</tc:token>
      <tc:token ID="wa2">,</tc:token>
      <tc:token ID="wa3">gemeint</tc:token>
      <tc:token ID="wa4">ist</tc:token>
      <tc:token ID="wa5">hier</tc:token>
      <tc:token ID="wa6">die</tc:token>
      <tc:token ID="wa7">Anzahl</tc:token>
      <tc:token ID="wa8">der</tc:token>
      <tc:token ID="wa9">korrekt</tc:token>
      <tc:token ID="waa">bestimmten</tc:token>
      <tc:token ID="wab">Sprecher</tc:token>
      <tc:token ID="wac">für</tc:token>
      <tc:token ID="wad">alle</tc:token>
      <tc:token ID="wae">direkten</tc:token>
      <tc:token ID="waf">Reden</tc:token>
      <tc:token ID="wb0">,</tc:token>
      <tc:token ID="wb1">von</tc:token>
      <tc:token ID="wb2">47.6</tc:token>
      <tc:token ID="wb3">%</tc:token>
      <tc:token ID="wb4">und</tc:token>
      <tc:token ID="wb5">86.7</tc:token>
      <tc:token ID="wb6">%.</tc:token>
      <tc:token ID="wb7">Glass</tc:token>
      <tc:token ID="wb8">und</tc:token>
      <tc:token ID="wb9">Bangay</tc:token>
      <tc:token ID="wba">(</tc:token>
      <tc:token ID="wbb">2006</tc:token>
      <tc:token ID="wbc">)</tc:token>
      <tc:token ID="wbd">,</tc:token>
      <tc:token ID="wbe">ebenfalls</tc:token>
      <tc:token ID="wbf">regelbasiert</tc:token>
      <tc:token ID="wc0">,</tc:token>
      <tc:token ID="wc1">bestimmen</tc:token>
      <tc:token ID="wc2">zunächst</tc:token>
      <tc:token ID="wc3">für</tc:token>
      <tc:token ID="wc4">eine</tc:token>
      <tc:token ID="wc5">direkte</tc:token>
      <tc:token ID="wc6">Rede</tc:token>
      <tc:token ID="wc7">das</tc:token>
      <tc:token ID="wc8">Kommunikationsverb</tc:token>
      <tc:token ID="wc9">und</tc:token>
      <tc:token ID="wca">anschließend</tc:token>
      <tc:token ID="wcb">eine</tc:token>
      <tc:token ID="wcc">Menge</tc:token>
      <tc:token ID="wcd">von</tc:token>
      <tc:token ID="wce">Akteuren</tc:token>
      <tc:token ID="wcf">,</tc:token>
      <tc:token ID="wd0">woraus</tc:token>
      <tc:token ID="wd1">letztendlich</tc:token>
      <tc:token ID="wd2">der</tc:token>
      <tc:token ID="wd3">Sprecher</tc:token>
      <tc:token ID="wd4">bestimmt</tc:token>
      <tc:token ID="wd5">wird</tc:token>
      <tc:token ID="wd6">.</tc:token>
      <tc:token ID="wd7">Sie</tc:token>
      <tc:token ID="wd8">evaluieren</tc:token>
      <tc:token ID="wd9">ihre</tc:token>
      <tc:token ID="wda">Techniken</tc:token>
      <tc:token ID="wdb">auf</tc:token>
      <tc:token ID="wdc">13</tc:token>
      <tc:token ID="wdd">englischsprachigen</tc:token>
      <tc:token ID="wde">fiktionalen</tc:token>
      <tc:token ID="wdf">Werken</tc:token>
      <tc:token ID="we0">und</tc:token>
      <tc:token ID="we1">berichten</tc:token>
      <tc:token ID="we2">eine</tc:token>
      <tc:token ID="we3">Genauigkeit</tc:token>
      <tc:token ID="we4">von</tc:token>
      <tc:token ID="we5">79.4</tc:token>
      <tc:token ID="we6">%</tc:token>
      <tc:token ID="we7">(</tc:token>
      <tc:token ID="we8">Glass</tc:token>
      <tc:token ID="we9">/</tc:token>
      <tc:token ID="wea">Bangay</tc:token>
      <tc:token ID="web">2007</tc:token>
      <tc:token ID="wec">)</tc:token>
      <tc:token ID="wed">.</tc:token>
      <tc:token ID="wee">Iosif</tc:token>
      <tc:token ID="wef">und</tc:token>
      <tc:token ID="wf0">Mishra</tc:token>
      <tc:token ID="wf1">(</tc:token>
      <tc:token ID="wf2">2014</tc:token>
      <tc:token ID="wf3">)</tc:token>
      <tc:token ID="wf4">folgen</tc:token>
      <tc:token ID="wf5">im</tc:token>
      <tc:token ID="wf6">Prinzip</tc:token>
      <tc:token ID="wf7">dem</tc:token>
      <tc:token ID="wf8">Schema</tc:token>
      <tc:token ID="wf9">von</tc:token>
      <tc:token ID="wfa">Glass</tc:token>
      <tc:token ID="wfb">und</tc:token>
      <tc:token ID="wfc">Bangay</tc:token>
      <tc:token ID="wfd">(</tc:token>
      <tc:token ID="wfe">2007</tc:token>
      <tc:token ID="wff">)</tc:token>
      <tc:token ID="w100">,</tc:token>
      <tc:token ID="w101">ergänzen</tc:token>
      <tc:token ID="w102">es</tc:token>
      <tc:token ID="w103">aber</tc:token>
      <tc:token ID="w104">durch</tc:token>
      <tc:token ID="w105">eine</tc:token>
      <tc:token ID="w106">aufwendigere</tc:token>
      <tc:token ID="w107">Vorverarbeitung</tc:token>
      <tc:token ID="w108">einschließlich</tc:token>
      <tc:token ID="w109">Koreferenzresolution</tc:token>
      <tc:token ID="w10a">.</tc:token>
      <tc:token ID="w10b">Sie</tc:token>
      <tc:token ID="w10c">erreichen</tc:token>
      <tc:token ID="w10d">eine</tc:token>
      <tc:token ID="w10e">Genauigkeit</tc:token>
      <tc:token ID="w10f">von</tc:token>
      <tc:token ID="w110">ca</tc:token>
      <tc:token ID="w111">84.5</tc:token>
      <tc:token ID="w112">%</tc:token>
      <tc:token ID="w113">und</tc:token>
      <tc:token ID="w114">zählen</tc:token>
      <tc:token ID="w115">damit</tc:token>
      <tc:token ID="w116">zu</tc:token>
      <tc:token ID="w117">den</tc:token>
      <tc:token ID="w118">besten</tc:token>
      <tc:token ID="w119">bisher</tc:token>
      <tc:token ID="w11a">veröffentlichten</tc:token>
      <tc:token ID="w11b">Ergebnissen</tc:token>
      <tc:token ID="w11c">.</tc:token>
      <tc:token ID="w11d">Ruppenhofer</tc:token>
      <tc:token ID="w11e">und</tc:token>
      <tc:token ID="w11f">andere</tc:token>
      <tc:token ID="w120">(</tc:token>
      <tc:token ID="w121">Ruppenhofer</tc:token>
      <tc:token ID="w122">et</tc:token>
      <tc:token ID="w123">al.</tc:token>
      <tc:token ID="w124">2010</tc:token>
      <tc:token ID="w125">)</tc:token>
      <tc:token ID="w126">berichten</tc:token>
      <tc:token ID="w127">einen</tc:token>
      <tc:token ID="w128">F-Score</tc:token>
      <tc:token ID="w129">von</tc:token>
      <tc:token ID="w12a">79</tc:token>
      <tc:token ID="w12b">%</tc:token>
      <tc:token ID="w12c">in</tc:token>
      <tc:token ID="w12d">der</tc:token>
      <tc:token ID="w12e">Zuordnung</tc:token>
      <tc:token ID="w12f">von</tc:token>
      <tc:token ID="w130">Politikern</tc:token>
      <tc:token ID="w131">zu</tc:token>
      <tc:token ID="w132">ihren</tc:token>
      <tc:token ID="w133">Aussagen</tc:token>
      <tc:token ID="w134">in</tc:token>
      <tc:token ID="w135">deutschsprachigen</tc:token>
      <tc:token ID="w136">Kabinettsprotokollen</tc:token>
      <tc:token ID="w137">aus</tc:token>
      <tc:token ID="w138">den</tc:token>
      <tc:token ID="w139">Jahren</tc:token>
      <tc:token ID="w13a">1949-1960</tc:token>
      <tc:token ID="w13b">.</tc:token>
      <tc:token ID="w13c">Neben</tc:token>
      <tc:token ID="w13d">diesen</tc:token>
      <tc:token ID="w13e">regelbasierten</tc:token>
      <tc:token ID="w13f">Ansätzen</tc:token>
      <tc:token ID="w140">werden</tc:token>
      <tc:token ID="w141">auch</tc:token>
      <tc:token ID="w142">maschinelle</tc:token>
      <tc:token ID="w143">Lernverfahren</tc:token>
      <tc:token ID="w144">eingesetzt</tc:token>
      <tc:token ID="w145">.</tc:token>
      <tc:token ID="w146">Zu</tc:token>
      <tc:token ID="w147">den</tc:token>
      <tc:token ID="w148">ersten</tc:token>
      <tc:token ID="w149">erfolgreichen</tc:token>
      <tc:token ID="w14a">Systemen</tc:token>
      <tc:token ID="w14b">zählt</tc:token>
      <tc:token ID="w14c">das</tc:token>
      <tc:token ID="w14d">von</tc:token>
      <tc:token ID="w14e">Elson</tc:token>
      <tc:token ID="w14f">und</tc:token>
      <tc:token ID="w150">McKeown</tc:token>
      <tc:token ID="w151">(</tc:token>
      <tc:token ID="w152">2010</tc:token>
      <tc:token ID="w153">)</tc:token>
      <tc:token ID="w154">.</tc:token>
      <tc:token ID="w155">Ihre</tc:token>
      <tc:token ID="w156">Daten</tc:token>
      <tc:token ID="w157">für</tc:token>
      <tc:token ID="w158">die</tc:token>
      <tc:token ID="w159">Sprecherzuordnung</tc:token>
      <tc:token ID="w15a">ließen</tc:token>
      <tc:token ID="w15b">sie</tc:token>
      <tc:token ID="w15c">über</tc:token>
      <tc:token ID="w15d">Amazons</tc:token>
      <tc:token ID="w15e">Mechanical</tc:token>
      <tc:token ID="w15f">Turk</tc:token>
      <tc:token ID="w160">System</tc:token>
      <tc:token ID="w161">bearbeiten</tc:token>
      <tc:token ID="w162">.</tc:token>
      <tc:token ID="w163">Ihr</tc:token>
      <tc:token ID="w164">System</tc:token>
      <tc:token ID="w165">klassifiziert</tc:token>
      <tc:token ID="w166">zunächst</tc:token>
      <tc:token ID="w167">regelbasiert</tc:token>
      <tc:token ID="w168">eine</tc:token>
      <tc:token ID="w169">direkte</tc:token>
      <tc:token ID="w16a">Rede</tc:token>
      <tc:token ID="w16b">in</tc:token>
      <tc:token ID="w16c">eine</tc:token>
      <tc:token ID="w16d">von</tc:token>
      <tc:token ID="w16e">fünf</tc:token>
      <tc:token ID="w16f">syntaktischen</tc:token>
      <tc:token ID="w170">Kategorien</tc:token>
      <tc:token ID="w171">.</tc:token>
      <tc:token ID="w172">Für</tc:token>
      <tc:token ID="w173">jede</tc:token>
      <tc:token ID="w174">dieser</tc:token>
      <tc:token ID="w175">Kategorien</tc:token>
      <tc:token ID="w176">wurden</tc:token>
      <tc:token ID="w177">anschließend</tc:token>
      <tc:token ID="w178">eigenständige</tc:token>
      <tc:token ID="w179">maschinelle</tc:token>
      <tc:token ID="w17a">Lernverfahren</tc:token>
      <tc:token ID="w17b">trainiert</tc:token>
      <tc:token ID="w17c">.</tc:token>
      <tc:token ID="w17d">Insgesamt</tc:token>
      <tc:token ID="w17e">erreichen</tc:token>
      <tc:token ID="w17f">sie</tc:token>
      <tc:token ID="w180">eine</tc:token>
      <tc:token ID="w181">Genauigkeit</tc:token>
      <tc:token ID="w182">von</tc:token>
      <tc:token ID="w183">etwa</tc:token>
      <tc:token ID="w184">83</tc:token>
      <tc:token ID="w185">%</tc:token>
      <tc:token ID="w186">,</tc:token>
      <tc:token ID="w187">ausgewertet</tc:token>
      <tc:token ID="w188">anhand</tc:token>
      <tc:token ID="w189">von</tc:token>
      <tc:token ID="w18a">englischen</tc:token>
      <tc:token ID="w18b">Romanen</tc:token>
      <tc:token ID="w18c">des</tc:token>
      <tc:token ID="w18d">19</tc:token>
      <tc:token ID="w18e">Jahrhunderts</tc:token>
      <tc:token ID="w18f">.</tc:token>
      <tc:token ID="w190">O’</tc:token>
      <tc:token ID="w191">Keefe</tc:token>
      <tc:token ID="w192">und</tc:token>
      <tc:token ID="w193">andere</tc:token>
      <tc:token ID="w194">(</tc:token>
      <tc:token ID="w195">O’Keefe</tc:token>
      <tc:token ID="w196">et</tc:token>
      <tc:token ID="w197">al.</tc:token>
      <tc:token ID="w198">2012</tc:token>
      <tc:token ID="w199">)</tc:token>
      <tc:token ID="w19a">,</tc:token>
      <tc:token ID="w19b">die</tc:token>
      <tc:token ID="w19c">an</tc:token>
      <tc:token ID="w19d">Elson</tc:token>
      <tc:token ID="w19e">und</tc:token>
      <tc:token ID="w19f">McKeowns</tc:token>
      <tc:token ID="w1a0">Ansatz</tc:token>
      <tc:token ID="w1a1">die</tc:token>
      <tc:token ID="w1a2">Erstellung</tc:token>
      <tc:token ID="w1a3">des</tc:token>
      <tc:token ID="w1a4">Goldstandards</tc:token>
      <tc:token ID="w1a5">und</tc:token>
      <tc:token ID="w1a6">auch</tc:token>
      <tc:token ID="w1a7">die</tc:token>
      <tc:token ID="w1a8">praxisferne</tc:token>
      <tc:token ID="w1a9">Verwendung</tc:token>
      <tc:token ID="w1aa">von</tc:token>
      <tc:token ID="w1ab">Informationen</tc:token>
      <tc:token ID="w1ac">aus</tc:token>
      <tc:token ID="w1ad">dem</tc:token>
      <tc:token ID="w1ae">Goldstandard</tc:token>
      <tc:token ID="w1af">kritisieren</tc:token>
      <tc:token ID="w1b0">,</tc:token>
      <tc:token ID="w1b1">betrachten</tc:token>
      <tc:token ID="w1b2">die</tc:token>
      <tc:token ID="w1b3">Zuordnung</tc:token>
      <tc:token ID="w1b4">als</tc:token>
      <tc:token ID="w1b5">Sequenzproblem</tc:token>
      <tc:token ID="w1b6">.</tc:token>
      <tc:token ID="w1b7">Sie</tc:token>
      <tc:token ID="w1b8">nutzen</tc:token>
      <tc:token ID="w1b9">die</tc:token>
      <tc:token ID="w1ba">Klassifikationsangaben</tc:token>
      <tc:token ID="w1bb">von</tc:token>
      <tc:token ID="w1bc">vorhergehenden</tc:token>
      <tc:token ID="w1bd">direkten</tc:token>
      <tc:token ID="w1be">Reden</tc:token>
      <tc:token ID="w1bf">als</tc:token>
      <tc:token ID="w1c0">Features</tc:token>
      <tc:token ID="w1c1">für</tc:token>
      <tc:token ID="w1c2">die</tc:token>
      <tc:token ID="w1c3">gesamte</tc:token>
      <tc:token ID="w1c4">Sequenz</tc:token>
      <tc:token ID="w1c5">.</tc:token>
      <tc:token ID="w1c6">In</tc:token>
      <tc:token ID="w1c7">ihrer</tc:token>
      <tc:token ID="w1c8">Evaluation</tc:token>
      <tc:token ID="w1c9">vergleichen</tc:token>
      <tc:token ID="w1ca">Sie</tc:token>
      <tc:token ID="w1cb">drei</tc:token>
      <tc:token ID="w1cc">Verfahren</tc:token>
      <tc:token ID="w1cd">mit</tc:token>
      <tc:token ID="w1ce">einer</tc:token>
      <tc:token ID="w1cf">sehr</tc:token>
      <tc:token ID="w1d0">einfachen</tc:token>
      <tc:token ID="w1d1">regelbasierten</tc:token>
      <tc:token ID="w1d2">Baseline</tc:token>
      <tc:token ID="w1d3">.</tc:token>
      <tc:token ID="w1d4">Ihre</tc:token>
      <tc:token ID="w1d5">Ergebnisse</tc:token>
      <tc:token ID="w1d6">bei</tc:token>
      <tc:token ID="w1d7">der</tc:token>
      <tc:token ID="w1d8">Anwendung</tc:token>
      <tc:token ID="w1d9">des</tc:token>
      <tc:token ID="w1da">Systems</tc:token>
      <tc:token ID="w1db">auf</tc:token>
      <tc:token ID="w1dc">zwei</tc:token>
      <tc:token ID="w1dd">Zeitungskorpora</tc:token>
      <tc:token ID="w1de">-</tc:token>
      <tc:token ID="w1df">Wall</tc:token>
      <tc:token ID="w1e0">Street</tc:token>
      <tc:token ID="w1e1">Journal</tc:token>
      <tc:token ID="w1e2">und</tc:token>
      <tc:token ID="w1e3">Sydney</tc:token>
      <tc:token ID="w1e4">Morning</tc:token>
      <tc:token ID="w1e5">Herald</tc:token>
      <tc:token ID="w1e6">-</tc:token>
      <tc:token ID="w1e7">sowie</tc:token>
      <tc:token ID="w1e8">die</tc:token>
      <tc:token ID="w1e9">Sammlung</tc:token>
      <tc:token ID="w1ea">literarischer</tc:token>
      <tc:token ID="w1eb">Texte</tc:token>
      <tc:token ID="w1ec">aus</tc:token>
      <tc:token ID="w1ed">der</tc:token>
      <tc:token ID="w1ee">Arbeit</tc:token>
      <tc:token ID="w1ef">von</tc:token>
      <tc:token ID="w1f0">Elson</tc:token>
      <tc:token ID="w1f1">und</tc:token>
      <tc:token ID="w1f2">McKeown</tc:token>
      <tc:token ID="w1f3">zeigen</tc:token>
      <tc:token ID="w1f4">einen</tc:token>
      <tc:token ID="w1f5">großen</tc:token>
      <tc:token ID="w1f6">Unterschied</tc:token>
      <tc:token ID="w1f7">zwischen</tc:token>
      <tc:token ID="w1f8">den</tc:token>
      <tc:token ID="w1f9">Domänen</tc:token>
      <tc:token ID="w1fa">.</tc:token>
      <tc:token ID="w1fb">Sie</tc:token>
      <tc:token ID="w1fc">erreichen</tc:token>
      <tc:token ID="w1fd">auf</tc:token>
      <tc:token ID="w1fe">den</tc:token>
      <tc:token ID="w1ff">beiden</tc:token>
      <tc:token ID="w200">Zeitungskorpora</tc:token>
      <tc:token ID="w201">84.1</tc:token>
      <tc:token ID="w202">%</tc:token>
      <tc:token ID="w203">(</tc:token>
      <tc:token ID="w204">WSJ</tc:token>
      <tc:token ID="w205">)</tc:token>
      <tc:token ID="w206">bzw.</tc:token>
      <tc:token ID="w207">91.7</tc:token>
      <tc:token ID="w208">%</tc:token>
      <tc:token ID="w209">(</tc:token>
      <tc:token ID="w20a">SMH</tc:token>
      <tc:token ID="w20b">)</tc:token>
      <tc:token ID="w20c">Genauigkeit</tc:token>
      <tc:token ID="w20d">.</tc:token>
      <tc:token ID="w20e">Auf</tc:token>
      <tc:token ID="w20f">dem</tc:token>
      <tc:token ID="w210">literarischen</tc:token>
      <tc:token ID="w211">Korpus</tc:token>
      <tc:token ID="w212">erreichen</tc:token>
      <tc:token ID="w213">sie</tc:token>
      <tc:token ID="w214">dagegen</tc:token>
      <tc:token ID="w215">lediglich</tc:token>
      <tc:token ID="w216">eine</tc:token>
      <tc:token ID="w217">maximale</tc:token>
      <tc:token ID="w218">Genauigkeit</tc:token>
      <tc:token ID="w219">von</tc:token>
      <tc:token ID="w21a">49</tc:token>
      <tc:token ID="w21b">%</tc:token>
      <tc:token ID="w21c">.</tc:token>
      <tc:token ID="w21d">(</tc:token>
      <tc:token ID="w21e">He</tc:token>
      <tc:token ID="w21f">et</tc:token>
      <tc:token ID="w220">al.</tc:token>
      <tc:token ID="w221">2013</tc:token>
      <tc:token ID="w222">)</tc:token>
      <tc:token ID="w223">erreichen</tc:token>
      <tc:token ID="w224">mit</tc:token>
      <tc:token ID="w225">einem</tc:token>
      <tc:token ID="w226">auf</tc:token>
      <tc:token ID="w227">Ranking</tc:token>
      <tc:token ID="w228">basierten</tc:token>
      <tc:token ID="w229">maschinellem</tc:token>
      <tc:token ID="w22a">Lernverfahren</tc:token>
      <tc:token ID="w22b">unter</tc:token>
      <tc:token ID="w22c">der</tc:token>
      <tc:token ID="w22d">Ausnutzung</tc:token>
      <tc:token ID="w22e">von</tc:token>
      <tc:token ID="w22f">Features</tc:token>
      <tc:token ID="w230">des</tc:token>
      <tc:token ID="w231">Actor-Topic</tc:token>
      <tc:token ID="w232">Modells</tc:token>
      <tc:token ID="w233">(</tc:token>
      <tc:token ID="w234">Celikyilmaz</tc:token>
      <tc:token ID="w235">et</tc:token>
      <tc:token ID="w236">al.</tc:token>
      <tc:token ID="w237">2010</tc:token>
      <tc:token ID="w238">)</tc:token>
      <tc:token ID="w239">auf</tc:token>
      <tc:token ID="w23a">dem</tc:token>
      <tc:token ID="w23b">Elson</tc:token>
      <tc:token ID="w23c">und</tc:token>
      <tc:token ID="w23d">McKeown-Korpus</tc:token>
      <tc:token ID="w23e">eine</tc:token>
      <tc:token ID="w23f">Genauigkeit</tc:token>
      <tc:token ID="w240">zwischen</tc:token>
      <tc:token ID="w241">74.8</tc:token>
      <tc:token ID="w242">%</tc:token>
      <tc:token ID="w243">und</tc:token>
      <tc:token ID="w244">80.3</tc:token>
      <tc:token ID="w245">%.</tc:token>
      <tc:token ID="w246">Almeida</tc:token>
      <tc:token ID="w247">und</tc:token>
      <tc:token ID="w248">andere</tc:token>
      <tc:token ID="w249">gehen</tc:token>
      <tc:token ID="w24a">von</tc:token>
      <tc:token ID="w24b">einer</tc:token>
      <tc:token ID="w24c">engen</tc:token>
      <tc:token ID="w24d">Verflechtung</tc:token>
      <tc:token ID="w24e">von</tc:token>
      <tc:token ID="w24f">Koreferenzresolution</tc:token>
      <tc:token ID="w250">und</tc:token>
      <tc:token ID="w251">Sprecherattribution</tc:token>
      <tc:token ID="w252">aus</tc:token>
      <tc:token ID="w253">und</tc:token>
      <tc:token ID="w254">integrieren</tc:token>
      <tc:token ID="w255">dabei</tc:token>
      <tc:token ID="w256">beide</tc:token>
      <tc:token ID="w257">Verfahren</tc:token>
      <tc:token ID="w258">in</tc:token>
      <tc:token ID="w259">ihrem</tc:token>
      <tc:token ID="w25a">Ansatz</tc:token>
      <tc:token ID="w25b">;</tc:token>
      <tc:token ID="w25c">die</tc:token>
      <tc:token ID="w25d">Ergebnisse</tc:token>
      <tc:token ID="w25e">der</tc:token>
      <tc:token ID="w25f">beiden</tc:token>
      <tc:token ID="w260">einzelnen</tc:token>
      <tc:token ID="w261">Lernverfahren</tc:token>
      <tc:token ID="w262">werden</tc:token>
      <tc:token ID="w263">in</tc:token>
      <tc:token ID="w264">einem</tc:token>
      <tc:token ID="w265">dritten</tc:token>
      <tc:token ID="w266">Schritt</tc:token>
      <tc:token ID="w267">verbunden</tc:token>
      <tc:token ID="w268">.</tc:token>
      <tc:token ID="w269">Sie</tc:token>
      <tc:token ID="w26a">erreichen</tc:token>
      <tc:token ID="w26b">damit</tc:token>
      <tc:token ID="w26c">88.1</tc:token>
      <tc:token ID="w26d">%</tc:token>
      <tc:token ID="w26e">Genauigkeit</tc:token>
      <tc:token ID="w26f">(</tc:token>
      <tc:token ID="w270">Almeida</tc:token>
      <tc:token ID="w271">et</tc:token>
      <tc:token ID="w272">al.</tc:token>
      <tc:token ID="w273">2014</tc:token>
      <tc:token ID="w274">)</tc:token>
      <tc:token ID="w275">.</tc:token>
      <tc:token ID="w276">Neuere</tc:token>
      <tc:token ID="w277">Versuche</tc:token>
      <tc:token ID="w278">mit</tc:token>
      <tc:token ID="w279">Deep</tc:token>
      <tc:token ID="w27a">Learning-Verfahren</tc:token>
      <tc:token ID="w27b">aufgrund</tc:token>
      <tc:token ID="w27c">der</tc:token>
      <tc:token ID="w27d">Sprache</tc:token>
      <tc:token ID="w27e">der</tc:token>
      <tc:token ID="w27f">Figuren</tc:token>
      <tc:token ID="w280">haben</tc:token>
      <tc:token ID="w281">nur</tc:token>
      <tc:token ID="w282">Genauigkeiten</tc:token>
      <tc:token ID="w283">von</tc:token>
      <tc:token ID="w284">unter</tc:token>
      <tc:token ID="w285">50</tc:token>
      <tc:token ID="w286">%</tc:token>
      <tc:token ID="w287">erreicht</tc:token>
      <tc:token ID="w288">(</tc:token>
      <tc:token ID="w289">Chaganty</tc:token>
      <tc:token ID="w28a">/</tc:token>
      <tc:token ID="w28b">Muzny</tc:token>
      <tc:token ID="w28c">2014</tc:token>
      <tc:token ID="w28d">)</tc:token>
      <tc:token ID="w28e">.</tc:token>
      <tc:token ID="w28f">Die</tc:token>
      <tc:token ID="w290">Zuordnung</tc:token>
      <tc:token ID="w291">einer</tc:token>
      <tc:token ID="w292">angesprochenen</tc:token>
      <tc:token ID="w293">Figur</tc:token>
      <tc:token ID="w294">wurde</tc:token>
      <tc:token ID="w295">unserer</tc:token>
      <tc:token ID="w296">Wissens</tc:token>
      <tc:token ID="w297">noch</tc:token>
      <tc:token ID="w298">in</tc:token>
      <tc:token ID="w299">keiner</tc:token>
      <tc:token ID="w29a">anderen</tc:token>
      <tc:token ID="w29b">Arbeit</tc:token>
      <tc:token ID="w29c">untersucht</tc:token>
      <tc:token ID="w29d">.</tc:token>
      <tc:token ID="w29e">Für</tc:token>
      <tc:token ID="w29f">diese</tc:token>
      <tc:token ID="w2a0">Arbeit</tc:token>
      <tc:token ID="w2a1">verwenden</tc:token>
      <tc:token ID="w2a2">wir</tc:token>
      <tc:token ID="w2a3">Abschnitte</tc:token>
      <tc:token ID="w2a4">des</tc:token>
      <tc:token ID="w2a5">frei</tc:token>
      <tc:token ID="w2a6">zugänglichen</tc:token>
      <tc:token ID="w2a7">Korpus</tc:token>
      <tc:token ID="w2a8">DROC.</tc:token>
      <tc:token ID="w2a9">DROC</tc:token>
      <tc:token ID="w2aa">besteht</tc:token>
      <tc:token ID="w2ab">aus</tc:token>
      <tc:token ID="w2ac">89</tc:token>
      <tc:token ID="w2ad">Romanausschnitten</tc:token>
      <tc:token ID="w2ae">,</tc:token>
      <tc:token ID="w2af">jeweils</tc:token>
      <tc:token ID="w2b0">130</tc:token>
      <tc:token ID="w2b1">Sätze</tc:token>
      <tc:token ID="w2b2">lang</tc:token>
      <tc:token ID="w2b3">,</tc:token>
      <tc:token ID="w2b4">in</tc:token>
      <tc:token ID="w2b5">denen</tc:token>
      <tc:token ID="w2b6">alle</tc:token>
      <tc:token ID="w2b7">Figurenreferenzen</tc:token>
      <tc:token ID="w2b8">(</tc:token>
      <tc:token ID="w2b9">mit</tc:token>
      <tc:token ID="w2ba">und</tc:token>
      <tc:token ID="w2bb">ohne</tc:token>
      <tc:token ID="w2bc">Namen</tc:token>
      <tc:token ID="w2bd">)</tc:token>
      <tc:token ID="w2be">und</tc:token>
      <tc:token ID="w2bf">Koreferenzen</tc:token>
      <tc:token ID="w2c0">annotiert</tc:token>
      <tc:token ID="w2c1">sind</tc:token>
      <tc:token ID="w2c2">.</tc:token>
      <tc:token ID="w2c3">Aus</tc:token>
      <tc:token ID="w2c4">dem</tc:token>
      <tc:token ID="w2c5">Korpus</tc:token>
      <tc:token ID="w2c6">wurden</tc:token>
      <tc:token ID="w2c7">77</tc:token>
      <tc:token ID="w2c8">Ausschnitte</tc:token>
      <tc:token ID="w2c9">ausgewählt</tc:token>
      <tc:token ID="w2ca">und</tc:token>
      <tc:token ID="w2cb">mit</tc:token>
      <tc:token ID="w2cc">einem</tc:token>
      <tc:token ID="w2cd">eigens</tc:token>
      <tc:token ID="w2ce">entwickelten</tc:token>
      <tc:token ID="w2cf">Tool</tc:token>
      <tc:token ID="w2d0">alle</tc:token>
      <tc:token ID="w2d1">direkten</tc:token>
      <tc:token ID="w2d2">Reden</tc:token>
      <tc:token ID="w2d3">sowie</tc:token>
      <tc:token ID="w2d4">die</tc:token>
      <tc:token ID="w2d5">zugehörigen</tc:token>
      <tc:token ID="w2d6">Sprecher</tc:token>
      <tc:token ID="w2d7">und</tc:token>
      <tc:token ID="w2d8">angesprochenen</tc:token>
      <tc:token ID="w2d9">Figuren</tc:token>
      <tc:token ID="w2da">eingetragen</tc:token>
      <tc:token ID="w2db">.</tc:token>
      <tc:token ID="w2dc">Jeder</tc:token>
      <tc:token ID="w2dd">Text</tc:token>
      <tc:token ID="w2de">wurde</tc:token>
      <tc:token ID="w2df">von</tc:token>
      <tc:token ID="w2e0">einem</tc:token>
      <tc:token ID="w2e1">Annotator</tc:token>
      <tc:token ID="w2e2">bearbeitet</tc:token>
      <tc:token ID="w2e3">;</tc:token>
      <tc:token ID="w2e4">eine</tc:token>
      <tc:token ID="w2e5">zweite</tc:token>
      <tc:token ID="w2e6">Annotation</tc:token>
      <tc:token ID="w2e7">ist</tc:token>
      <tc:token ID="w2e8">vorgesehen</tc:token>
      <tc:token ID="w2e9">.</tc:token>
      <tc:token ID="w2ea">Insgesamt</tc:token>
      <tc:token ID="w2eb">wurden</tc:token>
      <tc:token ID="w2ec">so</tc:token>
      <tc:token ID="w2ed">2264</tc:token>
      <tc:token ID="w2ee">direkte</tc:token>
      <tc:token ID="w2ef">Reden</tc:token>
      <tc:token ID="w2f0">mit</tc:token>
      <tc:token ID="w2f1">Sprecher</tc:token>
      <tc:token ID="w2f2">und</tc:token>
      <tc:token ID="w2f3">Angesprochenen</tc:token>
      <tc:token ID="w2f4">annotiert</tc:token>
      <tc:token ID="w2f5">.</tc:token>
      <tc:token ID="w2f6">Für</tc:token>
      <tc:token ID="w2f7">die</tc:token>
      <tc:token ID="w2f8">in</tc:token>
      <tc:token ID="w2f9">Abschnitt</tc:token>
      <tc:token ID="w2fa">5</tc:token>
      <tc:token ID="w2fb">diskutierten</tc:token>
      <tc:token ID="w2fc">Experimente</tc:token>
      <tc:token ID="w2fd">wurde</tc:token>
      <tc:token ID="w2fe">das</tc:token>
      <tc:token ID="w2ff">Korpus</tc:token>
      <tc:token ID="w300">in</tc:token>
      <tc:token ID="w301">drei</tc:token>
      <tc:token ID="w302">zufällige</tc:token>
      <tc:token ID="w303">Mengen</tc:token>
      <tc:token ID="w304">aufgeteilt</tc:token>
      <tc:token ID="w305">:</tc:token>
      <tc:token ID="w306">Wir</tc:token>
      <tc:token ID="w307">verwenden</tc:token>
      <tc:token ID="w308">regelbasierte</tc:token>
      <tc:token ID="w309">Verfahren</tc:token>
      <tc:token ID="w30a">und</tc:token>
      <tc:token ID="w30b">maschinelle</tc:token>
      <tc:token ID="w30c">Lernverfahren</tc:token>
      <tc:token ID="w30d">,</tc:token>
      <tc:token ID="w30e">aber</tc:token>
      <tc:token ID="w30f">anders</tc:token>
      <tc:token ID="w310">als</tc:token>
      <tc:token ID="w311">in</tc:token>
      <tc:token ID="w312">(</tc:token>
      <tc:token ID="w313">He</tc:token>
      <tc:token ID="w314">et</tc:token>
      <tc:token ID="w315">al.</tc:token>
      <tc:token ID="w316">2013</tc:token>
      <tc:token ID="w317">)</tc:token>
      <tc:token ID="w318">oder</tc:token>
      <tc:token ID="w319">(</tc:token>
      <tc:token ID="w31a">O’Keefe</tc:token>
      <tc:token ID="w31b">et</tc:token>
      <tc:token ID="w31c">al.</tc:token>
      <tc:token ID="w31d">2012</tc:token>
      <tc:token ID="w31e">)</tc:token>
      <tc:token ID="w31f">dienen</tc:token>
      <tc:token ID="w320">erstere</tc:token>
      <tc:token ID="w321">nicht</tc:token>
      <tc:token ID="w322">nur</tc:token>
      <tc:token ID="w323">als</tc:token>
      <tc:token ID="w324">Baseline-Verfahren</tc:token>
      <tc:token ID="w325">,</tc:token>
      <tc:token ID="w326">sondern</tc:token>
      <tc:token ID="w327">wurden</tc:token>
      <tc:token ID="w328">soweit</tc:token>
      <tc:token ID="w329">wie</tc:token>
      <tc:token ID="w32a">möglich</tc:token>
      <tc:token ID="w32b">optimiert</tc:token>
      <tc:token ID="w32c">.</tc:token>
      <tc:token ID="w32d">Wir</tc:token>
      <tc:token ID="w32e">verwenden</tc:token>
      <tc:token ID="w32f">die</tc:token>
      <tc:token ID="w330">Techniken</tc:token>
      <tc:token ID="w331">2-Way</tc:token>
      <tc:token ID="w332">Klassifikation</tc:token>
      <tc:token ID="w333">und</tc:token>
      <tc:token ID="w334">N-Way</tc:token>
      <tc:token ID="w335">Klassifikation</tc:token>
      <tc:token ID="w336">wie</tc:token>
      <tc:token ID="w337">in</tc:token>
      <tc:token ID="w338">(</tc:token>
      <tc:token ID="w339">O’Keefe</tc:token>
      <tc:token ID="w33a">et</tc:token>
      <tc:token ID="w33b">al.</tc:token>
      <tc:token ID="w33c">2012</tc:token>
      <tc:token ID="w33d">)</tc:token>
      <tc:token ID="w33e">vorgeschlagen</tc:token>
      <tc:token ID="w33f">.</tc:token>
      <tc:token ID="w340">Zusätzlich</tc:token>
      <tc:token ID="w341">evaluieren</tc:token>
      <tc:token ID="w342">wir</tc:token>
      <tc:token ID="w343">MaxEnt2WayToMatch</tc:token>
      <tc:token ID="w344">,</tc:token>
      <tc:token ID="w345">bei</tc:token>
      <tc:token ID="w346">dem</tc:token>
      <tc:token ID="w347">Kandidaten</tc:token>
      <tc:token ID="w348">nur</tc:token>
      <tc:token ID="w349">bis</tc:token>
      <tc:token ID="w34a">zum</tc:token>
      <tc:token ID="w34b">ersten</tc:token>
      <tc:token ID="w34c">tatsächlichen</tc:token>
      <tc:token ID="w34d">Sprecherkandidaten</tc:token>
      <tc:token ID="w34e">erzeugt</tc:token>
      <tc:token ID="w34f">werden</tc:token>
      <tc:token ID="w350">.</tc:token>
      <tc:token ID="w351">Für</tc:token>
      <tc:token ID="w352">die</tc:token>
      <tc:token ID="w353">Sprecherzuordnung</tc:token>
      <tc:token ID="w354">und</tc:token>
      <tc:token ID="w355">Zuordnung</tc:token>
      <tc:token ID="w356">eines</tc:token>
      <tc:token ID="w357">Angesprochenen</tc:token>
      <tc:token ID="w358">sind</tc:token>
      <tc:token ID="w359">die</tc:token>
      <tc:token ID="w35a">in</tc:token>
      <tc:token ID="w35b">dieser</tc:token>
      <tc:token ID="w35c">Arbeit</tc:token>
      <tc:token ID="w35d">verwendeten</tc:token>
      <tc:token ID="w35e">Features</tc:token>
      <tc:token ID="w35f">in</tc:token>
      <tc:token ID="w360">Tabelle</tc:token>
      <tc:token ID="w361">A1</tc:token>
      <tc:token ID="w362">im</tc:token>
      <tc:token ID="w363">Anhang</tc:token>
      <tc:token ID="w364">zusammengefasst</tc:token>
      <tc:token ID="w365">.</tc:token>
      <tc:token ID="w366">Für</tc:token>
      <tc:token ID="w367">diese</tc:token>
      <tc:token ID="w368">Aufgabe</tc:token>
      <tc:token ID="w369">haben</tc:token>
      <tc:token ID="w36a">sich</tc:token>
      <tc:token ID="w36b">regelbasierte</tc:token>
      <tc:token ID="w36c">Verfahren</tc:token>
      <tc:token ID="w36d">als</tc:token>
      <tc:token ID="w36e">konkurrenzfähig</tc:token>
      <tc:token ID="w36f">mit</tc:token>
      <tc:token ID="w370">den</tc:token>
      <tc:token ID="w371">aktuellen</tc:token>
      <tc:token ID="w372">ML-Verfahren</tc:token>
      <tc:token ID="w373">erwiesen</tc:token>
      <tc:token ID="w374">.</tc:token>
      <tc:token ID="w375">Sie</tc:token>
      <tc:token ID="w376">besitzen</tc:token>
      <tc:token ID="w377">außerden</tc:token>
      <tc:token ID="w378">den</tc:token>
      <tc:token ID="w379">Vorteil</tc:token>
      <tc:token ID="w37a">,</tc:token>
      <tc:token ID="w37b">dass</tc:token>
      <tc:token ID="w37c">sie</tc:token>
      <tc:token ID="w37d">nicht</tc:token>
      <tc:token ID="w37e">so</tc:token>
      <tc:token ID="w37f">viele</tc:token>
      <tc:token ID="w380">Trainingsbeispiele</tc:token>
      <tc:token ID="w381">benötigen</tc:token>
      <tc:token ID="w382">.</tc:token>
      <tc:token ID="w383">Die</tc:token>
      <tc:token ID="w384">Grundstruktur</tc:token>
      <tc:token ID="w385">des</tc:token>
      <tc:token ID="w386">Algorithmus</tc:token>
      <tc:token ID="w387">ist</tc:token>
      <tc:token ID="w388">der</tc:token>
      <tc:token ID="w389">Idee</tc:token>
      <tc:token ID="w38a">des</tc:token>
      <tc:token ID="w38b">regelbasierten</tc:token>
      <tc:token ID="w38c">Koreferenzsystems</tc:token>
      <tc:token ID="w38d">von</tc:token>
      <tc:token ID="w38e">Stanford</tc:token>
      <tc:token ID="w38f">(</tc:token>
      <tc:token ID="w390">Lee</tc:token>
      <tc:token ID="w391">et</tc:token>
      <tc:token ID="w392">al.</tc:token>
      <tc:token ID="w393">2011</tc:token>
      <tc:token ID="w394">)</tc:token>
      <tc:token ID="w395">angelehnt</tc:token>
      <tc:token ID="w396">.</tc:token>
      <tc:token ID="w397">Es</tc:token>
      <tc:token ID="w398">werden</tc:token>
      <tc:token ID="w399">eine</tc:token>
      <tc:token ID="w39a">Reihe</tc:token>
      <tc:token ID="w39b">von</tc:token>
      <tc:token ID="w39c">Regelpässen</tc:token>
      <tc:token ID="w39d">nacheinander</tc:token>
      <tc:token ID="w39e">ausgeführt</tc:token>
      <tc:token ID="w39f">.</tc:token>
      <tc:token ID="w3a0">Die</tc:token>
      <tc:token ID="w3a1">Regelpässe</tc:token>
      <tc:token ID="w3a2">sind</tc:token>
      <tc:token ID="w3a3">gemäß</tc:token>
      <tc:token ID="w3a4">ihrer</tc:token>
      <tc:token ID="w3a5">Precision</tc:token>
      <tc:token ID="w3a6">geordnet</tc:token>
      <tc:token ID="w3a7">,</tc:token>
      <tc:token ID="w3a8">d.</tc:token>
      <tc:token ID="w3a9">h.</tc:token>
      <tc:token ID="w3aa">Regeln</tc:token>
      <tc:token ID="w3ab">mit</tc:token>
      <tc:token ID="w3ac">einer</tc:token>
      <tc:token ID="w3ad">hohen</tc:token>
      <tc:token ID="w3ae">Precision</tc:token>
      <tc:token ID="w3af">werden</tc:token>
      <tc:token ID="w3b0">zuerst</tc:token>
      <tc:token ID="w3b1">ausgeführt</tc:token>
      <tc:token ID="w3b2">.</tc:token>
      <tc:token ID="w3b3">Eine</tc:token>
      <tc:token ID="w3b4">spätere</tc:token>
      <tc:token ID="w3b5">Regel</tc:token>
      <tc:token ID="w3b6">kann</tc:token>
      <tc:token ID="w3b7">eine</tc:token>
      <tc:token ID="w3b8">Entscheidung</tc:token>
      <tc:token ID="w3b9">einer</tc:token>
      <tc:token ID="w3ba">früheren</tc:token>
      <tc:token ID="w3bb">Regel</tc:token>
      <tc:token ID="w3bc">nicht</tc:token>
      <tc:token ID="w3bd">revidieren</tc:token>
      <tc:token ID="w3be">.</tc:token>
      <tc:token ID="w3bf">Tabelle</tc:token>
      <tc:token ID="w3c0">A2</tc:token>
      <tc:token ID="w3c1">im</tc:token>
      <tc:token ID="w3c2">Anhang</tc:token>
      <tc:token ID="w3c3">zeigt</tc:token>
      <tc:token ID="w3c4">die</tc:token>
      <tc:token ID="w3c5">in</tc:token>
      <tc:token ID="w3c6">dieser</tc:token>
      <tc:token ID="w3c7">Arbeit</tc:token>
      <tc:token ID="w3c8">verwendeten</tc:token>
      <tc:token ID="w3c9">Regelpässe</tc:token>
      <tc:token ID="w3ca">.</tc:token>
      <tc:token ID="w3cb">Mit</tc:token>
      <tc:token ID="w3cc">Hilfe</tc:token>
      <tc:token ID="w3cd">der</tc:token>
      <tc:token ID="w3ce">Trainingsdaten</tc:token>
      <tc:token ID="w3cf">konnte</tc:token>
      <tc:token ID="w3d0">eine</tc:token>
      <tc:token ID="w3d1">optimale</tc:token>
      <tc:token ID="w3d2">Reihenfolge</tc:token>
      <tc:token ID="w3d3">der</tc:token>
      <tc:token ID="w3d4">Ausführung</tc:token>
      <tc:token ID="w3d5">der</tc:token>
      <tc:token ID="w3d6">Regeln</tc:token>
      <tc:token ID="w3d7">empirisch</tc:token>
      <tc:token ID="w3d8">ermittelt</tc:token>
      <tc:token ID="w3d9">werden</tc:token>
      <tc:token ID="w3da">,</tc:token>
      <tc:token ID="w3db">bei</tc:token>
      <tc:token ID="w3dc">der</tc:token>
      <tc:token ID="w3dd">einige</tc:token>
      <tc:token ID="w3de">Regeln</tc:token>
      <tc:token ID="w3df">auch</tc:token>
      <tc:token ID="w3e0">mehrfach</tc:token>
      <tc:token ID="w3e1">angewendet</tc:token>
      <tc:token ID="w3e2">werden</tc:token>
      <tc:token ID="w3e3">.</tc:token>
      <tc:token ID="w3e4">(</tc:token>
      <tc:token ID="w3e5">1</tc:token>
      <tc:token ID="w3e6">)→(2</tc:token>
      <tc:token ID="w3e7">)→(3</tc:token>
      <tc:token ID="w3e8">)→(4</tc:token>
      <tc:token ID="w3e9">)→(5</tc:token>
      <tc:token ID="w3ea">)→(6</tc:token>
      <tc:token ID="w3eb">)→(7</tc:token>
      <tc:token ID="w3ec">)→(5</tc:token>
      <tc:token ID="w3ed">)→(6</tc:token>
      <tc:token ID="w3ee">)→(8</tc:token>
      <tc:token ID="w3ef">)</tc:token>
      <tc:token ID="w3f0">→(9</tc:token>
      <tc:token ID="w3f1">)→(5</tc:token>
      <tc:token ID="w3f2">)→(6</tc:token>
      <tc:token ID="w3f3">)→(7</tc:token>
      <tc:token ID="w3f4">)→(</tc:token>
      <tc:token ID="w3f5">10</tc:token>
      <tc:token ID="w3f6">)</tc:token>
      <tc:token ID="w3f7">.</tc:token>
      <tc:token ID="w3f8">Die</tc:token>
      <tc:token ID="w3f9">Parameter</tc:token>
      <tc:token ID="w3fa">für</tc:token>
      <tc:token ID="w3fb">die</tc:token>
      <tc:token ID="w3fc">ML-Verfahren</tc:token>
      <tc:token ID="w3fd">wurden</tc:token>
      <tc:token ID="w3fe">auf</tc:token>
      <tc:token ID="w3ff">dem</tc:token>
      <tc:token ID="w400">Development-Anteil</tc:token>
      <tc:token ID="w401">der</tc:token>
      <tc:token ID="w402">Daten</tc:token>
      <tc:token ID="w403">optimiert</tc:token>
      <tc:token ID="w404">und</tc:token>
      <tc:token ID="w405">anschließend</tc:token>
      <tc:token ID="w406">gegen</tc:token>
      <tc:token ID="w407">die</tc:token>
      <tc:token ID="w408">Testmenge</tc:token>
      <tc:token ID="w409">evaluiert</tc:token>
      <tc:token ID="w40a">.</tc:token>
      <tc:token ID="w40b">Für</tc:token>
      <tc:token ID="w40c">die</tc:token>
      <tc:token ID="w40d">regelbasierten</tc:token>
      <tc:token ID="w40e">Verfahren</tc:token>
      <tc:token ID="w40f">gibt</tc:token>
      <tc:token ID="w410">es</tc:token>
      <tc:token ID="w411">keine</tc:token>
      <tc:token ID="w412">Unterscheidung</tc:token>
      <tc:token ID="w413">zwischen</tc:token>
      <tc:token ID="w414">Trainings-</tc:token>
      <tc:token ID="w415">und</tc:token>
      <tc:token ID="w416">Development-Korpus</tc:token>
      <tc:token ID="w417">.</tc:token>
      <tc:token ID="w418">Ein</tc:token>
      <tc:token ID="w419">Sprecher</tc:token>
      <tc:token ID="w41a">gilt</tc:token>
      <tc:token ID="w41b">als</tc:token>
      <tc:token ID="w41c">korrekt</tc:token>
      <tc:token ID="w41d">bestimmt</tc:token>
      <tc:token ID="w41e">,</tc:token>
      <tc:token ID="w41f">wenn</tc:token>
      <tc:token ID="w420">sich</tc:token>
      <tc:token ID="w421">der</tc:token>
      <tc:token ID="w422">vom</tc:token>
      <tc:token ID="w423">System</tc:token>
      <tc:token ID="w424">bestimmte</tc:token>
      <tc:token ID="w425">Kandidat</tc:token>
      <tc:token ID="w426">in</tc:token>
      <tc:token ID="w427">der</tc:token>
      <tc:token ID="w428">selben</tc:token>
      <tc:token ID="w429">Koreferenzkette</tc:token>
      <tc:token ID="w42a">befindet</tc:token>
      <tc:token ID="w42b">,</tc:token>
      <tc:token ID="w42c">wie</tc:token>
      <tc:token ID="w42d">die</tc:token>
      <tc:token ID="w42e">Entität</tc:token>
      <tc:token ID="w42f">,</tc:token>
      <tc:token ID="w430">die</tc:token>
      <tc:token ID="w431">von</tc:token>
      <tc:token ID="w432">unserem</tc:token>
      <tc:token ID="w433">Annotator</tc:token>
      <tc:token ID="w434">als</tc:token>
      <tc:token ID="w435">korrekt</tc:token>
      <tc:token ID="w436">markiert</tc:token>
      <tc:token ID="w437">wurde</tc:token>
      <tc:token ID="w438">.</tc:token>
      <tc:token ID="w439">Tabelle</tc:token>
      <tc:token ID="w43a">2</tc:token>
      <tc:token ID="w43b">beschreibt</tc:token>
      <tc:token ID="w43c">die</tc:token>
      <tc:token ID="w43d">Ergebnisse</tc:token>
      <tc:token ID="w43e">bei</tc:token>
      <tc:token ID="w43f">der</tc:token>
      <tc:token ID="w440">Anwendung</tc:token>
      <tc:token ID="w441">der</tc:token>
      <tc:token ID="w442">Verfahren</tc:token>
      <tc:token ID="w443">auf</tc:token>
      <tc:token ID="w444">das</tc:token>
      <tc:token ID="w445">Testkorpus</tc:token>
      <tc:token ID="w446">.</tc:token>
      <tc:token ID="w447">Unsere</tc:token>
      <tc:token ID="w448">Experimente</tc:token>
      <tc:token ID="w449">bestätigen</tc:token>
      <tc:token ID="w44a">die</tc:token>
      <tc:token ID="w44b">Aussagen</tc:token>
      <tc:token ID="w44c">von</tc:token>
      <tc:token ID="w44d">O’Keefe</tc:token>
      <tc:token ID="w44e">(</tc:token>
      <tc:token ID="w44f">O’Keefe</tc:token>
      <tc:token ID="w450">et</tc:token>
      <tc:token ID="w451">al.</tc:token>
      <tc:token ID="w452">2012</tc:token>
      <tc:token ID="w453">)</tc:token>
      <tc:token ID="w454">,</tc:token>
      <tc:token ID="w455">dass</tc:token>
      <tc:token ID="w456">2</tc:token>
      <tc:token ID="w457">Way</tc:token>
      <tc:token ID="w458">ML-Verfahren</tc:token>
      <tc:token ID="w459">bessere</tc:token>
      <tc:token ID="w45a">Ergebnisse</tc:token>
      <tc:token ID="w45b">in</tc:token>
      <tc:token ID="w45c">der</tc:token>
      <tc:token ID="w45d">Sprechererkennung</tc:token>
      <tc:token ID="w45e">liefern</tc:token>
      <tc:token ID="w45f">,</tc:token>
      <tc:token ID="w460">als</tc:token>
      <tc:token ID="w461">korrespondierende</tc:token>
      <tc:token ID="w462">NWay</tc:token>
      <tc:token ID="w463">Verfahren</tc:token>
      <tc:token ID="w464">.</tc:token>
      <tc:token ID="w465">Analoges</tc:token>
      <tc:token ID="w466">gilt</tc:token>
      <tc:token ID="w467">für</tc:token>
      <tc:token ID="w468">die</tc:token>
      <tc:token ID="w469">Evaluation</tc:token>
      <tc:token ID="w46a">der</tc:token>
      <tc:token ID="w46b">CRFs</tc:token>
      <tc:token ID="w46c">,</tc:token>
      <tc:token ID="w46d">die</tc:token>
      <tc:token ID="w46e">sogar</tc:token>
      <tc:token ID="w46f">beinahe</tc:token>
      <tc:token ID="w470">den</tc:token>
      <tc:token ID="w471">selben</tc:token>
      <tc:token ID="w472">Wert</tc:token>
      <tc:token ID="w473">für</tc:token>
      <tc:token ID="w474">die</tc:token>
      <tc:token ID="w475">Sprechererkennung</tc:token>
      <tc:token ID="w476">liefern</tc:token>
      <tc:token ID="w477">wie</tc:token>
      <tc:token ID="w478">in</tc:token>
      <tc:token ID="w479">(</tc:token>
      <tc:token ID="w47a">O’Keefe</tc:token>
      <tc:token ID="w47b">et</tc:token>
      <tc:token ID="w47c">al.</tc:token>
      <tc:token ID="w47d">2012</tc:token>
      <tc:token ID="w47e">)</tc:token>
      <tc:token ID="w47f">.</tc:token>
      <tc:token ID="w480">Sowohl</tc:token>
      <tc:token ID="w481">auf</tc:token>
      <tc:token ID="w482">dem</tc:token>
      <tc:token ID="w483">Developmentkorpus</tc:token>
      <tc:token ID="w484">,</tc:token>
      <tc:token ID="w485">als</tc:token>
      <tc:token ID="w486">auch</tc:token>
      <tc:token ID="w487">auf</tc:token>
      <tc:token ID="w488">dem</tc:token>
      <tc:token ID="w489">Testkorpus</tc:token>
      <tc:token ID="w48a">zeigen</tc:token>
      <tc:token ID="w48b">regelbasierte</tc:token>
      <tc:token ID="w48c">Ansätze</tc:token>
      <tc:token ID="w48d">deutliche</tc:token>
      <tc:token ID="w48e">Vorteile</tc:token>
      <tc:token ID="w48f">gegenüber</tc:token>
      <tc:token ID="w490">den</tc:token>
      <tc:token ID="w491">in</tc:token>
      <tc:token ID="w492">dieser</tc:token>
      <tc:token ID="w493">Arbeit</tc:token>
      <tc:token ID="w494">verwendeten</tc:token>
      <tc:token ID="w495">ML-Verfahren</tc:token>
      <tc:token ID="w496">.</tc:token>
      <tc:token ID="w497">Es</tc:token>
      <tc:token ID="w498">ist</tc:token>
      <tc:token ID="w499">weiterhin</tc:token>
      <tc:token ID="w49a">ersichtlich</tc:token>
      <tc:token ID="w49b">,</tc:token>
      <tc:token ID="w49c">dass</tc:token>
      <tc:token ID="w49d">die</tc:token>
      <tc:token ID="w49e">Bestimmung</tc:token>
      <tc:token ID="w49f">des</tc:token>
      <tc:token ID="w4a0">Sprechers</tc:token>
      <tc:token ID="w4a1">einfacher</tc:token>
      <tc:token ID="w4a2">ist</tc:token>
      <tc:token ID="w4a3">,</tc:token>
      <tc:token ID="w4a4">als</tc:token>
      <tc:token ID="w4a5">die</tc:token>
      <tc:token ID="w4a6">Bestimmung</tc:token>
      <tc:token ID="w4a7">des</tc:token>
      <tc:token ID="w4a8">Angesprochenen</tc:token>
      <tc:token ID="w4a9">.</tc:token>
      <tc:token ID="w4aa">Wahrscheinlich</tc:token>
      <tc:token ID="w4ab">liegt</tc:token>
      <tc:token ID="w4ac">das</tc:token>
      <tc:token ID="w4ad">daran</tc:token>
      <tc:token ID="w4ae">,</tc:token>
      <tc:token ID="w4af">dass</tc:token>
      <tc:token ID="w4b0">im</tc:token>
      <tc:token ID="w4b1">Fall</tc:token>
      <tc:token ID="w4b2">der</tc:token>
      <tc:token ID="w4b3">Sprecherzuschreibung</tc:token>
      <tc:token ID="w4b4">mehr</tc:token>
      <tc:token ID="w4b5">Information</tc:token>
      <tc:token ID="w4b6">vorliegt</tc:token>
      <tc:token ID="w4b7">,</tc:token>
      <tc:token ID="w4b8">nämlich</tc:token>
      <tc:token ID="w4b9">die</tc:token>
      <tc:token ID="w4ba">direkte</tc:token>
      <tc:token ID="w4bb">Rede</tc:token>
      <tc:token ID="w4bc">und</tc:token>
      <tc:token ID="w4bd">der</tc:token>
      <tc:token ID="w4be">Kontext</tc:token>
      <tc:token ID="w4bf">,</tc:token>
      <tc:token ID="w4c0">während</tc:token>
      <tc:token ID="w4c1">bei</tc:token>
      <tc:token ID="w4c2">der</tc:token>
      <tc:token ID="w4c3">Ermittlung</tc:token>
      <tc:token ID="w4c4">des</tc:token>
      <tc:token ID="w4c5">Angesprochenen</tc:token>
      <tc:token ID="w4c6">die</tc:token>
      <tc:token ID="w4c7">direkte</tc:token>
      <tc:token ID="w4c8">Rede</tc:token>
      <tc:token ID="w4c9">selbst</tc:token>
      <tc:token ID="w4ca">nur</tc:token>
      <tc:token ID="w4cb">hilfreich</tc:token>
      <tc:token ID="w4cc">ist</tc:token>
      <tc:token ID="w4cd">,</tc:token>
      <tc:token ID="w4ce">wenn</tc:token>
      <tc:token ID="w4cf">ein</tc:token>
      <tc:token ID="w4d0">Angesprochener</tc:token>
      <tc:token ID="w4d1">direkt</tc:token>
      <tc:token ID="w4d2">darin</tc:token>
      <tc:token ID="w4d3">vermerkt</tc:token>
      <tc:token ID="w4d4">ist</tc:token>
      <tc:token ID="w4d5">.</tc:token>
      <tc:token ID="w4d6">Ein</tc:token>
      <tc:token ID="w4d7">direkter</tc:token>
      <tc:token ID="w4d8">Vergleich</tc:token>
      <tc:token ID="w4d9">mit</tc:token>
      <tc:token ID="w4da">dem</tc:token>
      <tc:token ID="w4db">besten</tc:token>
      <tc:token ID="w4dc">in</tc:token>
      <tc:token ID="w4dd">der</tc:token>
      <tc:token ID="w4de">Literatur</tc:token>
      <tc:token ID="w4df">zu</tc:token>
      <tc:token ID="w4e0">findenden</tc:token>
      <tc:token ID="w4e1">Verfahren</tc:token>
      <tc:token ID="w4e2">(</tc:token>
      <tc:token ID="w4e3">Almeida</tc:token>
      <tc:token ID="w4e4">et</tc:token>
      <tc:token ID="w4e5">al.</tc:token>
      <tc:token ID="w4e6">2014</tc:token>
      <tc:token ID="w4e7">)</tc:token>
      <tc:token ID="w4e8">kann</tc:token>
      <tc:token ID="w4e9">direkt</tc:token>
      <tc:token ID="w4ea">nicht</tc:token>
      <tc:token ID="w4eb">durchgeführt</tc:token>
      <tc:token ID="w4ec">werden</tc:token>
      <tc:token ID="w4ed">.</tc:token>
      <tc:token ID="w4ee">Berücksichtigt</tc:token>
      <tc:token ID="w4ef">man</tc:token>
      <tc:token ID="w4f0">den</tc:token>
      <tc:token ID="w4f1">Unterschied</tc:token>
      <tc:token ID="w4f2">,</tc:token>
      <tc:token ID="w4f3">der</tc:token>
      <tc:token ID="w4f4">Verfahren</tc:token>
      <tc:token ID="w4f5">von</tc:token>
      <tc:token ID="w4f6">O’Keefe</tc:token>
      <tc:token ID="w4f7">auf</tc:token>
      <tc:token ID="w4f8">den</tc:token>
      <tc:token ID="w4f9">Texten</tc:token>
      <tc:token ID="w4fa">des</tc:token>
      <tc:token ID="w4fb">WSJ</tc:token>
      <tc:token ID="w4fc">und</tc:token>
      <tc:token ID="w4fd">den</tc:token>
      <tc:token ID="w4fe">literarischen</tc:token>
      <tc:token ID="w4ff">Texten</tc:token>
      <tc:token ID="w500">,</tc:token>
      <tc:token ID="w501">könnte</tc:token>
      <tc:token ID="w502">eine</tc:token>
      <tc:token ID="w503">Qualität</tc:token>
      <tc:token ID="w504">von</tc:token>
      <tc:token ID="w505">90</tc:token>
      <tc:token ID="w506">%</tc:token>
      <tc:token ID="w507">Genauigkeit</tc:token>
      <tc:token ID="w508">erreicht</tc:token>
      <tc:token ID="w509">werden</tc:token>
      <tc:token ID="w50a">und</tc:token>
      <tc:token ID="w50b">damit</tc:token>
      <tc:token ID="w50c">ein</tc:token>
      <tc:token ID="w50d">mit</tc:token>
      <tc:token ID="w50e">der</tc:token>
      <tc:token ID="w50f">state</tc:token>
      <tc:token ID="w510">of</tc:token>
      <tc:token ID="w511">the</tc:token>
      <tc:token ID="w512">art</tc:token>
      <tc:token ID="w513">vergleichbares</tc:token>
      <tc:token ID="w514">,</tc:token>
      <tc:token ID="w515">sogar</tc:token>
      <tc:token ID="w516">möglicherweise</tc:token>
      <tc:token ID="w517">besseres</tc:token>
      <tc:token ID="w518">Ergebnis</tc:token>
      <tc:token ID="w519">.</tc:token>
      <tc:token ID="w51a">Im</tc:token>
      <tc:token ID="w51b">Gegensatz</tc:token>
      <tc:token ID="w51c">zu</tc:token>
      <tc:token ID="w51d">ihrem</tc:token>
      <tc:token ID="w51e">Verfahren</tc:token>
      <tc:token ID="w51f">ermitteln</tc:token>
      <tc:token ID="w520">wir</tc:token>
      <tc:token ID="w521">zudem</tc:token>
      <tc:token ID="w522">auch</tc:token>
      <tc:token ID="w523">noch</tc:token>
      <tc:token ID="w524">eine</tc:token>
      <tc:token ID="w525">angesprochene</tc:token>
      <tc:token ID="w526">Entität</tc:token>
      <tc:token ID="w527">.</tc:token>
      <tc:token ID="w528">Die</tc:token>
      <tc:token ID="w529">Ergebnisse</tc:token>
      <tc:token ID="w52a">zeigen</tc:token>
      <tc:token ID="w52b">,</tc:token>
      <tc:token ID="w52c">dass</tc:token>
      <tc:token ID="w52d">das</tc:token>
      <tc:token ID="w52e">regelbasierte</tc:token>
      <tc:token ID="w52f">Verfahren</tc:token>
      <tc:token ID="w530">für</tc:token>
      <tc:token ID="w531">diese</tc:token>
      <tc:token ID="w532">Aufgabe</tc:token>
      <tc:token ID="w533">deutlich</tc:token>
      <tc:token ID="w534">bessere</tc:token>
      <tc:token ID="w535">Ergebnisse</tc:token>
      <tc:token ID="w536">erzielen</tc:token>
      <tc:token ID="w537">kann</tc:token>
      <tc:token ID="w538">als</tc:token>
      <tc:token ID="w539">alle</tc:token>
      <tc:token ID="w53a">ML-Verfahren</tc:token>
      <tc:token ID="w53b">,</tc:token>
      <tc:token ID="w53c">die</tc:token>
      <tc:token ID="w53d">in</tc:token>
      <tc:token ID="w53e">dieser</tc:token>
      <tc:token ID="w53f">Arbeit</tc:token>
      <tc:token ID="w540">getestet</tc:token>
      <tc:token ID="w541">wurden</tc:token>
      <tc:token ID="w542">.</tc:token>
      <tc:token ID="w543">Es</tc:token>
      <tc:token ID="w544">ist</tc:token>
      <tc:token ID="w545">geplant</tc:token>
      <tc:token ID="w546">,</tc:token>
      <tc:token ID="w547">die</tc:token>
      <tc:token ID="w548">hier</tc:token>
      <tc:token ID="w549">erstellte</tc:token>
      <tc:token ID="w54a">Zuordnung</tc:token>
      <tc:token ID="w54b">in</tc:token>
      <tc:token ID="w54c">die</tc:token>
      <tc:token ID="w54d">regelbasierte</tc:token>
      <tc:token ID="w54e">Koreferenzauflösung</tc:token>
      <tc:token ID="w54f">von</tc:token>
      <tc:token ID="w550">(</tc:token>
      <tc:token ID="w551">Krug</tc:token>
      <tc:token ID="w552">et</tc:token>
      <tc:token ID="w553">al.</tc:token>
      <tc:token ID="w554">2015</tc:token>
      <tc:token ID="w555">)</tc:token>
      <tc:token ID="w556">einzuarbeiten</tc:token>
      <tc:token ID="w557">,</tc:token>
      <tc:token ID="w558">um</tc:token>
      <tc:token ID="w559">diese</tc:token>
      <tc:token ID="w55a">damit</tc:token>
      <tc:token ID="w55b">zu</tc:token>
      <tc:token ID="w55c">verbessern</tc:token>
      <tc:token ID="w55d">.</tc:token>
      <tc:token ID="w55e">Weil</tc:token>
      <tc:token ID="w55f">unsere</tc:token>
      <tc:token ID="w560">Hauptmotivation</tc:token>
      <tc:token ID="w561">die</tc:token>
      <tc:token ID="w562">Verbesserung</tc:token>
      <tc:token ID="w563">der</tc:token>
      <tc:token ID="w564">Koreferenzresolution</tc:token>
      <tc:token ID="w565">ist</tc:token>
      <tc:token ID="w566">,</tc:token>
      <tc:token ID="w567">diese</tc:token>
      <tc:token ID="w568">aber</tc:token>
      <tc:token ID="w569">im</tc:token>
      <tc:token ID="w56a">Ansatz</tc:token>
      <tc:token ID="w56b">von</tc:token>
      <tc:token ID="w56c">Almeida</tc:token>
      <tc:token ID="w56d">nicht</tc:token>
      <tc:token ID="w56e">wirksam</tc:token>
      <tc:token ID="w56f">verbessert</tc:token>
      <tc:token ID="w570">werden</tc:token>
      <tc:token ID="w571">konnte</tc:token>
      <tc:token ID="w572">,</tc:token>
      <tc:token ID="w573">haben</tc:token>
      <tc:token ID="w574">wir</tc:token>
      <tc:token ID="w575">darauf</tc:token>
      <tc:token ID="w576">verzichtet</tc:token>
      <tc:token ID="w577">,</tc:token>
      <tc:token ID="w578">deren</tc:token>
      <tc:token ID="w579">komplexes</tc:token>
      <tc:token ID="w57a">Lernverfahren</tc:token>
      <tc:token ID="w57b">nachzuvollziehen</tc:token>
      <tc:token ID="w57c">.</tc:token>
      <tc:token ID="w57d">Gerade</tc:token>
      <tc:token ID="w57e">die</tc:token>
      <tc:token ID="w57f">Ergebnisse</tc:token>
      <tc:token ID="w580">,</tc:token>
      <tc:token ID="w581">die</tc:token>
      <tc:token ID="w582">in</tc:token>
      <tc:token ID="w583">Tabelle</tc:token>
      <tc:token ID="w584">2</tc:token>
      <tc:token ID="w585">zu</tc:token>
      <tc:token ID="w586">sehen</tc:token>
      <tc:token ID="w587">sind</tc:token>
      <tc:token ID="w588">,</tc:token>
      <tc:token ID="w589">zeigen</tc:token>
      <tc:token ID="w58a">,</tc:token>
      <tc:token ID="w58b">dass</tc:token>
      <tc:token ID="w58c">mögliche</tc:token>
      <tc:token ID="w58d">Dialogsequenzen</tc:token>
      <tc:token ID="w58e">genauer</tc:token>
      <tc:token ID="w58f">untersucht</tc:token>
      <tc:token ID="w590">werden</tc:token>
      <tc:token ID="w591">müssen</tc:token>
      <tc:token ID="w592">,</tc:token>
      <tc:token ID="w593">um</tc:token>
      <tc:token ID="w594">diese</tc:token>
      <tc:token ID="w595">zuverlässig</tc:token>
      <tc:token ID="w596">erkennen</tc:token>
      <tc:token ID="w597">und</tc:token>
      <tc:token ID="w598">auflösen</tc:token>
      <tc:token ID="w599">zu</tc:token>
      <tc:token ID="w59a">können</tc:token>
      <tc:token ID="w59b">.</tc:token>
      <tc:token ID="w59c">Eine</tc:token>
      <tc:token ID="w59d">genaue</tc:token>
      <tc:token ID="w59e">Dialoganalyse</tc:token>
      <tc:token ID="w59f">vereinfacht</tc:token>
      <tc:token ID="w5a0">wiederum</tc:token>
      <tc:token ID="w5a1">die</tc:token>
      <tc:token ID="w5a2">Korefenzauflösung</tc:token>
      <tc:token ID="w5a3">,</tc:token>
      <tc:token ID="w5a4">so</tc:token>
      <tc:token ID="w5a5">dass</tc:token>
      <tc:token ID="w5a6">eine</tc:token>
      <tc:token ID="w5a7">Extraktion</tc:token>
      <tc:token ID="w5a8">von</tc:token>
      <tc:token ID="w5a9">Beziehungen</tc:token>
      <tc:token ID="w5aa">zwischen</tc:token>
      <tc:token ID="w5ab">Personen</tc:token>
      <tc:token ID="w5ac">und</tc:token>
      <tc:token ID="w5ad">Attributen</tc:token>
      <tc:token ID="w5ae">zu</tc:token>
      <tc:token ID="w5af">Entitäten</tc:token>
      <tc:token ID="w5b0">innerhalb</tc:token>
      <tc:token ID="w5b1">der</tc:token>
      <tc:token ID="w5b2">Romane</tc:token>
      <tc:token ID="w5b3">möglicher</tc:token>
      <tc:token ID="w5b4">erscheint</tc:token>
      <tc:token ID="w5b5">.</tc:token>
      <tc:token ID="w5b6">Tab.</tc:token>
      <tc:token ID="w5b7">A1</tc:token>
      <tc:token ID="w5b8">:</tc:token>
      <tc:token ID="w5b9">Ein</tc:token>
      <tc:token ID="w5ba">Überblick</tc:token>
      <tc:token ID="w5bb">über</tc:token>
      <tc:token ID="w5bc">die</tc:token>
      <tc:token ID="w5bd">in</tc:token>
      <tc:token ID="w5be">dieser</tc:token>
      <tc:token ID="w5bf">Arbeit</tc:token>
      <tc:token ID="w5c0">verwendeten</tc:token>
      <tc:token ID="w5c1">Features</tc:token>
      <tc:token ID="w5c2">.</tc:token>
      <tc:token ID="w5c3">Durch</tc:token>
      <tc:token ID="w5c4">+</tc:token>
      <tc:token ID="w5c5">und</tc:token>
      <tc:token ID="w5c6">-</tc:token>
      <tc:token ID="w5c7">ist</tc:token>
      <tc:token ID="w5c8">angegeben</tc:token>
      <tc:token ID="w5c9">,</tc:token>
      <tc:token ID="w5ca">ob</tc:token>
      <tc:token ID="w5cb">dieses</tc:token>
      <tc:token ID="w5cc">Feature</tc:token>
      <tc:token ID="w5cd">gewinnbringend</tc:token>
      <tc:token ID="w5ce">eingesetzt</tc:token>
      <tc:token ID="w5cf">werden</tc:token>
      <tc:token ID="w5d0">konnte</tc:token>
      <tc:token ID="w5d1">.</tc:token>
      <tc:token ID="w5d2">Zur</tc:token>
      <tc:token ID="w5d3">Wahl</tc:token>
      <tc:token ID="w5d4">der</tc:token>
      <tc:token ID="w5d5">Features</tc:token>
      <tc:token ID="w5d6">vgl.</tc:token>
      <tc:token ID="w5d7">auch</tc:token>
      <tc:token ID="w5d8">(</tc:token>
      <tc:token ID="w5d9">Elson</tc:token>
      <tc:token ID="w5da">/</tc:token>
      <tc:token ID="w5db">McKeown</tc:token>
      <tc:token ID="w5dc">2010</tc:token>
      <tc:token ID="w5dd">)</tc:token>
      <tc:token ID="w5de">und</tc:token>
      <tc:token ID="w5df">(</tc:token>
      <tc:token ID="w5e0">He</tc:token>
      <tc:token ID="w5e1">et</tc:token>
      <tc:token ID="w5e2">al.</tc:token>
      <tc:token ID="w5e3">2013</tc:token>
      <tc:token ID="w5e4">)</tc:token>
      <tc:token ID="w5e5">.</tc:token>
      <tc:token ID="w5e6">Tab.</tc:token>
      <tc:token ID="w5e7">A2</tc:token>
      <tc:token ID="w5e8">:</tc:token>
      <tc:token ID="w5e9">Überblick</tc:token>
      <tc:token ID="w5ea">über</tc:token>
      <tc:token ID="w5eb">die</tc:token>
      <tc:token ID="w5ec">Regelpäse</tc:token>
      <tc:token ID="w5ed">für</tc:token>
      <tc:token ID="w5ee">das</tc:token>
      <tc:token ID="w5ef">in</tc:token>
      <tc:token ID="w5f0">dieser</tc:token>
      <tc:token ID="w5f1">Arbeit</tc:token>
      <tc:token ID="w5f2">vorgestellte</tc:token>
      <tc:token ID="w5f3">regelbasierte</tc:token>
      <tc:token ID="w5f4">Verfahren</tc:token>
      <tc:token ID="w5f5">zur</tc:token>
      <tc:token ID="w5f6">Sprecherzuordnung</tc:token>
      <tc:token ID="w5f7">bzw</tc:token>
      <tc:token ID="w5f8">.</tc:token>
      <tc:token ID="w5f9">Zuordnung</tc:token>
      <tc:token ID="w5fa">eines</tc:token>
      <tc:token ID="w5fb">Angesprochenen</tc:token>
      <tc:token ID="w5fc">.</tc:token>
      <tc:token ID="w5fd">Optimale</tc:token>
      <tc:token ID="w5fe">Reihenfolge</tc:token>
      <tc:token ID="w5ff">der</tc:token>
      <tc:token ID="w600">Ausführung</tc:token>
      <tc:token ID="w601">der</tc:token>
      <tc:token ID="w602">Regeln</tc:token>
      <tc:token ID="w603">aufgrund</tc:token>
      <tc:token ID="w604">der</tc:token>
      <tc:token ID="w605">Auswertung</tc:token>
      <tc:token ID="w606">des</tc:token>
      <tc:token ID="w607">Trainingssatzes</tc:token>
      <tc:token ID="w608">:</tc:token>
      <tc:token ID="w609">(</tc:token>
      <tc:token ID="w60a">1</tc:token>
      <tc:token ID="w60b">)→(2</tc:token>
      <tc:token ID="w60c">)→(3</tc:token>
      <tc:token ID="w60d">)→(4</tc:token>
      <tc:token ID="w60e">)→(5</tc:token>
      <tc:token ID="w60f">)→(6</tc:token>
      <tc:token ID="w610">)→(7</tc:token>
      <tc:token ID="w611">)→(5</tc:token>
      <tc:token ID="w612">)→(6</tc:token>
      <tc:token ID="w613">)→(8</tc:token>
      <tc:token ID="w614">)</tc:token>
      <tc:token ID="w615">→(9</tc:token>
      <tc:token ID="w616">)→(5</tc:token>
      <tc:token ID="w617">)→(6</tc:token>
      <tc:token ID="w618">)→(7</tc:token>
      <tc:token ID="w619">)→(</tc:token>
      <tc:token ID="w61a">10</tc:token>
      <tc:token ID="w61b">)</tc:token>
      <tc:token ID="w61c">.</tc:token>
      <tc:token ID="w61d">Problembeschreibung</tc:token>
      <tc:token ID="w61e">Stand</tc:token>
      <tc:token ID="w61f">der</tc:token>
      <tc:token ID="w620">Forschung</tc:token>
      <tc:token ID="w621">Daten</tc:token>
      <tc:token ID="w622">und</tc:token>
      <tc:token ID="w623">Annotation</tc:token>
      <tc:token ID="w624">Tab.</tc:token>
      <tc:token ID="w625">1</tc:token>
      <tc:token ID="w626">:</tc:token>
      <tc:token ID="w627">Überblick</tc:token>
      <tc:token ID="w628">über</tc:token>
      <tc:token ID="w629">die</tc:token>
      <tc:token ID="w62a">Auftrennung</tc:token>
      <tc:token ID="w62b">des</tc:token>
      <tc:token ID="w62c">in</tc:token>
      <tc:token ID="w62d">dieser</tc:token>
      <tc:token ID="w62e">Arbeit</tc:token>
      <tc:token ID="w62f">verwendeten</tc:token>
      <tc:token ID="w630">Korpus</tc:token>
      <tc:token ID="w631">.</tc:token>
      <tc:token ID="w632">Methoden</tc:token>
      <tc:token ID="w633">Evaluation</tc:token>
      <tc:token ID="w634">Tab.</tc:token>
      <tc:token ID="w635">2</tc:token>
      <tc:token ID="w636">:</tc:token>
      <tc:token ID="w637">Ergebnisse</tc:token>
      <tc:token ID="w638">der</tc:token>
      <tc:token ID="w639">einzelnen</tc:token>
      <tc:token ID="w63a">Verfahren</tc:token>
      <tc:token ID="w63b">auf</tc:token>
      <tc:token ID="w63c">dem</tc:token>
      <tc:token ID="w63d">Testkorpus</tc:token>
      <tc:token ID="w63e">,</tc:token>
      <tc:token ID="w63f">bestehend</tc:token>
      <tc:token ID="w640">aus</tc:token>
      <tc:token ID="w641">20</tc:token>
      <tc:token ID="w642">zufällig</tc:token>
      <tc:token ID="w643">gewählten</tc:token>
      <tc:token ID="w644">Romanfragmenten</tc:token>
      <tc:token ID="w645">.</tc:token>
      <tc:token ID="w646">Diskussion</tc:token>
      <tc:token ID="w647">und</tc:token>
      <tc:token ID="w648">Ausblick</tc:token>
      <tc:token ID="w649">Anhang</tc:token>
      <tc:token ID="w64a">Featurebeschrei-bung</tc:token>
      <tc:token ID="w64b">(</tc:token>
      <tc:token ID="w64c">zwischen</tc:token>
      <tc:token ID="w64d">Kandidat</tc:token>
      <tc:token ID="w64e">und</tc:token>
      <tc:token ID="w64f">direkten</tc:token>
      <tc:token ID="w650">Rede</tc:token>
      <tc:token ID="w651">)</tc:token>
      <tc:token ID="w652">Verwendung</tc:token>
      <tc:token ID="w653">für</tc:token>
      <tc:token ID="w654">Sprecherzuord-nung</tc:token>
      <tc:token ID="w655">Zuordnung</tc:token>
      <tc:token ID="w656">des</tc:token>
      <tc:token ID="w657">Angesprochenen</tc:token>
      <tc:token ID="w658">1.</tc:token>
      <tc:token ID="w659">Ist</tc:token>
      <tc:token ID="w65a">der</tc:token>
      <tc:token ID="w65b">Kandidat</tc:token>
      <tc:token ID="w65c">Subjekt</tc:token>
      <tc:token ID="w65d">+</tc:token>
      <tc:token ID="w65e">-</tc:token>
      <tc:token ID="w65f">2</tc:token>
      <tc:token ID="w660">.</tc:token>
      <tc:token ID="w661">Das</tc:token>
      <tc:token ID="w662">Verb</tc:token>
      <tc:token ID="w663">in</tc:token>
      <tc:token ID="w664">der</tc:token>
      <tc:token ID="w665">Dependenzstruk-tur</tc:token>
      <tc:token ID="w666">,</tc:token>
      <tc:token ID="w667">auf</tc:token>
      <tc:token ID="w668">das</tc:token>
      <tc:token ID="w669">sich</tc:token>
      <tc:token ID="w66a">der</tc:token>
      <tc:token ID="w66b">Kandidat</tc:token>
      <tc:token ID="w66c">bezieht</tc:token>
      <tc:token ID="w66d">+</tc:token>
      <tc:token ID="w66e">+</tc:token>
      <tc:token ID="w66f">3</tc:token>
      <tc:token ID="w670">.</tc:token>
      <tc:token ID="w671">Das</tc:token>
      <tc:token ID="w672">POS-Tag</tc:token>
      <tc:token ID="w673">des</tc:token>
      <tc:token ID="w674">Kandidaten</tc:token>
      <tc:token ID="w675">-</tc:token>
      <tc:token ID="w676">-</tc:token>
      <tc:token ID="w677">4.</tc:token>
      <tc:token ID="w678">Ist</tc:token>
      <tc:token ID="w679">der</tc:token>
      <tc:token ID="w67a">Kandidat</tc:token>
      <tc:token ID="w67b">ein</tc:token>
      <tc:token ID="w67c">Pronomen</tc:token>
      <tc:token ID="w67d">-</tc:token>
      <tc:token ID="w67e">-</tc:token>
      <tc:token ID="w67f">5-6</tc:token>
      <tc:token ID="w680">.</tc:token>
      <tc:token ID="w681">Befindet</tc:token>
      <tc:token ID="w682">sich</tc:token>
      <tc:token ID="w683">der</tc:token>
      <tc:token ID="w684">Kandidat</tc:token>
      <tc:token ID="w685">im</tc:token>
      <tc:token ID="w686">Akkusativ/</tc:token>
      <tc:token ID="w687">Dativ</tc:token>
      <tc:token ID="w688">+</tc:token>
      <tc:token ID="w689">/+</tc:token>
      <tc:token ID="w68a">+</tc:token>
      <tc:token ID="w68b">/+</tc:token>
      <tc:token ID="w68c">7.</tc:token>
      <tc:token ID="w68d">Kandidat</tc:token>
      <tc:token ID="w68e">befindet</tc:token>
      <tc:token ID="w68f">sich</tc:token>
      <tc:token ID="w690">in</tc:token>
      <tc:token ID="w691">einer</tc:token>
      <tc:token ID="w692">direkten</tc:token>
      <tc:token ID="w693">Rede</tc:token>
      <tc:token ID="w694">+</tc:token>
      <tc:token ID="w695">-</tc:token>
      <tc:token ID="w696">8.</tc:token>
      <tc:token ID="w697">Kandidat</tc:token>
      <tc:token ID="w698">erscheint</tc:token>
      <tc:token ID="w699">in</tc:token>
      <tc:token ID="w69a">der</tc:token>
      <tc:token ID="w69b">aktuellen</tc:token>
      <tc:token ID="w69c">direkten</tc:token>
      <tc:token ID="w69d">Rede</tc:token>
      <tc:token ID="w69e">-</tc:token>
      <tc:token ID="w69f">-</tc:token>
      <tc:token ID="w6a0">9.</tc:token>
      <tc:token ID="w6a1">Kandidat</tc:token>
      <tc:token ID="w6a2">befindet</tc:token>
      <tc:token ID="w6a3">sich</tc:token>
      <tc:token ID="w6a4">im</tc:token>
      <tc:token ID="w6a5">selben</tc:token>
      <tc:token ID="w6a6">Satz</tc:token>
      <tc:token ID="w6a7">wie</tc:token>
      <tc:token ID="w6a8">die</tc:token>
      <tc:token ID="w6a9">direkte</tc:token>
      <tc:token ID="w6aa">Rede</tc:token>
      <tc:token ID="w6ab">+</tc:token>
      <tc:token ID="w6ac">-</tc:token>
      <tc:token ID="w6ad">10</tc:token>
      <tc:token ID="w6ae">.</tc:token>
      <tc:token ID="w6af">Die</tc:token>
      <tc:token ID="w6b0">Direkte</tc:token>
      <tc:token ID="w6b1">Rede</tc:token>
      <tc:token ID="w6b2">beginnt</tc:token>
      <tc:token ID="w6b3">mit</tc:token>
      <tc:token ID="w6b4">einem</tc:token>
      <tc:token ID="w6b5">kleingeschriebe-nem</tc:token>
      <tc:token ID="w6b6">Wort</tc:token>
      <tc:token ID="w6b7">+</tc:token>
      <tc:token ID="w6b8">-</tc:token>
      <tc:token ID="w6b9">11</tc:token>
      <tc:token ID="w6ba">.</tc:token>
      <tc:token ID="w6bb">Zwischen</tc:token>
      <tc:token ID="w6bc">Kandidat</tc:token>
      <tc:token ID="w6bd">und</tc:token>
      <tc:token ID="w6be">direkter</tc:token>
      <tc:token ID="w6bf">Rede</tc:token>
      <tc:token ID="w6c0">befindet</tc:token>
      <tc:token ID="w6c1">sich</tc:token>
      <tc:token ID="w6c2">ein</tc:token>
      <tc:token ID="w6c3">Doppelpunkt</tc:token>
      <tc:token ID="w6c4">-</tc:token>
      <tc:token ID="w6c5">-</tc:token>
      <tc:token ID="w6c6">12-14.</tc:token>
      <tc:token ID="w6c7">Distanz</tc:token>
      <tc:token ID="w6c8">zw</tc:token>
      <tc:token ID="w6c9">.</tc:token>
      <tc:token ID="w6ca">Kandidat</tc:token>
      <tc:token ID="w6cb">und</tc:token>
      <tc:token ID="w6cc">direkter</tc:token>
      <tc:token ID="w6cd">Rede</tc:token>
      <tc:token ID="w6ce">in</tc:token>
      <tc:token ID="w6cf">Sätze/Wörter/Entitäten</tc:token>
      <tc:token ID="w6d0">-</tc:token>
      <tc:token ID="w6d1">/-</tc:token>
      <tc:token ID="w6d2">/+</tc:token>
      <tc:token ID="w6d3">-</tc:token>
      <tc:token ID="w6d4">/-</tc:token>
      <tc:token ID="w6d5">/-</tc:token>
      <tc:token ID="w6d6">15-16</tc:token>
      <tc:token ID="w6d7">.</tc:token>
      <tc:token ID="w6d8">Wort</tc:token>
      <tc:token ID="w6d9">an</tc:token>
      <tc:token ID="w6da">Position</tc:token>
      <tc:token ID="w6db">+1</tc:token>
      <tc:token ID="w6dc">/-1</tc:token>
      <tc:token ID="w6dd">-</tc:token>
      <tc:token ID="w6de">/-</tc:token>
      <tc:token ID="w6df">-</tc:token>
      <tc:token ID="w6e0">/-</tc:token>
      <tc:token ID="w6e1">17-18</tc:token>
      <tc:token ID="w6e2">.</tc:token>
      <tc:token ID="w6e3">Wort</tc:token>
      <tc:token ID="w6e4">an</tc:token>
      <tc:token ID="w6e5">Position</tc:token>
      <tc:token ID="w6e6">+1</tc:token>
      <tc:token ID="w6e7">/-1</tc:token>
      <tc:token ID="w6e8">ist</tc:token>
      <tc:token ID="w6e9">Satzzeichen</tc:token>
      <tc:token ID="w6ea">+</tc:token>
      <tc:token ID="w6eb">/+</tc:token>
      <tc:token ID="w6ec">-</tc:token>
      <tc:token ID="w6ed">/-</tc:token>
      <tc:token ID="w6ee">19-20</tc:token>
      <tc:token ID="w6ef">.</tc:token>
      <tc:token ID="w6f0">Wort</tc:token>
      <tc:token ID="w6f1">an</tc:token>
      <tc:token ID="w6f2">Position</tc:token>
      <tc:token ID="w6f3">+1</tc:token>
      <tc:token ID="w6f4">/-1</tc:token>
      <tc:token ID="w6f5">ist</tc:token>
      <tc:token ID="w6f6">in</tc:token>
      <tc:token ID="w6f7">direkter</tc:token>
      <tc:token ID="w6f8">Rede</tc:token>
      <tc:token ID="w6f9">+</tc:token>
      <tc:token ID="w6fa">/+</tc:token>
      <tc:token ID="w6fb">-</tc:token>
      <tc:token ID="w6fc">/-</tc:token>
      <tc:token ID="w6fd">19-20</tc:token>
      <tc:token ID="w6fe">.</tc:token>
      <tc:token ID="w6ff">Kandidat</tc:token>
      <tc:token ID="w700">ist</tc:token>
      <tc:token ID="w701">Sprecher</tc:token>
      <tc:token ID="w702">der</tc:token>
      <tc:token ID="w703">direkten</tc:token>
      <tc:token ID="w704">Rede</tc:token>
      <tc:token ID="w705">an</tc:token>
      <tc:token ID="w706">Position</tc:token>
      <tc:token ID="w707">-1</tc:token>
      <tc:token ID="w708">/-2</tc:token>
      <tc:token ID="w709">-</tc:token>
      <tc:token ID="w70a">/-</tc:token>
      <tc:token ID="w70b">+</tc:token>
      <tc:token ID="w70c">/-</tc:token>
      <tc:token ID="w70d">21-22</tc:token>
      <tc:token ID="w70e">.</tc:token>
      <tc:token ID="w70f">Kandidat</tc:token>
      <tc:token ID="w710">ist</tc:token>
      <tc:token ID="w711">Angesprochener</tc:token>
      <tc:token ID="w712">der</tc:token>
      <tc:token ID="w713">direkten</tc:token>
      <tc:token ID="w714">Rede</tc:token>
      <tc:token ID="w715">an</tc:token>
      <tc:token ID="w716">Position</tc:token>
      <tc:token ID="w717">-1</tc:token>
      <tc:token ID="w718">/-2</tc:token>
      <tc:token ID="w719">-</tc:token>
      <tc:token ID="w71a">/-</tc:token>
      <tc:token ID="w71b">-</tc:token>
      <tc:token ID="w71c">/-</tc:token>
      <tc:token ID="w71d">Regelbezeichnung</tc:token>
      <tc:token ID="w71e">Regelbeschreibung</tc:token>
      <tc:token ID="w71f">(</tc:token>
      <tc:token ID="w720">1</tc:token>
      <tc:token ID="w721">)</tc:token>
      <tc:token ID="w722">Explizite</tc:token>
      <tc:token ID="w723">Sprechererkennung</tc:token>
      <tc:token ID="w724">Nutzt</tc:token>
      <tc:token ID="w725">Pattern-Matching</tc:token>
      <tc:token ID="w726">und</tc:token>
      <tc:token ID="w727">grammatikalische</tc:token>
      <tc:token ID="w728">Regeln</tc:token>
      <tc:token ID="w729">um</tc:token>
      <tc:token ID="w72a">explizite</tc:token>
      <tc:token ID="w72b">Erwähnungen</tc:token>
      <tc:token ID="w72c">eines</tc:token>
      <tc:token ID="w72d">Sprechers</tc:token>
      <tc:token ID="w72e">im</tc:token>
      <tc:token ID="w72f">direkten</tc:token>
      <tc:token ID="w730">Umfeld</tc:token>
      <tc:token ID="w731">einer</tc:token>
      <tc:token ID="w732">direkten</tc:token>
      <tc:token ID="w733">Rede</tc:token>
      <tc:token ID="w734">zu</tc:token>
      <tc:token ID="w735">erkennen</tc:token>
      <tc:token ID="w736">.</tc:token>
      <tc:token ID="w737">(</tc:token>
      <tc:token ID="w738">2</tc:token>
      <tc:token ID="w739">)</tc:token>
      <tc:token ID="w73a">Explizite</tc:token>
      <tc:token ID="w73b">Erkennung</tc:token>
      <tc:token ID="w73c">des</tc:token>
      <tc:token ID="w73d">Angesprochenen</tc:token>
      <tc:token ID="w73e">Nutzt</tc:token>
      <tc:token ID="w73f">Pattern-Matching</tc:token>
      <tc:token ID="w740">und</tc:token>
      <tc:token ID="w741">grammatikalische</tc:token>
      <tc:token ID="w742">Regeln</tc:token>
      <tc:token ID="w743">um</tc:token>
      <tc:token ID="w744">explizite</tc:token>
      <tc:token ID="w745">Erwähnungen</tc:token>
      <tc:token ID="w746">eines</tc:token>
      <tc:token ID="w747">Angesprochenen</tc:token>
      <tc:token ID="w748">innerhalb</tc:token>
      <tc:token ID="w749">der</tc:token>
      <tc:token ID="w74a">direkten</tc:token>
      <tc:token ID="w74b">Rede</tc:token>
      <tc:token ID="w74c">zu</tc:token>
      <tc:token ID="w74d">erkennen</tc:token>
      <tc:token ID="w74e">.</tc:token>
      <tc:token ID="w74f">(</tc:token>
      <tc:token ID="w750">3</tc:token>
      <tc:token ID="w751">)</tc:token>
      <tc:token ID="w752">Explizite</tc:token>
      <tc:token ID="w753">Erkennung</tc:token>
      <tc:token ID="w754">des</tc:token>
      <tc:token ID="w755">Angesprochenen</tc:token>
      <tc:token ID="w756">II</tc:token>
      <tc:token ID="w757">Wie</tc:token>
      <tc:token ID="w758">(</tc:token>
      <tc:token ID="w759">1</tc:token>
      <tc:token ID="w75a">)</tc:token>
      <tc:token ID="w75b">nur</tc:token>
      <tc:token ID="w75c">für</tc:token>
      <tc:token ID="w75d">den</tc:token>
      <tc:token ID="w75e">Angesprochenen</tc:token>
      <tc:token ID="w75f">(</tc:token>
      <tc:token ID="w760">4</tc:token>
      <tc:token ID="w761">)</tc:token>
      <tc:token ID="w762">Explizite</tc:token>
      <tc:token ID="w763">Sprechererkennung</tc:token>
      <tc:token ID="w764">II</tc:token>
      <tc:token ID="w765">Wie</tc:token>
      <tc:token ID="w766">(</tc:token>
      <tc:token ID="w767">1</tc:token>
      <tc:token ID="w768">)</tc:token>
      <tc:token ID="w769">,</tc:token>
      <tc:token ID="w76a">nur</tc:token>
      <tc:token ID="w76b">der</tc:token>
      <tc:token ID="w76c">Kontext</tc:token>
      <tc:token ID="w76d">wird</tc:token>
      <tc:token ID="w76e">um</tc:token>
      <tc:token ID="w76f">1</tc:token>
      <tc:token ID="w770">Satz</tc:token>
      <tc:token ID="w771">außerhalb</tc:token>
      <tc:token ID="w772">der</tc:token>
      <tc:token ID="w773">direkten</tc:token>
      <tc:token ID="w774">Rede</tc:token>
      <tc:token ID="w775">erweitert</tc:token>
      <tc:token ID="w776">.</tc:token>
      <tc:token ID="w777">(</tc:token>
      <tc:token ID="w778">5</tc:token>
      <tc:token ID="w779">)</tc:token>
      <tc:token ID="w77a">Vorwärtspropagierung</tc:token>
      <tc:token ID="w77b">Zwei</tc:token>
      <tc:token ID="w77c">direkt</tc:token>
      <tc:token ID="w77d">aufeinanderfolgenden</tc:token>
      <tc:token ID="w77e">direkten</tc:token>
      <tc:token ID="w77f">Reden</tc:token>
      <tc:token ID="w780">wird</tc:token>
      <tc:token ID="w781">der</tc:token>
      <tc:token ID="w782">Sprecher/Angesprochener</tc:token>
      <tc:token ID="w783">der</tc:token>
      <tc:token ID="w784">ersten</tc:token>
      <tc:token ID="w785">direkten</tc:token>
      <tc:token ID="w786">Rede</tc:token>
      <tc:token ID="w787">zugeordnet</tc:token>
      <tc:token ID="w788">,</tc:token>
      <tc:token ID="w789">wenn</tc:token>
      <tc:token ID="w78a">beide</tc:token>
      <tc:token ID="w78b">direkte</tc:token>
      <tc:token ID="w78c">Reden</tc:token>
      <tc:token ID="w78d">innerhalb</tc:token>
      <tc:token ID="w78e">des</tc:token>
      <tc:token ID="w78f">selben</tc:token>
      <tc:token ID="w790">Satzes</tc:token>
      <tc:token ID="w791">liegen</tc:token>
      <tc:token ID="w792">(</tc:token>
      <tc:token ID="w793">6</tc:token>
      <tc:token ID="w794">)</tc:token>
      <tc:token ID="w795">Rückwärtspropagierung</tc:token>
      <tc:token ID="w796">wie</tc:token>
      <tc:token ID="w797">(</tc:token>
      <tc:token ID="w798">5</tc:token>
      <tc:token ID="w799">)</tc:token>
      <tc:token ID="w79a">nur</tc:token>
      <tc:token ID="w79b">mit</tc:token>
      <tc:token ID="w79c">entgegengesetzter</tc:token>
      <tc:token ID="w79d">Richtung</tc:token>
      <tc:token ID="w79e">der</tc:token>
      <tc:token ID="w79f">Ausführung</tc:token>
      <tc:token ID="w7a0">(</tc:token>
      <tc:token ID="w7a1">7</tc:token>
      <tc:token ID="w7a2">)</tc:token>
      <tc:token ID="w7a3">Nachbarschafts-propagierung</tc:token>
      <tc:token ID="w7a4">Direkten</tc:token>
      <tc:token ID="w7a5">Reden</tc:token>
      <tc:token ID="w7a6">,</tc:token>
      <tc:token ID="w7a7">die</tc:token>
      <tc:token ID="w7a8">keinen</tc:token>
      <tc:token ID="w7a9">eingeschobenen</tc:token>
      <tc:token ID="w7aa">Kontext</tc:token>
      <tc:token ID="w7ab">aufzeigen</tc:token>
      <tc:token ID="w7ac">,</tc:token>
      <tc:token ID="w7ad">wechseln</tc:token>
      <tc:token ID="w7ae">den</tc:token>
      <tc:token ID="w7af">Sprecher/Angesprochenen</tc:token>
      <tc:token ID="w7b0">(</tc:token>
      <tc:token ID="w7b1">falls</tc:token>
      <tc:token ID="w7b2">vorhanden</tc:token>
      <tc:token ID="w7b3">)</tc:token>
      <tc:token ID="w7b4">(</tc:token>
      <tc:token ID="w7b5">8</tc:token>
      <tc:token ID="w7b6">)</tc:token>
      <tc:token ID="w7b7">Fragenpropagierung</tc:token>
      <tc:token ID="w7b8">Nach</tc:token>
      <tc:token ID="w7b9">einer</tc:token>
      <tc:token ID="w7ba">Frage</tc:token>
      <tc:token ID="w7bb">wechseln</tc:token>
      <tc:token ID="w7bc">Sprecher/Angesprochener</tc:token>
      <tc:token ID="w7bd">(</tc:token>
      <tc:token ID="w7be">9</tc:token>
      <tc:token ID="w7bf">)</tc:token>
      <tc:token ID="w7c0">Dialogpropagierung</tc:token>
      <tc:token ID="w7c1">Direkte</tc:token>
      <tc:token ID="w7c2">Rede</tc:token>
      <tc:token ID="w7c3">mit</tc:token>
      <tc:token ID="w7c4">maximal</tc:token>
      <tc:token ID="w7c5">einem</tc:token>
      <tc:token ID="w7c6">zwischenliegenden</tc:token>
      <tc:token ID="w7c7">Satz</tc:token>
      <tc:token ID="w7c8">wechseln</tc:token>
      <tc:token ID="w7c9">ihren</tc:token>
      <tc:token ID="w7ca">Sprecher/Angesprochenen</tc:token>
      <tc:token ID="w7cb">(</tc:token>
      <tc:token ID="w7cc">10</tc:token>
      <tc:token ID="w7cd">)</tc:token>
      <tc:token ID="w7ce">Default-Sprecher</tc:token>
      <tc:token ID="w7cf">/</tc:token>
      <tc:token ID="w7d0">Angesprochener</tc:token>
      <tc:token ID="w7d1">Als</tc:token>
      <tc:token ID="w7d2">Sprecher</tc:token>
      <tc:token ID="w7d3">wird</tc:token>
      <tc:token ID="w7d4">das</tc:token>
      <tc:token ID="w7d5">letzte</tc:token>
      <tc:token ID="w7d6">Subjekt</tc:token>
      <tc:token ID="w7d7">außerhalb</tc:token>
      <tc:token ID="w7d8">direkter</tc:token>
      <tc:token ID="w7d9">Reden</tc:token>
      <tc:token ID="w7da">gesetzt</tc:token>
      <tc:token ID="w7db">,</tc:token>
      <tc:token ID="w7dc">als</tc:token>
      <tc:token ID="w7dd">Angesprochener</tc:token>
      <tc:token ID="w7de">das</tc:token>
      <tc:token ID="w7df">letzte</tc:token>
      <tc:token ID="w7e0">Subjekt</tc:token>
      <tc:token ID="w7e1">,</tc:token>
      <tc:token ID="w7e2">das</tc:token>
      <tc:token ID="w7e3">nicht</tc:token>
      <tc:token ID="w7e4">Sprecher</tc:token>
      <tc:token ID="w7e5">der</tc:token>
      <tc:token ID="w7e6">aktuellen</tc:token>
      <tc:token ID="w7e7">direkten</tc:token>
      <tc:token ID="w7e8">Rede</tc:token>
      <tc:token ID="w7e9">ist</tc:token>
      <tc:token ID="w7ea">.</tc:token>
      <tc:token ID="w7eb">Abb.</tc:token>
      <tc:token ID="w7ec">A3</tc:token>
      <tc:token ID="w7ed">:</tc:token>
      <tc:token ID="w7ee">Auszug</tc:token>
      <tc:token ID="w7ef">aus</tc:token>
      <tc:token ID="w7f0">Aston</tc:token>
      <tc:token ID="w7f1">Louise</tc:token>
      <tc:token ID="w7f2">“</tc:token>
      <tc:token ID="w7f3">Lydia</tc:token>
      <tc:token ID="w7f4">”</tc:token>
      <tc:token ID="w7f5">:</tc:token>
      <tc:token ID="w7f6">Beispiel</tc:token>
      <tc:token ID="w7f7">für</tc:token>
      <tc:token ID="w7f8">die</tc:token>
      <tc:token ID="w7f9">Erkennung</tc:token>
      <tc:token ID="w7fa">von</tc:token>
      <tc:token ID="w7fb">Sprecher</tc:token>
      <tc:token ID="w7fc">und</tc:token>
      <tc:token ID="w7fd">Angesprochenem</tc:token>
      <tc:token ID="w7fe">in</tc:token>
      <tc:token ID="w7ff">direkten</tc:token>
      <tc:token ID="w800">Reden</tc:token>
      <tc:token ID="w801">gemäß</tc:token>
      <tc:token ID="w802">den</tc:token>
      <tc:token ID="w803">Regeln</tc:token>
      <tc:token ID="w804">in</tc:token>
      <tc:token ID="w805">Tabelle</tc:token>
      <tc:token ID="w806">A2</tc:token>
      <tc:token ID="w807">.</tc:token>
      <tc:token ID="w808">Im</tc:token>
      <tc:token ID="w809">ersten</tc:token>
      <tc:token ID="w80a">Durchlauf</tc:token>
      <tc:token ID="w80b">wird</tc:token>
      <tc:token ID="w80c">mit</tc:token>
      <tc:token ID="w80d">der</tc:token>
      <tc:token ID="w80e">Regel</tc:token>
      <tc:token ID="w80f">(</tc:token>
      <tc:token ID="w810">1</tc:token>
      <tc:token ID="w811">)</tc:token>
      <tc:token ID="w812">die</tc:token>
      <tc:token ID="w813">Sprecherin</tc:token>
      <tc:token ID="w814">für</tc:token>
      <tc:token ID="w815">die</tc:token>
      <tc:token ID="w816">direkten</tc:token>
      <tc:token ID="w817">Reden</tc:token>
      <tc:token ID="w818">1</tc:token>
      <tc:token ID="w819">und</tc:token>
      <tc:token ID="w81a">5</tc:token>
      <tc:token ID="w81b">erkannt</tc:token>
      <tc:token ID="w81c">.</tc:token>
      <tc:token ID="w81d">Anschließend</tc:token>
      <tc:token ID="w81e">erkennt</tc:token>
      <tc:token ID="w81f">Regel</tc:token>
      <tc:token ID="w820">(</tc:token>
      <tc:token ID="w821">7</tc:token>
      <tc:token ID="w822">)</tc:token>
      <tc:token ID="w823">in</tc:token>
      <tc:token ID="w824">Rückwärtsrichtung</tc:token>
      <tc:token ID="w825">jeweils</tc:token>
      <tc:token ID="w826">abwechselnd</tc:token>
      <tc:token ID="w827">Sprecherin</tc:token>
      <tc:token ID="w828">4</tc:token>
      <tc:token ID="w829">und</tc:token>
      <tc:token ID="w82a">2</tc:token>
      <tc:token ID="w82b">und</tc:token>
      <tc:token ID="w82c">Angesprochene</tc:token>
      <tc:token ID="w82d">in</tc:token>
      <tc:token ID="w82e">3.</tc:token>
      <tc:token ID="w82f">Schließlich</tc:token>
      <tc:token ID="w830">erkennt</tc:token>
      <tc:token ID="w831">Regel</tc:token>
      <tc:token ID="w832">(</tc:token>
      <tc:token ID="w833">7</tc:token>
      <tc:token ID="w834">)</tc:token>
      <tc:token ID="w835">in</tc:token>
      <tc:token ID="w836">Vorwärtsrichtung</tc:token>
      <tc:token ID="w837">die</tc:token>
      <tc:token ID="w838">Sprecherin</tc:token>
      <tc:token ID="w839">in</tc:token>
      <tc:token ID="w83a">3</tc:token>
      <tc:token ID="w83b">und</tc:token>
      <tc:token ID="w83c">die</tc:token>
      <tc:token ID="w83d">Angesprochene</tc:token>
      <tc:token ID="w83e">in</tc:token>
      <tc:token ID="w83f">4</tc:token>
      <tc:token ID="w840">und</tc:token>
      <tc:token ID="w841">2.</tc:token>
      <tc:token ID="w842">Almeida</tc:token>
      <tc:token ID="w843">,</tc:token>
      <tc:token ID="w844">Mariana</tc:token>
      <tc:token ID="w845">S.</tc:token>
      <tc:token ID="w846">C.</tc:token>
      <tc:token ID="w847">/</tc:token>
      <tc:token ID="w848">Almeida</tc:token>
      <tc:token ID="w849">,</tc:token>
      <tc:token ID="w84a">Miguel</tc:token>
      <tc:token ID="w84b">B.</tc:token>
      <tc:token ID="w84c">/</tc:token>
      <tc:token ID="w84d">Martins</tc:token>
      <tc:token ID="w84e">,</tc:token>
      <tc:token ID="w84f">André</tc:token>
      <tc:token ID="w850">F.T.</tc:token>
      <tc:token ID="w851">(</tc:token>
      <tc:token ID="w852">2014</tc:token>
      <tc:token ID="w853">)</tc:token>
      <tc:token ID="w854">:</tc:token>
      <tc:token ID="w855">"</tc:token>
      <tc:token ID="w856">A</tc:token>
      <tc:token ID="w857">joint</tc:token>
      <tc:token ID="w858">model</tc:token>
      <tc:token ID="w859">for</tc:token>
      <tc:token ID="w85a">quotation</tc:token>
      <tc:token ID="w85b">attribution</tc:token>
      <tc:token ID="w85c">and</tc:token>
      <tc:token ID="w85d">coreference</tc:token>
      <tc:token ID="w85e">resolution</tc:token>
      <tc:token ID="w85f">"</tc:token>
      <tc:token ID="w860">,</tc:token>
      <tc:token ID="w861">in</tc:token>
      <tc:token ID="w862">:</tc:token>
      <tc:token ID="w863">Proceedings</tc:token>
      <tc:token ID="w864">of</tc:token>
      <tc:token ID="w865">the</tc:token>
      <tc:token ID="w866">14th</tc:token>
      <tc:token ID="w867">Conference</tc:token>
      <tc:token ID="w868">of</tc:token>
      <tc:token ID="w869">the</tc:token>
      <tc:token ID="w86a">European</tc:token>
      <tc:token ID="w86b">Chapter</tc:token>
      <tc:token ID="w86c">of</tc:token>
      <tc:token ID="w86d">the</tc:token>
      <tc:token ID="w86e">Association</tc:token>
      <tc:token ID="w86f">for</tc:token>
      <tc:token ID="w870">Computational</tc:token>
      <tc:token ID="w871">Linguistics</tc:token>
      <tc:token ID="w872">,</tc:token>
      <tc:token ID="w873">Gothenburg</tc:token>
      <tc:token ID="w874">,</tc:token>
      <tc:token ID="w875">Sweden</tc:token>
      <tc:token ID="w876">39-48</tc:token>
      <tc:token ID="w877">.</tc:token>
      <tc:token ID="w878">Bohnet</tc:token>
      <tc:token ID="w879">,</tc:token>
      <tc:token ID="w87a">Bernd</tc:token>
      <tc:token ID="w87b">/</tc:token>
      <tc:token ID="w87c">Kuhn</tc:token>
      <tc:token ID="w87d">,</tc:token>
      <tc:token ID="w87e">Jonas</tc:token>
      <tc:token ID="w87f">(</tc:token>
      <tc:token ID="w880">2012</tc:token>
      <tc:token ID="w881">)</tc:token>
      <tc:token ID="w882">:</tc:token>
      <tc:token ID="w883">"</tc:token>
      <tc:token ID="w884">The</tc:token>
      <tc:token ID="w885">best</tc:token>
      <tc:token ID="w886">of</tc:token>
      <tc:token ID="w887">both</tc:token>
      <tc:token ID="w888">worlds</tc:token>
      <tc:token ID="w889">:</tc:token>
      <tc:token ID="w88a">a</tc:token>
      <tc:token ID="w88b">graph-based</tc:token>
      <tc:token ID="w88c">completion</tc:token>
      <tc:token ID="w88d">model</tc:token>
      <tc:token ID="w88e">for</tc:token>
      <tc:token ID="w88f">transition-based</tc:token>
      <tc:token ID="w890">parsers</tc:token>
      <tc:token ID="w891">.</tc:token>
      <tc:token ID="w892">"</tc:token>
      <tc:token ID="w893">In</tc:token>
      <tc:token ID="w894">:</tc:token>
      <tc:token ID="w895">Proceedings</tc:token>
      <tc:token ID="w896">of</tc:token>
      <tc:token ID="w897">the</tc:token>
      <tc:token ID="w898">13th</tc:token>
      <tc:token ID="w899">Conference</tc:token>
      <tc:token ID="w89a">of</tc:token>
      <tc:token ID="w89b">the</tc:token>
      <tc:token ID="w89c">European</tc:token>
      <tc:token ID="w89d">Chapter</tc:token>
      <tc:token ID="w89e">of</tc:token>
      <tc:token ID="w89f">the</tc:token>
      <tc:token ID="w8a0">Association</tc:token>
      <tc:token ID="w8a1">for</tc:token>
      <tc:token ID="w8a2">Computational</tc:token>
      <tc:token ID="w8a3">Linguistics</tc:token>
      <tc:token ID="w8a4">.</tc:token>
      <tc:token ID="w8a5">Avignon</tc:token>
      <tc:token ID="w8a6">,</tc:token>
      <tc:token ID="w8a7">France</tc:token>
      <tc:token ID="w8a8">:</tc:token>
      <tc:token ID="w8a9">77-87</tc:token>
      <tc:token ID="w8aa">.</tc:token>
      <tc:token ID="w8ab">Chaganty</tc:token>
      <tc:token ID="w8ac">,</tc:token>
      <tc:token ID="w8ad">Arun</tc:token>
      <tc:token ID="w8ae">/</tc:token>
      <tc:token ID="w8af">Muzny</tc:token>
      <tc:token ID="w8b0">,</tc:token>
      <tc:token ID="w8b1">Grace</tc:token>
      <tc:token ID="w8b2">(</tc:token>
      <tc:token ID="w8b3">2015</tc:token>
      <tc:token ID="w8b4">)</tc:token>
      <tc:token ID="w8b5">:</tc:token>
      <tc:token ID="w8b6">Quote</tc:token>
      <tc:token ID="w8b7">Attribution</tc:token>
      <tc:token ID="w8b8">for</tc:token>
      <tc:token ID="w8b9">Literary</tc:token>
      <tc:token ID="w8ba">Text</tc:token>
      <tc:token ID="w8bb">with</tc:token>
      <tc:token ID="w8bc">Neural</tc:token>
      <tc:token ID="w8bd">Networks</tc:token>
      <tc:token ID="w8be">https://cs224d.stanford.edu/reports/ChagantyArun.pdf</tc:token>
      <tc:token ID="w8bf">[</tc:token>
      <tc:token ID="w8c0">letzter</tc:token>
      <tc:token ID="w8c1">Zugriff</tc:token>
      <tc:token ID="w8c2">08.</tc:token>
      <tc:token ID="w8c3">Februar</tc:token>
      <tc:token ID="w8c4">2016</tc:token>
      <tc:token ID="w8c5">]</tc:token>
      <tc:token ID="w8c6">.</tc:token>
      <tc:token ID="w8c7">Celikyilmaz</tc:token>
      <tc:token ID="w8c8">,</tc:token>
      <tc:token ID="w8c9">Asli</tc:token>
      <tc:token ID="w8ca">/</tc:token>
      <tc:token ID="w8cb">Hakkani-Tur</tc:token>
      <tc:token ID="w8cc">,</tc:token>
      <tc:token ID="w8cd">Dilek</tc:token>
      <tc:token ID="w8ce">/</tc:token>
      <tc:token ID="w8cf">He</tc:token>
      <tc:token ID="w8d0">,</tc:token>
      <tc:token ID="w8d1">Hua</tc:token>
      <tc:token ID="w8d2">/</tc:token>
      <tc:token ID="w8d3">Kondrak</tc:token>
      <tc:token ID="w8d4">,</tc:token>
      <tc:token ID="w8d5">Greg</tc:token>
      <tc:token ID="w8d6">/</tc:token>
      <tc:token ID="w8d7">Barbosa</tc:token>
      <tc:token ID="w8d8">,</tc:token>
      <tc:token ID="w8d9">Denilson</tc:token>
      <tc:token ID="w8da">(</tc:token>
      <tc:token ID="w8db">2010</tc:token>
      <tc:token ID="w8dc">)</tc:token>
      <tc:token ID="w8dd">:</tc:token>
      <tc:token ID="w8de">"</tc:token>
      <tc:token ID="w8df">The</tc:token>
      <tc:token ID="w8e0">actortopic</tc:token>
      <tc:token ID="w8e1">model</tc:token>
      <tc:token ID="w8e2">for</tc:token>
      <tc:token ID="w8e3">extracting</tc:token>
      <tc:token ID="w8e4">social</tc:token>
      <tc:token ID="w8e5">networks</tc:token>
      <tc:token ID="w8e6">in</tc:token>
      <tc:token ID="w8e7">literary</tc:token>
      <tc:token ID="w8e8">narrative</tc:token>
      <tc:token ID="w8e9">.</tc:token>
      <tc:token ID="w8ea">"</tc:token>
      <tc:token ID="w8eb">,</tc:token>
      <tc:token ID="w8ec">in</tc:token>
      <tc:token ID="w8ed">:</tc:token>
      <tc:token ID="w8ee">Proceedings</tc:token>
      <tc:token ID="w8ef">of</tc:token>
      <tc:token ID="w8f0">the</tc:token>
      <tc:token ID="w8f1">NIPS</tc:token>
      <tc:token ID="w8f2">2010</tc:token>
      <tc:token ID="w8f3">Workshop</tc:token>
      <tc:token ID="w8f4">Machine</tc:token>
      <tc:token ID="w8f5">Learning</tc:token>
      <tc:token ID="w8f6">for</tc:token>
      <tc:token ID="w8f7">Social</tc:token>
      <tc:token ID="w8f8">Computing</tc:token>
      <tc:token ID="w8f9">https://webdocs.cs.ualberta.ca/~denilson/files/publications/nips2010.pdf</tc:token>
      <tc:token ID="w8fa">[</tc:token>
      <tc:token ID="w8fb">letzter</tc:token>
      <tc:token ID="w8fc">Zugriff</tc:token>
      <tc:token ID="w8fd">08.</tc:token>
      <tc:token ID="w8fe">Februar</tc:token>
      <tc:token ID="w8ff">2016</tc:token>
      <tc:token ID="w900">]</tc:token>
      <tc:token ID="w901">.</tc:token>
      <tc:token ID="w902">Elson</tc:token>
      <tc:token ID="w903">,</tc:token>
      <tc:token ID="w904">David</tc:token>
      <tc:token ID="w905">K.</tc:token>
      <tc:token ID="w906">/</tc:token>
      <tc:token ID="w907">Dames</tc:token>
      <tc:token ID="w908">,</tc:token>
      <tc:token ID="w909">Nicholas</tc:token>
      <tc:token ID="w90a">/</tc:token>
      <tc:token ID="w90b">McKeown</tc:token>
      <tc:token ID="w90c">,</tc:token>
      <tc:token ID="w90d">Kathleen</tc:token>
      <tc:token ID="w90e">R.</tc:token>
      <tc:token ID="w90f">(</tc:token>
      <tc:token ID="w910">2010a</tc:token>
      <tc:token ID="w911">)</tc:token>
      <tc:token ID="w912">:</tc:token>
      <tc:token ID="w913">"</tc:token>
      <tc:token ID="w914">Extracting</tc:token>
      <tc:token ID="w915">social</tc:token>
      <tc:token ID="w916">networks</tc:token>
      <tc:token ID="w917">from</tc:token>
      <tc:token ID="w918">literary</tc:token>
      <tc:token ID="w919">fiction</tc:token>
      <tc:token ID="w91a">"</tc:token>
      <tc:token ID="w91b">,</tc:token>
      <tc:token ID="w91c">in</tc:token>
      <tc:token ID="w91d">:</tc:token>
      <tc:token ID="w91e">Proceedings</tc:token>
      <tc:token ID="w91f">of</tc:token>
      <tc:token ID="w920">the</tc:token>
      <tc:token ID="w921">48th</tc:token>
      <tc:token ID="w922">annual</tc:token>
      <tc:token ID="w923">meeting</tc:token>
      <tc:token ID="w924">of</tc:token>
      <tc:token ID="w925">the</tc:token>
      <tc:token ID="w926">association</tc:token>
      <tc:token ID="w927">for</tc:token>
      <tc:token ID="w928">computational</tc:token>
      <tc:token ID="w929">linguistics</tc:token>
      <tc:token ID="w92a">.</tc:token>
      <tc:token ID="w92b">Association</tc:token>
      <tc:token ID="w92c">for</tc:token>
      <tc:token ID="w92d">Computational</tc:token>
      <tc:token ID="w92e">Linguistics</tc:token>
      <tc:token ID="w92f">http://www1.cs.columbia.edu/~delson/pubs/ACL2010-ElsonDamesMcKeown.pdf</tc:token>
      <tc:token ID="w930">[</tc:token>
      <tc:token ID="w931">letzter</tc:token>
      <tc:token ID="w932">Zugriff</tc:token>
      <tc:token ID="w933">08.</tc:token>
      <tc:token ID="w934">Februar</tc:token>
      <tc:token ID="w935">2016</tc:token>
      <tc:token ID="w936">]</tc:token>
      <tc:token ID="w937">.</tc:token>
      <tc:token ID="w938">Elson</tc:token>
      <tc:token ID="w939">,</tc:token>
      <tc:token ID="w93a">David</tc:token>
      <tc:token ID="w93b">K.</tc:token>
      <tc:token ID="w93c">/</tc:token>
      <tc:token ID="w93d">McKeown</tc:token>
      <tc:token ID="w93e">,</tc:token>
      <tc:token ID="w93f">Kathleen</tc:token>
      <tc:token ID="w940">R.</tc:token>
      <tc:token ID="w941">(</tc:token>
      <tc:token ID="w942">2010b</tc:token>
      <tc:token ID="w943">)</tc:token>
      <tc:token ID="w944">:</tc:token>
      <tc:token ID="w945">"</tc:token>
      <tc:token ID="w946">Automatic</tc:token>
      <tc:token ID="w947">Attribution</tc:token>
      <tc:token ID="w948">of</tc:token>
      <tc:token ID="w949">Quoted</tc:token>
      <tc:token ID="w94a">Speech</tc:token>
      <tc:token ID="w94b">in</tc:token>
      <tc:token ID="w94c">Literary</tc:token>
      <tc:token ID="w94d">Narrative</tc:token>
      <tc:token ID="w94e">"</tc:token>
      <tc:token ID="w94f">,</tc:token>
      <tc:token ID="w950">in</tc:token>
      <tc:token ID="w951">:</tc:token>
      <tc:token ID="w952">Proceedings</tc:token>
      <tc:token ID="w953">of</tc:token>
      <tc:token ID="w954">AAAI</tc:token>
      <tc:token ID="w955">1013-1019</tc:token>
      <tc:token ID="w956">.</tc:token>
      <tc:token ID="w957">Glass</tc:token>
      <tc:token ID="w958">,</tc:token>
      <tc:token ID="w959">Kevin</tc:token>
      <tc:token ID="w95a">/</tc:token>
      <tc:token ID="w95b">Bangay</tc:token>
      <tc:token ID="w95c">,</tc:token>
      <tc:token ID="w95d">Shaun</tc:token>
      <tc:token ID="w95e">(</tc:token>
      <tc:token ID="w95f">2006</tc:token>
      <tc:token ID="w960">)</tc:token>
      <tc:token ID="w961">:</tc:token>
      <tc:token ID="w962">"</tc:token>
      <tc:token ID="w963">Hierarchical</tc:token>
      <tc:token ID="w964">rule</tc:token>
      <tc:token ID="w965">generalisation</tc:token>
      <tc:token ID="w966">for</tc:token>
      <tc:token ID="w967">speaker</tc:token>
      <tc:token ID="w968">identification</tc:token>
      <tc:token ID="w969">in</tc:token>
      <tc:token ID="w96a">fiction</tc:token>
      <tc:token ID="w96b">books</tc:token>
      <tc:token ID="w96c">"</tc:token>
      <tc:token ID="w96d">,</tc:token>
      <tc:token ID="w96e">in</tc:token>
      <tc:token ID="w96f">:</tc:token>
      <tc:token ID="w970">Proceedings</tc:token>
      <tc:token ID="w971">of</tc:token>
      <tc:token ID="w972">the</tc:token>
      <tc:token ID="w973">2006</tc:token>
      <tc:token ID="w974">annual</tc:token>
      <tc:token ID="w975">research</tc:token>
      <tc:token ID="w976">conference</tc:token>
      <tc:token ID="w977">of</tc:token>
      <tc:token ID="w978">the</tc:token>
      <tc:token ID="w979">South</tc:token>
      <tc:token ID="w97a">African</tc:token>
      <tc:token ID="w97b">institute</tc:token>
      <tc:token ID="w97c">of</tc:token>
      <tc:token ID="w97d">computer</tc:token>
      <tc:token ID="w97e">scientists</tc:token>
      <tc:token ID="w97f">and</tc:token>
      <tc:token ID="w980">information</tc:token>
      <tc:token ID="w981">technologists</tc:token>
      <tc:token ID="w982">on</tc:token>
      <tc:token ID="w983">IT</tc:token>
      <tc:token ID="w984">research</tc:token>
      <tc:token ID="w985">in</tc:token>
      <tc:token ID="w986">developing</tc:token>
      <tc:token ID="w987">countries</tc:token>
      <tc:token ID="w988">.</tc:token>
      <tc:token ID="w989">South</tc:token>
      <tc:token ID="w98a">African</tc:token>
      <tc:token ID="w98b">Institute</tc:token>
      <tc:token ID="w98c">for</tc:token>
      <tc:token ID="w98d">Computer</tc:token>
      <tc:token ID="w98e">Scientists</tc:token>
      <tc:token ID="w98f">and</tc:token>
      <tc:token ID="w990">Information</tc:token>
      <tc:token ID="w991">Technologists</tc:token>
      <tc:token ID="w992">:</tc:token>
      <tc:token ID="w993">31-40</tc:token>
      <tc:token ID="w994">.</tc:token>
      <tc:token ID="w995">Glass</tc:token>
      <tc:token ID="w996">,</tc:token>
      <tc:token ID="w997">Kevin</tc:token>
      <tc:token ID="w998">/</tc:token>
      <tc:token ID="w999">Bangay</tc:token>
      <tc:token ID="w99a">,</tc:token>
      <tc:token ID="w99b">Shaun</tc:token>
      <tc:token ID="w99c">(</tc:token>
      <tc:token ID="w99d">2007</tc:token>
      <tc:token ID="w99e">)</tc:token>
      <tc:token ID="w99f">:</tc:token>
      <tc:token ID="w9a0">"</tc:token>
      <tc:token ID="w9a1">A</tc:token>
      <tc:token ID="w9a2">naive</tc:token>
      <tc:token ID="w9a3">salience-based</tc:token>
      <tc:token ID="w9a4">method</tc:token>
      <tc:token ID="w9a5">for</tc:token>
      <tc:token ID="w9a6">speaker</tc:token>
      <tc:token ID="w9a7">identification</tc:token>
      <tc:token ID="w9a8">in</tc:token>
      <tc:token ID="w9a9">fiction</tc:token>
      <tc:token ID="w9aa">books</tc:token>
      <tc:token ID="w9ab">"</tc:token>
      <tc:token ID="w9ac">,</tc:token>
      <tc:token ID="w9ad">in</tc:token>
      <tc:token ID="w9ae">:</tc:token>
      <tc:token ID="w9af">Proceedings</tc:token>
      <tc:token ID="w9b0">of</tc:token>
      <tc:token ID="w9b1">the</tc:token>
      <tc:token ID="w9b2">18th</tc:token>
      <tc:token ID="w9b3">Annual</tc:token>
      <tc:token ID="w9b4">Symposium</tc:token>
      <tc:token ID="w9b5">of</tc:token>
      <tc:token ID="w9b6">the</tc:token>
      <tc:token ID="w9b7">Pattern</tc:token>
      <tc:token ID="w9b8">Recognition</tc:token>
      <tc:token ID="w9b9">Association</tc:token>
      <tc:token ID="w9ba">of</tc:token>
      <tc:token ID="w9bb">South</tc:token>
      <tc:token ID="w9bc">Africa</tc:token>
      <tc:token ID="w9bd">(</tc:token>
      <tc:token ID="w9be">PRASA’</tc:token>
      <tc:token ID="w9bf">07</tc:token>
      <tc:token ID="w9c0">)</tc:token>
      <tc:token ID="w9c1">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.494.3729&amp;rep=rep1&amp;type=pdf</tc:token>
      <tc:token ID="w9c2">[</tc:token>
      <tc:token ID="w9c3">letzter</tc:token>
      <tc:token ID="w9c4">Zugriff</tc:token>
      <tc:token ID="w9c5">16.</tc:token>
      <tc:token ID="w9c6">Februar</tc:token>
      <tc:token ID="w9c7">2016</tc:token>
      <tc:token ID="w9c8">]</tc:token>
      <tc:token ID="w9c9">.</tc:token>
      <tc:token ID="w9ca">He</tc:token>
      <tc:token ID="w9cb">,</tc:token>
      <tc:token ID="w9cc">Hua</tc:token>
      <tc:token ID="w9cd">/</tc:token>
      <tc:token ID="w9ce">Barbosa</tc:token>
      <tc:token ID="w9cf">,</tc:token>
      <tc:token ID="w9d0">Denilson</tc:token>
      <tc:token ID="w9d1">/</tc:token>
      <tc:token ID="w9d2">Kondrak</tc:token>
      <tc:token ID="w9d3">,</tc:token>
      <tc:token ID="w9d4">Grzegorz</tc:token>
      <tc:token ID="w9d5">(</tc:token>
      <tc:token ID="w9d6">2013</tc:token>
      <tc:token ID="w9d7">)</tc:token>
      <tc:token ID="w9d8">:</tc:token>
      <tc:token ID="w9d9">"</tc:token>
      <tc:token ID="w9da">Identification</tc:token>
      <tc:token ID="w9db">of</tc:token>
      <tc:token ID="w9dc">Speakers</tc:token>
      <tc:token ID="w9dd">in</tc:token>
      <tc:token ID="w9de">Novels</tc:token>
      <tc:token ID="w9df">"</tc:token>
      <tc:token ID="w9e0">,</tc:token>
      <tc:token ID="w9e1">in</tc:token>
      <tc:token ID="w9e2">:</tc:token>
      <tc:token ID="w9e3">Proceedings</tc:token>
      <tc:token ID="w9e4">of</tc:token>
      <tc:token ID="w9e5">the</tc:token>
      <tc:token ID="w9e6">51st</tc:token>
      <tc:token ID="w9e7">Annual</tc:token>
      <tc:token ID="w9e8">Meeting</tc:token>
      <tc:token ID="w9e9">of</tc:token>
      <tc:token ID="w9ea">the</tc:token>
      <tc:token ID="w9eb">Association</tc:token>
      <tc:token ID="w9ec">for</tc:token>
      <tc:token ID="w9ed">Computational</tc:token>
      <tc:token ID="w9ee">Linguistics</tc:token>
      <tc:token ID="w9ef">.</tc:token>
      <tc:token ID="w9f0">Sofia</tc:token>
      <tc:token ID="w9f1">,</tc:token>
      <tc:token ID="w9f2">Bulgaria</tc:token>
      <tc:token ID="w9f3">:</tc:token>
      <tc:token ID="w9f4">1312-1320</tc:token>
      <tc:token ID="w9f5">.</tc:token>
      <tc:token ID="w9f6">Iosif</tc:token>
      <tc:token ID="w9f7">,</tc:token>
      <tc:token ID="w9f8">Elias</tc:token>
      <tc:token ID="w9f9">/</tc:token>
      <tc:token ID="w9fa">Mishra</tc:token>
      <tc:token ID="w9fb">,</tc:token>
      <tc:token ID="w9fc">Taniya</tc:token>
      <tc:token ID="w9fd">(</tc:token>
      <tc:token ID="w9fe">2014</tc:token>
      <tc:token ID="w9ff">)</tc:token>
      <tc:token ID="wa00">:</tc:token>
      <tc:token ID="wa01">"</tc:token>
      <tc:token ID="wa02">From</tc:token>
      <tc:token ID="wa03">Speaker</tc:token>
      <tc:token ID="wa04">Identification</tc:token>
      <tc:token ID="wa05">to</tc:token>
      <tc:token ID="wa06">Affective</tc:token>
      <tc:token ID="wa07">Analysis</tc:token>
      <tc:token ID="wa08">:</tc:token>
      <tc:token ID="wa09">A</tc:token>
      <tc:token ID="wa0a">Multi-Step</tc:token>
      <tc:token ID="wa0b">System</tc:token>
      <tc:token ID="wa0c">for</tc:token>
      <tc:token ID="wa0d">Analyzing</tc:token>
      <tc:token ID="wa0e">Children’s</tc:token>
      <tc:token ID="wa0f">Stories</tc:token>
      <tc:token ID="wa10">"</tc:token>
      <tc:token ID="wa11">,</tc:token>
      <tc:token ID="wa12">in</tc:token>
      <tc:token ID="wa13">:</tc:token>
      <tc:token ID="wa14">EACL</tc:token>
      <tc:token ID="wa15">2014</tc:token>
      <tc:token ID="wa16">:</tc:token>
      <tc:token ID="wa17">40-49</tc:token>
      <tc:token ID="wa18">.</tc:token>
      <tc:token ID="wa19">Jannidis</tc:token>
      <tc:token ID="wa1a">,</tc:token>
      <tc:token ID="wa1b">Fotis</tc:token>
      <tc:token ID="wa1c">/</tc:token>
      <tc:token ID="wa1d">Krug</tc:token>
      <tc:token ID="wa1e">,</tc:token>
      <tc:token ID="wa1f">Markus</tc:token>
      <tc:token ID="wa20">/</tc:token>
      <tc:token ID="wa21">Reger</tc:token>
      <tc:token ID="wa22">,</tc:token>
      <tc:token ID="wa23">Isabella</tc:token>
      <tc:token ID="wa24">/</tc:token>
      <tc:token ID="wa25">Toepfer</tc:token>
      <tc:token ID="wa26">,</tc:token>
      <tc:token ID="wa27">Martin</tc:token>
      <tc:token ID="wa28">/</tc:token>
      <tc:token ID="wa29">Weimer</tc:token>
      <tc:token ID="wa2a">,</tc:token>
      <tc:token ID="wa2b">Lukas</tc:token>
      <tc:token ID="wa2c">/</tc:token>
      <tc:token ID="wa2d">Puppe</tc:token>
      <tc:token ID="wa2e">,</tc:token>
      <tc:token ID="wa2f">Frank</tc:token>
      <tc:token ID="wa30">(</tc:token>
      <tc:token ID="wa31">2015</tc:token>
      <tc:token ID="wa32">)</tc:token>
      <tc:token ID="wa33">:</tc:token>
      <tc:token ID="wa34">“</tc:token>
      <tc:token ID="wa35">Automatische</tc:token>
      <tc:token ID="wa36">Erkennung</tc:token>
      <tc:token ID="wa37">von</tc:token>
      <tc:token ID="wa38">Figuren</tc:token>
      <tc:token ID="wa39">in</tc:token>
      <tc:token ID="wa3a">deutschsprachigen</tc:token>
      <tc:token ID="wa3b">Romanen</tc:token>
      <tc:token ID="wa3c">”</tc:token>
      <tc:token ID="wa3d">,</tc:token>
      <tc:token ID="wa3e">in</tc:token>
      <tc:token ID="wa3f">:</tc:token>
      <tc:token ID="wa40">Digital</tc:token>
      <tc:token ID="wa41">Humanities</tc:token>
      <tc:token ID="wa42">im</tc:token>
      <tc:token ID="wa43">deutschsprachigen</tc:token>
      <tc:token ID="wa44">Raum</tc:token>
      <tc:token ID="wa45">(</tc:token>
      <tc:token ID="wa46">Dhd</tc:token>
      <tc:token ID="wa47">2015</tc:token>
      <tc:token ID="wa48">)</tc:token>
      <tc:token ID="wa49">,</tc:token>
      <tc:token ID="wa4a">Graz</tc:token>
      <tc:token ID="wa4b">,</tc:token>
      <tc:token ID="wa4c">Austria</tc:token>
      <tc:token ID="wa4d">.</tc:token>
      <tc:token ID="wa4e">Joachims</tc:token>
      <tc:token ID="wa4f">,</tc:token>
      <tc:token ID="wa50">Thorsten</tc:token>
      <tc:token ID="wa51">(</tc:token>
      <tc:token ID="wa52">2002</tc:token>
      <tc:token ID="wa53">)</tc:token>
      <tc:token ID="wa54">:</tc:token>
      <tc:token ID="wa55">Learning</tc:token>
      <tc:token ID="wa56">to</tc:token>
      <tc:token ID="wa57">classify</tc:token>
      <tc:token ID="wa58">text</tc:token>
      <tc:token ID="wa59">using</tc:token>
      <tc:token ID="wa5a">support</tc:token>
      <tc:token ID="wa5b">vector</tc:token>
      <tc:token ID="wa5c">machines</tc:token>
      <tc:token ID="wa5d">.</tc:token>
      <tc:token ID="wa5e">Methods</tc:token>
      <tc:token ID="wa5f">,</tc:token>
      <tc:token ID="wa60">theory</tc:token>
      <tc:token ID="wa61">and</tc:token>
      <tc:token ID="wa62">algorithms</tc:token>
      <tc:token ID="wa63">(</tc:token>
      <tc:token ID="wa64">=</tc:token>
      <tc:token ID="wa65">The</tc:token>
      <tc:token ID="wa66">Springer</tc:token>
      <tc:token ID="wa67">International</tc:token>
      <tc:token ID="wa68">Series</tc:token>
      <tc:token ID="wa69">in</tc:token>
      <tc:token ID="wa6a">Engineering</tc:token>
      <tc:token ID="wa6b">and</tc:token>
      <tc:token ID="wa6c">Computer</tc:token>
      <tc:token ID="wa6d">Science</tc:token>
      <tc:token ID="wa6e">668</tc:token>
      <tc:token ID="wa6f">)</tc:token>
      <tc:token ID="wa70">.</tc:token>
      <tc:token ID="wa71">New</tc:token>
      <tc:token ID="wa72">York</tc:token>
      <tc:token ID="wa73">:</tc:token>
      <tc:token ID="wa74">Springer</tc:token>
      <tc:token ID="wa75">.</tc:token>
      <tc:token ID="wa76">Krug</tc:token>
      <tc:token ID="wa77">,</tc:token>
      <tc:token ID="wa78">Markus</tc:token>
      <tc:token ID="wa79">/</tc:token>
      <tc:token ID="wa7a">Puppe</tc:token>
      <tc:token ID="wa7b">,</tc:token>
      <tc:token ID="wa7c">Frank</tc:token>
      <tc:token ID="wa7d">/</tc:token>
      <tc:token ID="wa7e">Jannidis</tc:token>
      <tc:token ID="wa7f">,</tc:token>
      <tc:token ID="wa80">Fotis</tc:token>
      <tc:token ID="wa81">/</tc:token>
      <tc:token ID="wa82">Macharowsky</tc:token>
      <tc:token ID="wa83">,</tc:token>
      <tc:token ID="wa84">Luisa</tc:token>
      <tc:token ID="wa85">/</tc:token>
      <tc:token ID="wa86">Reger</tc:token>
      <tc:token ID="wa87">,</tc:token>
      <tc:token ID="wa88">Isabella</tc:token>
      <tc:token ID="wa89">/</tc:token>
      <tc:token ID="wa8a">Weimer</tc:token>
      <tc:token ID="wa8b">,</tc:token>
      <tc:token ID="wa8c">Lukas</tc:token>
      <tc:token ID="wa8d">(</tc:token>
      <tc:token ID="wa8e">2015</tc:token>
      <tc:token ID="wa8f">)</tc:token>
      <tc:token ID="wa90">:</tc:token>
      <tc:token ID="wa91">"</tc:token>
      <tc:token ID="wa92">Rule-based</tc:token>
      <tc:token ID="wa93">Coreference</tc:token>
      <tc:token ID="wa94">Resolution</tc:token>
      <tc:token ID="wa95">in</tc:token>
      <tc:token ID="wa96">German</tc:token>
      <tc:token ID="wa97">Historic</tc:token>
      <tc:token ID="wa98">Novels</tc:token>
      <tc:token ID="wa99">"</tc:token>
      <tc:token ID="wa9a">,</tc:token>
      <tc:token ID="wa9b">in</tc:token>
      <tc:token ID="wa9c">:</tc:token>
      <tc:token ID="wa9d">Proceedings</tc:token>
      <tc:token ID="wa9e">of</tc:token>
      <tc:token ID="wa9f">the</tc:token>
      <tc:token ID="waa0">Fourth</tc:token>
      <tc:token ID="waa1">Workshop</tc:token>
      <tc:token ID="waa2">on</tc:token>
      <tc:token ID="waa3">Computational</tc:token>
      <tc:token ID="waa4">Linguistics</tc:token>
      <tc:token ID="waa5">for</tc:token>
      <tc:token ID="waa6">Literature</tc:token>
      <tc:token ID="waa7">98-104</tc:token>
      <tc:token ID="waa8">.</tc:token>
      <tc:token ID="waa9">Lee</tc:token>
      <tc:token ID="waaa">,</tc:token>
      <tc:token ID="waab">Heeyoung</tc:token>
      <tc:token ID="waac">/</tc:token>
      <tc:token ID="waad">Peirsman</tc:token>
      <tc:token ID="waae">,</tc:token>
      <tc:token ID="waaf">Yves</tc:token>
      <tc:token ID="wab0">/</tc:token>
      <tc:token ID="wab1">Chang</tc:token>
      <tc:token ID="wab2">,</tc:token>
      <tc:token ID="wab3">Angel</tc:token>
      <tc:token ID="wab4">/</tc:token>
      <tc:token ID="wab5">Chambers</tc:token>
      <tc:token ID="wab6">,</tc:token>
      <tc:token ID="wab7">Nathanael</tc:token>
      <tc:token ID="wab8">/</tc:token>
      <tc:token ID="wab9">Surdeanu</tc:token>
      <tc:token ID="waba">,</tc:token>
      <tc:token ID="wabb">Mihai</tc:token>
      <tc:token ID="wabc">/</tc:token>
      <tc:token ID="wabd">Jurafsky</tc:token>
      <tc:token ID="wabe">,</tc:token>
      <tc:token ID="wabf">Dan</tc:token>
      <tc:token ID="wac0">(</tc:token>
      <tc:token ID="wac1">2011</tc:token>
      <tc:token ID="wac2">)</tc:token>
      <tc:token ID="wac3">:</tc:token>
      <tc:token ID="wac4">"</tc:token>
      <tc:token ID="wac5">Stanford</tc:token>
      <tc:token ID="wac6">'s</tc:token>
      <tc:token ID="wac7">multi-pass</tc:token>
      <tc:token ID="wac8">sieve</tc:token>
      <tc:token ID="wac9">coreference</tc:token>
      <tc:token ID="waca">resolution</tc:token>
      <tc:token ID="wacb">system</tc:token>
      <tc:token ID="wacc">at</tc:token>
      <tc:token ID="wacd">the</tc:token>
      <tc:token ID="wace">CoNLL-2011</tc:token>
      <tc:token ID="wacf">shared</tc:token>
      <tc:token ID="wad0">task</tc:token>
      <tc:token ID="wad1">"</tc:token>
      <tc:token ID="wad2">,</tc:token>
      <tc:token ID="wad3">in</tc:token>
      <tc:token ID="wad4">:</tc:token>
      <tc:token ID="wad5">Proceedings</tc:token>
      <tc:token ID="wad6">of</tc:token>
      <tc:token ID="wad7">the</tc:token>
      <tc:token ID="wad8">Fifteenth</tc:token>
      <tc:token ID="wad9">Conference</tc:token>
      <tc:token ID="wada">on</tc:token>
      <tc:token ID="wadb">Computational</tc:token>
      <tc:token ID="wadc">Natural</tc:token>
      <tc:token ID="wadd">Language</tc:token>
      <tc:token ID="wade">Learning</tc:token>
      <tc:token ID="wadf">:</tc:token>
      <tc:token ID="wae0">Shared</tc:token>
      <tc:token ID="wae1">Task</tc:token>
      <tc:token ID="wae2">.</tc:token>
      <tc:token ID="wae3">Association</tc:token>
      <tc:token ID="wae4">for</tc:token>
      <tc:token ID="wae5">Computational</tc:token>
      <tc:token ID="wae6">Linguistics</tc:token>
      <tc:token ID="wae7">http://nlp.stanford.edu/pubs/conllst2011-coref.pdf</tc:token>
      <tc:token ID="wae8">[</tc:token>
      <tc:token ID="wae9">letzter</tc:token>
      <tc:token ID="waea">Zugriff</tc:token>
      <tc:token ID="waeb">08.</tc:token>
      <tc:token ID="waec">Februar</tc:token>
      <tc:token ID="waed">2016</tc:token>
      <tc:token ID="waee">]</tc:token>
      <tc:token ID="waef">.</tc:token>
      <tc:token ID="waf0">McCallum</tc:token>
      <tc:token ID="waf1">,</tc:token>
      <tc:token ID="waf2">Andrew</tc:token>
      <tc:token ID="waf3">Kachites</tc:token>
      <tc:token ID="waf4">(</tc:token>
      <tc:token ID="waf5">2002</tc:token>
      <tc:token ID="waf6">)</tc:token>
      <tc:token ID="waf7">:</tc:token>
      <tc:token ID="waf8">MALLET</tc:token>
      <tc:token ID="waf9">:</tc:token>
      <tc:token ID="wafa">A</tc:token>
      <tc:token ID="wafb">Machine</tc:token>
      <tc:token ID="wafc">Learning</tc:token>
      <tc:token ID="wafd">for</tc:token>
      <tc:token ID="wafe">Language</tc:token>
      <tc:token ID="waff">Toolkit</tc:token>
      <tc:token ID="wb00">http://mallet.cs.umass.edu</tc:token>
      <tc:token ID="wb01">[</tc:token>
      <tc:token ID="wb02">letzter</tc:token>
      <tc:token ID="wb03">Zugriff</tc:token>
      <tc:token ID="wb04">08.</tc:token>
      <tc:token ID="wb05">Februar</tc:token>
      <tc:token ID="wb06">2016</tc:token>
      <tc:token ID="wb07">]</tc:token>
      <tc:token ID="wb08">.</tc:token>
      <tc:token ID="wb09">Mikolov</tc:token>
      <tc:token ID="wb0a">,</tc:token>
      <tc:token ID="wb0b">Tomas</tc:token>
      <tc:token ID="wb0c">/</tc:token>
      <tc:token ID="wb0d">Sutskever</tc:token>
      <tc:token ID="wb0e">,</tc:token>
      <tc:token ID="wb0f">Ilya</tc:token>
      <tc:token ID="wb10">/</tc:token>
      <tc:token ID="wb11">Chen</tc:token>
      <tc:token ID="wb12">,</tc:token>
      <tc:token ID="wb13">Kai</tc:token>
      <tc:token ID="wb14">/</tc:token>
      <tc:token ID="wb15">Corrado</tc:token>
      <tc:token ID="wb16">,</tc:token>
      <tc:token ID="wb17">Greg</tc:token>
      <tc:token ID="wb18">/</tc:token>
      <tc:token ID="wb19">Dean</tc:token>
      <tc:token ID="wb1a">Jeffrey</tc:token>
      <tc:token ID="wb1b">(</tc:token>
      <tc:token ID="wb1c">2013</tc:token>
      <tc:token ID="wb1d">)</tc:token>
      <tc:token ID="wb1e">:</tc:token>
      <tc:token ID="wb1f">"</tc:token>
      <tc:token ID="wb20">Distributed</tc:token>
      <tc:token ID="wb21">representations</tc:token>
      <tc:token ID="wb22">of</tc:token>
      <tc:token ID="wb23">words</tc:token>
      <tc:token ID="wb24">and</tc:token>
      <tc:token ID="wb25">phrases</tc:token>
      <tc:token ID="wb26">and</tc:token>
      <tc:token ID="wb27">their</tc:token>
      <tc:token ID="wb28">compositionality</tc:token>
      <tc:token ID="wb29">"</tc:token>
      <tc:token ID="wb2a">,</tc:token>
      <tc:token ID="wb2b">in</tc:token>
      <tc:token ID="wb2c">:</tc:token>
      <tc:token ID="wb2d">Advances</tc:token>
      <tc:token ID="wb2e">in</tc:token>
      <tc:token ID="wb2f">neural</tc:token>
      <tc:token ID="wb30">information</tc:token>
      <tc:token ID="wb31">processing</tc:token>
      <tc:token ID="wb32">systems</tc:token>
      <tc:token ID="wb33">26</tc:token>
      <tc:token ID="wb34">http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf</tc:token>
      <tc:token ID="wb35">[</tc:token>
      <tc:token ID="wb36">letzter</tc:token>
      <tc:token ID="wb37">Zugriff</tc:token>
      <tc:token ID="wb38">08.</tc:token>
      <tc:token ID="wb39">Februar</tc:token>
      <tc:token ID="wb3a">2016</tc:token>
      <tc:token ID="wb3b">]</tc:token>
      <tc:token ID="wb3c">.</tc:token>
      <tc:token ID="wb3d">O'</tc:token>
      <tc:token ID="wb3e">Keefe</tc:token>
      <tc:token ID="wb3f">,</tc:token>
      <tc:token ID="wb40">Tim</tc:token>
      <tc:token ID="wb41">/</tc:token>
      <tc:token ID="wb42">Pareti</tc:token>
      <tc:token ID="wb43">,</tc:token>
      <tc:token ID="wb44">Silvia</tc:token>
      <tc:token ID="wb45">/</tc:token>
      <tc:token ID="wb46">Curran</tc:token>
      <tc:token ID="wb47">,</tc:token>
      <tc:token ID="wb48">James</tc:token>
      <tc:token ID="wb49">R.</tc:token>
      <tc:token ID="wb4a">/</tc:token>
      <tc:token ID="wb4b">Koprinska</tc:token>
      <tc:token ID="wb4c">,</tc:token>
      <tc:token ID="wb4d">Irena</tc:token>
      <tc:token ID="wb4e">/</tc:token>
      <tc:token ID="wb4f">Honnibal</tc:token>
      <tc:token ID="wb50">,</tc:token>
      <tc:token ID="wb51">Matthew</tc:token>
      <tc:token ID="wb52">(</tc:token>
      <tc:token ID="wb53">2012</tc:token>
      <tc:token ID="wb54">)</tc:token>
      <tc:token ID="wb55">:</tc:token>
      <tc:token ID="wb56">"</tc:token>
      <tc:token ID="wb57">A</tc:token>
      <tc:token ID="wb58">sequence</tc:token>
      <tc:token ID="wb59">labelling</tc:token>
      <tc:token ID="wb5a">approach</tc:token>
      <tc:token ID="wb5b">to</tc:token>
      <tc:token ID="wb5c">quote</tc:token>
      <tc:token ID="wb5d">attribution</tc:token>
      <tc:token ID="wb5e">"</tc:token>
      <tc:token ID="wb5f">,</tc:token>
      <tc:token ID="wb60">in</tc:token>
      <tc:token ID="wb61">:</tc:token>
      <tc:token ID="wb62">Proceedings</tc:token>
      <tc:token ID="wb63">of</tc:token>
      <tc:token ID="wb64">the</tc:token>
      <tc:token ID="wb65">2012</tc:token>
      <tc:token ID="wb66">Joint</tc:token>
      <tc:token ID="wb67">Conference</tc:token>
      <tc:token ID="wb68">on</tc:token>
      <tc:token ID="wb69">Empirical</tc:token>
      <tc:token ID="wb6a">Methods</tc:token>
      <tc:token ID="wb6b">in</tc:token>
      <tc:token ID="wb6c">Natural</tc:token>
      <tc:token ID="wb6d">Language</tc:token>
      <tc:token ID="wb6e">Processing</tc:token>
      <tc:token ID="wb6f">and</tc:token>
      <tc:token ID="wb70">Computational</tc:token>
      <tc:token ID="wb71">Natural</tc:token>
      <tc:token ID="wb72">Language</tc:token>
      <tc:token ID="wb73">Learning</tc:token>
      <tc:token ID="wb74">.</tc:token>
      <tc:token ID="wb75">Association</tc:token>
      <tc:token ID="wb76">for</tc:token>
      <tc:token ID="wb77">Computational</tc:token>
      <tc:token ID="wb78">Linguistics</tc:token>
      <tc:token ID="wb79">,</tc:token>
      <tc:token ID="wb7a">2012</tc:token>
      <tc:token ID="wb7b">:</tc:token>
      <tc:token ID="wb7c">790–799</tc:token>
      <tc:token ID="wb7d">.</tc:token>
      <tc:token ID="wb7e">Rahman</tc:token>
      <tc:token ID="wb7f">,</tc:token>
      <tc:token ID="wb80">Altaf</tc:token>
      <tc:token ID="wb81">/</tc:token>
      <tc:token ID="wb82">Ng</tc:token>
      <tc:token ID="wb83">,</tc:token>
      <tc:token ID="wb84">Vincent</tc:token>
      <tc:token ID="wb85">(</tc:token>
      <tc:token ID="wb86">2011</tc:token>
      <tc:token ID="wb87">)</tc:token>
      <tc:token ID="wb88">:</tc:token>
      <tc:token ID="wb89">"</tc:token>
      <tc:token ID="wb8a">Narrowing</tc:token>
      <tc:token ID="wb8b">the</tc:token>
      <tc:token ID="wb8c">modeling</tc:token>
      <tc:token ID="wb8d">gap</tc:token>
      <tc:token ID="wb8e">:</tc:token>
      <tc:token ID="wb8f">a</tc:token>
      <tc:token ID="wb90">cluster-ranking</tc:token>
      <tc:token ID="wb91">approach</tc:token>
      <tc:token ID="wb92">to</tc:token>
      <tc:token ID="wb93">coreference</tc:token>
      <tc:token ID="wb94">resolution</tc:token>
      <tc:token ID="wb95">"</tc:token>
      <tc:token ID="wb96">,</tc:token>
      <tc:token ID="wb97">in</tc:token>
      <tc:token ID="wb98">:</tc:token>
      <tc:token ID="wb99">Journal</tc:token>
      <tc:token ID="wb9a">of</tc:token>
      <tc:token ID="wb9b">Artificial</tc:token>
      <tc:token ID="wb9c">Intelligence</tc:token>
      <tc:token ID="wb9d">Research</tc:token>
      <tc:token ID="wb9e">40</tc:token>
      <tc:token ID="wb9f">:</tc:token>
      <tc:token ID="wba0">469-521</tc:token>
      <tc:token ID="wba1">.</tc:token>
      <tc:token ID="wba2">Ruppenhofer</tc:token>
      <tc:token ID="wba3">,</tc:token>
      <tc:token ID="wba4">Josef</tc:token>
      <tc:token ID="wba5">/</tc:token>
      <tc:token ID="wba6">Sporleder</tc:token>
      <tc:token ID="wba7">,</tc:token>
      <tc:token ID="wba8">Caroline</tc:token>
      <tc:token ID="wba9">/</tc:token>
      <tc:token ID="wbaa">Shirokov</tc:token>
      <tc:token ID="wbab">,</tc:token>
      <tc:token ID="wbac">Fabian</tc:token>
      <tc:token ID="wbad">(</tc:token>
      <tc:token ID="wbae">2010</tc:token>
      <tc:token ID="wbaf">)</tc:token>
      <tc:token ID="wbb0">:</tc:token>
      <tc:token ID="wbb1">"</tc:token>
      <tc:token ID="wbb2">Speaker</tc:token>
      <tc:token ID="wbb3">Attribution</tc:token>
      <tc:token ID="wbb4">in</tc:token>
      <tc:token ID="wbb5">Cabinet</tc:token>
      <tc:token ID="wbb6">Protocols</tc:token>
      <tc:token ID="wbb7">"</tc:token>
      <tc:token ID="wbb8">,</tc:token>
      <tc:token ID="wbb9">in</tc:token>
      <tc:token ID="wbba">:</tc:token>
      <tc:token ID="wbbb">The</tc:token>
      <tc:token ID="wbbc">seventh</tc:token>
      <tc:token ID="wbbd">international</tc:token>
      <tc:token ID="wbbe">conference</tc:token>
      <tc:token ID="wbbf">on</tc:token>
      <tc:token ID="wbc0">Language</tc:token>
      <tc:token ID="wbc1">Resources</tc:token>
      <tc:token ID="wbc2">and</tc:token>
      <tc:token ID="wbc3">Evaluation</tc:token>
      <tc:token ID="wbc4">(</tc:token>
      <tc:token ID="wbc5">LREC</tc:token>
      <tc:token ID="wbc6">)</tc:token>
      <tc:token ID="wbc7">2510-2515</tc:token>
      <tc:token ID="wbc8">.</tc:token>
      <tc:token ID="wbc9">Schmid</tc:token>
      <tc:token ID="wbca">,</tc:token>
      <tc:token ID="wbcb">Helmut</tc:token>
      <tc:token ID="wbcc">(</tc:token>
      <tc:token ID="wbcd">1999</tc:token>
      <tc:token ID="wbce">)</tc:token>
      <tc:token ID="wbcf">:</tc:token>
      <tc:token ID="wbd0">"</tc:token>
      <tc:token ID="wbd1">Improvements</tc:token>
      <tc:token ID="wbd2">in</tc:token>
      <tc:token ID="wbd3">part-of-speech</tc:token>
      <tc:token ID="wbd4">tagging</tc:token>
      <tc:token ID="wbd5">with</tc:token>
      <tc:token ID="wbd6">an</tc:token>
      <tc:token ID="wbd7">application</tc:token>
      <tc:token ID="wbd8">to</tc:token>
      <tc:token ID="wbd9">German</tc:token>
      <tc:token ID="wbda">"</tc:token>
      <tc:token ID="wbdb">,</tc:token>
      <tc:token ID="wbdc">in</tc:token>
      <tc:token ID="wbdd">:</tc:token>
      <tc:token ID="wbde">Armstrong</tc:token>
      <tc:token ID="wbdf">,</tc:token>
      <tc:token ID="wbe0">Susan</tc:token>
      <tc:token ID="wbe1">/</tc:token>
      <tc:token ID="wbe2">Church</tc:token>
      <tc:token ID="wbe3">,</tc:token>
      <tc:token ID="wbe4">Kenneth</tc:token>
      <tc:token ID="wbe5">/</tc:token>
      <tc:token ID="wbe6">Isabelle</tc:token>
      <tc:token ID="wbe7">,</tc:token>
      <tc:token ID="wbe8">Pierre</tc:token>
      <tc:token ID="wbe9">/</tc:token>
      <tc:token ID="wbea">Manzi</tc:token>
      <tc:token ID="wbeb">,</tc:token>
      <tc:token ID="wbec">Sandra</tc:token>
      <tc:token ID="wbed">/</tc:token>
      <tc:token ID="wbee">Tzoukermann</tc:token>
      <tc:token ID="wbef">,</tc:token>
      <tc:token ID="wbf0">Evelyne</tc:token>
      <tc:token ID="wbf1">/</tc:token>
      <tc:token ID="wbf2">Yarowsky</tc:token>
      <tc:token ID="wbf3">,</tc:token>
      <tc:token ID="wbf4">David</tc:token>
      <tc:token ID="wbf5">(</tc:token>
      <tc:token ID="wbf6">eds</tc:token>
      <tc:token ID="wbf7">.</tc:token>
      <tc:token ID="wbf8">)</tc:token>
      <tc:token ID="wbf9">:</tc:token>
      <tc:token ID="wbfa">Natural</tc:token>
      <tc:token ID="wbfb">language</tc:token>
      <tc:token ID="wbfc">processing</tc:token>
      <tc:token ID="wbfd">using</tc:token>
      <tc:token ID="wbfe">very</tc:token>
      <tc:token ID="wbff">large</tc:token>
      <tc:token ID="wc00">corpora</tc:token>
      <tc:token ID="wc01">(</tc:token>
      <tc:token ID="wc02">=</tc:token>
      <tc:token ID="wc03">Text</tc:token>
      <tc:token ID="wc04">,</tc:token>
      <tc:token ID="wc05">Speech</tc:token>
      <tc:token ID="wc06">and</tc:token>
      <tc:token ID="wc07">Language</tc:token>
      <tc:token ID="wc08">Technology</tc:token>
      <tc:token ID="wc09">11</tc:token>
      <tc:token ID="wc0a">)</tc:token>
      <tc:token ID="wc0b">.</tc:token>
      <tc:token ID="wc0c">New</tc:token>
      <tc:token ID="wc0d">York</tc:token>
      <tc:token ID="wc0e">:</tc:token>
      <tc:token ID="wc0f">Springer</tc:token>
      <tc:token ID="wc10">13-25</tc:token>
      <tc:token ID="wc11">.</tc:token>
      <tc:token ID="wc12">Schmid</tc:token>
      <tc:token ID="wc13">,</tc:token>
      <tc:token ID="wc14">Helmut</tc:token>
      <tc:token ID="wc15">/</tc:token>
      <tc:token ID="wc16">Laws</tc:token>
      <tc:token ID="wc17">,</tc:token>
      <tc:token ID="wc18">Florian</tc:token>
      <tc:token ID="wc19">(</tc:token>
      <tc:token ID="wc1a">2008</tc:token>
      <tc:token ID="wc1b">)</tc:token>
      <tc:token ID="wc1c">:</tc:token>
      <tc:token ID="wc1d">"</tc:token>
      <tc:token ID="wc1e">Estimation</tc:token>
      <tc:token ID="wc1f">of</tc:token>
      <tc:token ID="wc20">conditional</tc:token>
      <tc:token ID="wc21">probabilities</tc:token>
      <tc:token ID="wc22">with</tc:token>
      <tc:token ID="wc23">decision</tc:token>
      <tc:token ID="wc24">trees</tc:token>
      <tc:token ID="wc25">and</tc:token>
      <tc:token ID="wc26">an</tc:token>
      <tc:token ID="wc27">application</tc:token>
      <tc:token ID="wc28">to</tc:token>
      <tc:token ID="wc29">fine-grained</tc:token>
      <tc:token ID="wc2a">POS</tc:token>
      <tc:token ID="wc2b">tagging</tc:token>
      <tc:token ID="wc2c">"</tc:token>
      <tc:token ID="wc2d">,</tc:token>
      <tc:token ID="wc2e">in</tc:token>
      <tc:token ID="wc2f">:</tc:token>
      <tc:token ID="wc30">Proceedings</tc:token>
      <tc:token ID="wc31">of</tc:token>
      <tc:token ID="wc32">the</tc:token>
      <tc:token ID="wc33">22nd</tc:token>
      <tc:token ID="wc34">International</tc:token>
      <tc:token ID="wc35">Conference</tc:token>
      <tc:token ID="wc36">on</tc:token>
      <tc:token ID="wc37">Computational</tc:token>
      <tc:token ID="wc38">Linguistics</tc:token>
      <tc:token ID="wc39">(</tc:token>
      <tc:token ID="wc3a">Coling</tc:token>
      <tc:token ID="wc3b">2008</tc:token>
      <tc:token ID="wc3c">)</tc:token>
      <tc:token ID="wc3d">777–784</tc:token>
      <tc:token ID="wc3e">.</tc:token>
      <tc:token ID="wc3f">Sutton</tc:token>
      <tc:token ID="wc40">,</tc:token>
      <tc:token ID="wc41">Charles</tc:token>
      <tc:token ID="wc42">/</tc:token>
      <tc:token ID="wc43">McCallum</tc:token>
      <tc:token ID="wc44">,</tc:token>
      <tc:token ID="wc45">Andrew</tc:token>
      <tc:token ID="wc46">(</tc:token>
      <tc:token ID="wc47">2006</tc:token>
      <tc:token ID="wc48">)</tc:token>
      <tc:token ID="wc49">:</tc:token>
      <tc:token ID="wc4a">"</tc:token>
      <tc:token ID="wc4b">An</tc:token>
      <tc:token ID="wc4c">introduction</tc:token>
      <tc:token ID="wc4d">to</tc:token>
      <tc:token ID="wc4e">conditional</tc:token>
      <tc:token ID="wc4f">random</tc:token>
      <tc:token ID="wc50">fields</tc:token>
      <tc:token ID="wc51">for</tc:token>
      <tc:token ID="wc52">relational</tc:token>
      <tc:token ID="wc53">learning</tc:token>
      <tc:token ID="wc54">"</tc:token>
      <tc:token ID="wc55">,</tc:token>
      <tc:token ID="wc56">in</tc:token>
      <tc:token ID="wc57">:</tc:token>
      <tc:token ID="wc58">Getoor</tc:token>
      <tc:token ID="wc59">,</tc:token>
      <tc:token ID="wc5a">Lise</tc:token>
      <tc:token ID="wc5b">/</tc:token>
      <tc:token ID="wc5c">Taskar</tc:token>
      <tc:token ID="wc5d">,</tc:token>
      <tc:token ID="wc5e">Ben</tc:token>
      <tc:token ID="wc5f">(</tc:token>
      <tc:token ID="wc60">eds</tc:token>
      <tc:token ID="wc61">.</tc:token>
      <tc:token ID="wc62">)</tc:token>
      <tc:token ID="wc63">:Introduction</tc:token>
      <tc:token ID="wc64">to</tc:token>
      <tc:token ID="wc65">statistical</tc:token>
      <tc:token ID="wc66">relational</tc:token>
      <tc:token ID="wc67">learning</tc:token>
      <tc:token ID="wc68">.</tc:token>
      <tc:token ID="wc69">Cambridge</tc:token>
      <tc:token ID="wc6a">,</tc:token>
      <tc:token ID="wc6b">MA</tc:token>
      <tc:token ID="wc6c">/</tc:token>
      <tc:token ID="wc6d">London</tc:token>
      <tc:token ID="wc6e">:</tc:token>
      <tc:token ID="wc6f">The</tc:token>
      <tc:token ID="wc70">MIT</tc:token>
      <tc:token ID="wc71">Press</tc:token>
      <tc:token ID="wc72">93-128</tc:token>
      <tc:token ID="wc73">.</tc:token>
      <tc:token ID="wc74">Zhang</tc:token>
      <tc:token ID="wc75">,</tc:token>
      <tc:token ID="wc76">Jason</tc:token>
      <tc:token ID="wc77">Y.</tc:token>
      <tc:token ID="wc78">/</tc:token>
      <tc:token ID="wc79">Black</tc:token>
      <tc:token ID="wc7a">Alan</tc:token>
      <tc:token ID="wc7b">W.</tc:token>
      <tc:token ID="wc7c">/</tc:token>
      <tc:token ID="wc7d">Sproat</tc:token>
      <tc:token ID="wc7e">,</tc:token>
      <tc:token ID="wc7f">Richard</tc:token>
      <tc:token ID="wc80">(</tc:token>
      <tc:token ID="wc81">2003</tc:token>
      <tc:token ID="wc82">)</tc:token>
      <tc:token ID="wc83">:</tc:token>
      <tc:token ID="wc84">"</tc:token>
      <tc:token ID="wc85">Identifying</tc:token>
      <tc:token ID="wc86">speakers</tc:token>
      <tc:token ID="wc87">in</tc:token>
      <tc:token ID="wc88">children's</tc:token>
      <tc:token ID="wc89">stories</tc:token>
      <tc:token ID="wc8a">for</tc:token>
      <tc:token ID="wc8b">speech</tc:token>
      <tc:token ID="wc8c">synthesis</tc:token>
      <tc:token ID="wc8d">"</tc:token>
      <tc:token ID="wc8e">,</tc:token>
      <tc:token ID="wc8f">in</tc:token>
      <tc:token ID="wc90">:</tc:token>
      <tc:token ID="wc91">EUROSPEECH</tc:token>
      <tc:token ID="wc92">2041-2044</tc:token>
      <tc:token ID="wc93">.</tc:token>
      <tc:token ID="wc94">Bibliographie</tc:token>
    </tc:tokens>
    <tc:sentences xmlns:tc="http://www.dspin.de/data/textcorpus">
      <tc:sentence tokenIDs="w1 w2 w3 w4 w5 w6 w7 w8 w9 wa wb wc wd we wf w10 w11 w12 w13 w14 w15 w16 w17 w18 w19 w1a" ID="s1"/>
      <tc:sentence tokenIDs="w1b w1c w1d w1e w1f w20 w21 w22 w23 w24 w25 w26 w27 w28 w29 w2a w2b w2c w2d w2e w2f w30 w31 w32 w33 w34 w35 w36 w37 w38 w39 w3a w3b w3c w3d w3e w3f w40 w41 w42 w43 w44 w45 w46 w47 w48 w49 w4a w4b w4c w4d w4e w4f w50 w51 w52 w53 w54 w55 w56 w57 w58 w59 w5a w5b w5c w5d" ID="s2"/>
      <tc:sentence tokenIDs="w5e w5f w60 w61 w62 w63 w64 w65 w66 w67 w68 w69 w6a w6b w6c w6d w6e w6f w70 w71 w72 w73 w74 w75 w76 w77 w78" ID="s3"/>
      <tc:sentence tokenIDs="w79 w7a w7b w7c w7d w7e w7f w80 w81 w82 w83 w84 w85 w86 w87 w88 w89 w8a w8b w8c w8d w8e w8f w90" ID="s4"/>
      <tc:sentence tokenIDs="w91 w92 w93 w94 w95 w96 w97 w98 w99 w9a w9b w9c w9d" ID="s5"/>
      <tc:sentence tokenIDs="w9e w9f wa0 wa1 wa2 wa3 wa4 wa5 wa6 wa7 wa8 wa9 waa wab wac wad wae waf wb0 wb1 wb2 wb3 wb4 wb5 wb6 wb7 wb8 wb9 wba wbb wbc wbd wbe wbf wc0 wc1 wc2 wc3 wc4 wc5 wc6 wc7 wc8 wc9 wca wcb wcc wcd wce wcf wd0 wd1 wd2 wd3 wd4 wd5 wd6" ID="s6"/>
      <tc:sentence tokenIDs="wd7 wd8 wd9 wda wdb wdc wdd wde wdf we0 we1 we2 we3 we4 we5 we6 we7 we8 we9 wea web wec wed" ID="s7"/>
      <tc:sentence tokenIDs="wee wef wf0 wf1 wf2 wf3 wf4 wf5 wf6 wf7 wf8 wf9 wfa wfb wfc wfd wfe wff w100 w101 w102 w103 w104 w105 w106 w107 w108 w109 w10a" ID="s8"/>
      <tc:sentence tokenIDs="w10b w10c w10d w10e w10f w110 w111 w112 w113 w114 w115 w116 w117 w118 w119 w11a w11b w11c" ID="s9"/>
      <tc:sentence tokenIDs="w11d w11e w11f w120 w121 w122 w123 w124 w125 w126 w127 w128 w129 w12a w12b w12c w12d w12e w12f w130 w131 w132 w133 w134 w135 w136 w137 w138 w139 w13a w13b" ID="sa"/>
      <tc:sentence tokenIDs="w13c w13d w13e w13f w140 w141 w142 w143 w144 w145" ID="sb"/>
      <tc:sentence tokenIDs="w146 w147 w148 w149 w14a w14b w14c w14d w14e w14f w150 w151 w152 w153 w154" ID="sc"/>
      <tc:sentence tokenIDs="w155 w156 w157 w158 w159 w15a w15b w15c w15d w15e w15f w160 w161 w162" ID="sd"/>
      <tc:sentence tokenIDs="w163 w164 w165 w166 w167 w168 w169 w16a w16b w16c w16d w16e w16f w170 w171" ID="se"/>
      <tc:sentence tokenIDs="w172 w173 w174 w175 w176 w177 w178 w179 w17a w17b w17c" ID="sf"/>
      <tc:sentence tokenIDs="w17d w17e w17f w180 w181 w182 w183 w184 w185 w186 w187 w188 w189 w18a w18b w18c w18d w18e w18f" ID="s10"/>
      <tc:sentence tokenIDs="w190 w191 w192 w193 w194 w195 w196 w197 w198 w199 w19a w19b w19c w19d w19e w19f w1a0 w1a1 w1a2 w1a3 w1a4 w1a5 w1a6 w1a7 w1a8 w1a9 w1aa w1ab w1ac w1ad w1ae w1af w1b0 w1b1 w1b2 w1b3 w1b4 w1b5 w1b6" ID="s11"/>
      <tc:sentence tokenIDs="w1b7 w1b8 w1b9 w1ba w1bb w1bc w1bd w1be w1bf w1c0 w1c1 w1c2 w1c3 w1c4 w1c5" ID="s12"/>
      <tc:sentence tokenIDs="w1c6 w1c7 w1c8 w1c9 w1ca w1cb w1cc w1cd w1ce w1cf w1d0 w1d1 w1d2 w1d3" ID="s13"/>
      <tc:sentence tokenIDs="w1d4 w1d5 w1d6 w1d7 w1d8 w1d9 w1da w1db w1dc w1dd w1de w1df w1e0 w1e1 w1e2 w1e3 w1e4 w1e5 w1e6 w1e7 w1e8 w1e9 w1ea w1eb w1ec w1ed w1ee w1ef w1f0 w1f1 w1f2 w1f3 w1f4 w1f5 w1f6 w1f7 w1f8 w1f9 w1fa" ID="s14"/>
      <tc:sentence tokenIDs="w1fb w1fc w1fd w1fe w1ff w200 w201 w202 w203 w204 w205 w206 w207 w208 w209 w20a w20b w20c w20d" ID="s15"/>
      <tc:sentence tokenIDs="w20e w20f w210 w211 w212 w213 w214 w215 w216 w217 w218 w219 w21a w21b w21c" ID="s16"/>
      <tc:sentence tokenIDs="w21d w21e w21f w220 w221 w222 w223 w224 w225 w226 w227 w228 w229 w22a w22b w22c w22d w22e w22f w230 w231 w232 w233 w234 w235 w236 w237 w238 w239 w23a w23b w23c w23d w23e w23f w240 w241 w242 w243 w244 w245 w246 w247 w248 w249 w24a w24b w24c w24d w24e w24f w250 w251 w252 w253 w254 w255 w256 w257 w258 w259 w25a w25b w25c w25d w25e w25f w260 w261 w262 w263 w264 w265 w266 w267 w268" ID="s17"/>
      <tc:sentence tokenIDs="w269 w26a w26b w26c w26d w26e w26f w270 w271 w272 w273 w274 w275" ID="s18"/>
      <tc:sentence tokenIDs="w276 w277 w278 w279 w27a w27b w27c w27d w27e w27f w280 w281 w282 w283 w284 w285 w286 w287 w288 w289 w28a w28b w28c w28d w28e" ID="s19"/>
      <tc:sentence tokenIDs="w28f w290 w291 w292 w293 w294 w295 w296 w297 w298 w299 w29a w29b w29c w29d" ID="s1a"/>
      <tc:sentence tokenIDs="w29e w29f w2a0 w2a1 w2a2 w2a3 w2a4 w2a5 w2a6 w2a7 w2a8 w2a9 w2aa w2ab w2ac w2ad w2ae w2af w2b0 w2b1 w2b2 w2b3 w2b4 w2b5 w2b6 w2b7 w2b8 w2b9 w2ba w2bb w2bc w2bd w2be w2bf w2c0 w2c1 w2c2" ID="s1b"/>
      <tc:sentence tokenIDs="w2c3 w2c4 w2c5 w2c6 w2c7 w2c8 w2c9 w2ca w2cb w2cc w2cd w2ce w2cf w2d0 w2d1 w2d2 w2d3 w2d4 w2d5 w2d6 w2d7 w2d8 w2d9 w2da w2db" ID="s1c"/>
      <tc:sentence tokenIDs="w2dc w2dd w2de w2df w2e0 w2e1 w2e2 w2e3 w2e4 w2e5 w2e6 w2e7 w2e8 w2e9" ID="s1d"/>
      <tc:sentence tokenIDs="w2ea w2eb w2ec w2ed w2ee w2ef w2f0 w2f1 w2f2 w2f3 w2f4 w2f5" ID="s1e"/>
      <tc:sentence tokenIDs="w2f6 w2f7 w2f8 w2f9 w2fa w2fb w2fc w2fd w2fe w2ff w300 w301 w302 w303 w304 w305" ID="s1f"/>
      <tc:sentence tokenIDs="w306 w307 w308 w309 w30a w30b w30c w30d w30e w30f w310 w311 w312 w313 w314 w315 w316 w317 w318 w319 w31a w31b w31c w31d w31e w31f w320 w321 w322 w323 w324 w325 w326 w327 w328 w329 w32a w32b w32c" ID="s20"/>
      <tc:sentence tokenIDs="w32d w32e w32f w330 w331 w332 w333 w334 w335 w336 w337 w338 w339 w33a w33b w33c w33d w33e w33f" ID="s21"/>
      <tc:sentence tokenIDs="w340 w341 w342 w343 w344 w345 w346 w347 w348 w349 w34a w34b w34c w34d w34e w34f w350" ID="s22"/>
      <tc:sentence tokenIDs="w351 w352 w353 w354 w355 w356 w357 w358 w359 w35a w35b w35c w35d w35e w35f w360 w361 w362 w363 w364 w365" ID="s23"/>
      <tc:sentence tokenIDs="w366 w367 w368 w369 w36a w36b w36c w36d w36e w36f w370 w371 w372 w373 w374" ID="s24"/>
      <tc:sentence tokenIDs="w375 w376 w377 w378 w379 w37a w37b w37c w37d w37e w37f w380 w381 w382" ID="s25"/>
      <tc:sentence tokenIDs="w383 w384 w385 w386 w387 w388 w389 w38a w38b w38c w38d w38e w38f w390 w391 w392 w393 w394 w395 w396" ID="s26"/>
      <tc:sentence tokenIDs="w397 w398 w399 w39a w39b w39c w39d w39e w39f" ID="s27"/>
      <tc:sentence tokenIDs="w3a0 w3a1 w3a2 w3a3 w3a4 w3a5 w3a6 w3a7 w3a8 w3a9 w3aa w3ab w3ac w3ad w3ae w3af w3b0 w3b1 w3b2" ID="s28"/>
      <tc:sentence tokenIDs="w3b3 w3b4 w3b5 w3b6 w3b7 w3b8 w3b9 w3ba w3bb w3bc w3bd w3be" ID="s29"/>
      <tc:sentence tokenIDs="w3bf w3c0 w3c1 w3c2 w3c3 w3c4 w3c5 w3c6 w3c7 w3c8 w3c9 w3ca" ID="s2a"/>
      <tc:sentence tokenIDs="w3cb w3cc w3cd w3ce w3cf w3d0 w3d1 w3d2 w3d3 w3d4 w3d5 w3d6 w3d7 w3d8 w3d9 w3da w3db w3dc w3dd w3de w3df w3e0 w3e1 w3e2 w3e3" ID="s2b"/>
      <tc:sentence tokenIDs="w3e4 w3e5 w3e6 w3e7 w3e8 w3e9 w3ea w3eb w3ec w3ed w3ee w3ef w3f0 w3f1 w3f2 w3f3 w3f4 w3f5 w3f6 w3f7" ID="s2c"/>
      <tc:sentence tokenIDs="w3f8 w3f9 w3fa w3fb w3fc w3fd w3fe w3ff w400 w401 w402 w403 w404 w405 w406 w407 w408 w409 w40a" ID="s2d"/>
      <tc:sentence tokenIDs="w40b w40c w40d w40e w40f w410 w411 w412 w413 w414 w415 w416 w417" ID="s2e"/>
      <tc:sentence tokenIDs="w418 w419 w41a w41b w41c w41d w41e w41f w420 w421 w422 w423 w424 w425 w426 w427 w428 w429 w42a w42b w42c w42d w42e w42f w430 w431 w432 w433 w434 w435 w436 w437 w438" ID="s2f"/>
      <tc:sentence tokenIDs="w439 w43a w43b w43c w43d w43e w43f w440 w441 w442 w443 w444 w445 w446" ID="s30"/>
      <tc:sentence tokenIDs="w447 w448 w449 w44a w44b w44c w44d w44e w44f w450 w451 w452 w453 w454 w455 w456 w457 w458 w459 w45a w45b w45c w45d w45e w45f w460 w461 w462 w463 w464" ID="s31"/>
      <tc:sentence tokenIDs="w465 w466 w467 w468 w469 w46a w46b w46c w46d w46e w46f w470 w471 w472 w473 w474 w475 w476 w477 w478 w479 w47a w47b w47c w47d w47e w47f" ID="s32"/>
      <tc:sentence tokenIDs="w480 w481 w482 w483 w484 w485 w486 w487 w488 w489 w48a w48b w48c w48d w48e w48f w490 w491 w492 w493 w494 w495 w496" ID="s33"/>
      <tc:sentence tokenIDs="w497 w498 w499 w49a w49b w49c w49d w49e w49f w4a0 w4a1 w4a2 w4a3 w4a4 w4a5 w4a6 w4a7 w4a8 w4a9" ID="s34"/>
      <tc:sentence tokenIDs="w4aa w4ab w4ac w4ad w4ae w4af w4b0 w4b1 w4b2 w4b3 w4b4 w4b5 w4b6 w4b7 w4b8 w4b9 w4ba w4bb w4bc w4bd w4be w4bf w4c0 w4c1 w4c2 w4c3 w4c4 w4c5 w4c6 w4c7 w4c8 w4c9 w4ca w4cb w4cc w4cd w4ce w4cf w4d0 w4d1 w4d2 w4d3 w4d4 w4d5" ID="s35"/>
      <tc:sentence tokenIDs="w4d6 w4d7 w4d8 w4d9 w4da w4db w4dc w4dd w4de w4df w4e0 w4e1 w4e2 w4e3 w4e4 w4e5 w4e6 w4e7 w4e8 w4e9 w4ea w4eb w4ec w4ed" ID="s36"/>
      <tc:sentence tokenIDs="w4ee w4ef w4f0 w4f1 w4f2 w4f3 w4f4 w4f5 w4f6 w4f7 w4f8 w4f9 w4fa w4fb w4fc w4fd w4fe w4ff w500 w501 w502 w503 w504 w505 w506 w507 w508 w509 w50a w50b w50c w50d w50e w50f w510 w511 w512 w513 w514 w515 w516 w517 w518 w519" ID="s37"/>
      <tc:sentence tokenIDs="w51a w51b w51c w51d w51e w51f w520 w521 w522 w523 w524 w525 w526 w527" ID="s38"/>
      <tc:sentence tokenIDs="w528 w529 w52a w52b w52c w52d w52e w52f w530 w531 w532 w533 w534 w535 w536 w537 w538 w539 w53a w53b w53c w53d w53e w53f w540 w541 w542" ID="s39"/>
      <tc:sentence tokenIDs="w543 w544 w545 w546 w547 w548 w549 w54a w54b w54c w54d w54e w54f w550 w551 w552 w553 w554 w555 w556 w557 w558 w559 w55a w55b w55c w55d" ID="s3a"/>
      <tc:sentence tokenIDs="w55e w55f w560 w561 w562 w563 w564 w565 w566 w567 w568 w569 w56a w56b w56c w56d w56e w56f w570 w571 w572 w573 w574 w575 w576 w577 w578 w579 w57a w57b w57c" ID="s3b"/>
      <tc:sentence tokenIDs="w57d w57e w57f w580 w581 w582 w583 w584 w585 w586 w587 w588 w589 w58a w58b w58c w58d w58e w58f w590 w591 w592 w593 w594 w595 w596 w597 w598 w599 w59a w59b" ID="s3c"/>
      <tc:sentence tokenIDs="w59c w59d w59e w59f w5a0 w5a1 w5a2 w5a3 w5a4 w5a5 w5a6 w5a7 w5a8 w5a9 w5aa w5ab w5ac w5ad w5ae w5af w5b0 w5b1 w5b2 w5b3 w5b4 w5b5" ID="s3d"/>
      <tc:sentence tokenIDs="w5b6 w5b7 w5b8" ID="s3e"/>
      <tc:sentence tokenIDs="w5b9 w5ba w5bb w5bc w5bd w5be w5bf w5c0 w5c1 w5c2" ID="s3f"/>
      <tc:sentence tokenIDs="w5c3 w5c4 w5c5 w5c6 w5c7 w5c8 w5c9 w5ca w5cb w5cc w5cd w5ce w5cf w5d0 w5d1" ID="s40"/>
      <tc:sentence tokenIDs="w5d2 w5d3 w5d4 w5d5 w5d6 w5d7 w5d8 w5d9 w5da w5db w5dc w5dd w5de w5df w5e0 w5e1 w5e2 w5e3 w5e4 w5e5" ID="s41"/>
      <tc:sentence tokenIDs="w5e6 w5e7 w5e8 w5e9 w5ea w5eb w5ec w5ed w5ee w5ef w5f0 w5f1 w5f2 w5f3 w5f4 w5f5 w5f6 w5f7 w5f8" ID="s42"/>
      <tc:sentence tokenIDs="w5f9 w5fa w5fb w5fc" ID="s43"/>
      <tc:sentence tokenIDs="w5fd w5fe w5ff w600 w601 w602 w603 w604 w605 w606 w607 w608" ID="s44"/>
      <tc:sentence tokenIDs="w609 w60a w60b w60c w60d w60e w60f w610 w611 w612 w613 w614 w615 w616 w617 w618 w619 w61a w61b w61c" ID="s45"/>
      <tc:sentence tokenIDs="w61d w61e w61f w620 w621 w622 w623 w624 w625 w626 w627 w628 w629 w62a w62b w62c w62d w62e w62f w630 w631" ID="s46"/>
      <tc:sentence tokenIDs="w632 w633 w634 w635 w636 w637 w638 w639 w63a w63b w63c w63d w63e w63f w640 w641 w642 w643 w644 w645" ID="s47"/>
      <tc:sentence tokenIDs="w646 w647 w648 w649 w64a w64b w64c w64d w64e w64f w650 w651 w652 w653 w654 w655 w656 w657 w658 w659 w65a w65b w65c w65d w65e w65f w660" ID="s48"/>
      <tc:sentence tokenIDs="w661 w662 w663 w664 w665 w666 w667 w668 w669 w66a w66b w66c w66d w66e w66f w670" ID="s49"/>
      <tc:sentence tokenIDs="w671 w672 w673 w674 w675 w676" ID="s4a"/>
      <tc:sentence tokenIDs="w677 w678 w679 w67a w67b w67c w67d w67e w67f w680" ID="s4b"/>
      <tc:sentence tokenIDs="w681 w682 w683 w684 w685 w686 w687 w688 w689 w68a w68b w68c w68d w68e w68f w690 w691 w692 w693 w694 w695 w696 w697 w698 w699 w69a w69b w69c w69d w69e w69f w6a0 w6a1 w6a2 w6a3 w6a4 w6a5 w6a6 w6a7 w6a8 w6a9 w6aa w6ab w6ac w6ad w6ae" ID="s4c"/>
      <tc:sentence tokenIDs="w6af w6b0 w6b1 w6b2 w6b3 w6b4 w6b5 w6b6 w6b7 w6b8 w6b9 w6ba" ID="s4d"/>
      <tc:sentence tokenIDs="w6bb w6bc w6bd w6be w6bf w6c0 w6c1 w6c2 w6c3 w6c4 w6c5" ID="s4e"/>
      <tc:sentence tokenIDs="w6c6 w6c7 w6c8 w6c9" ID="s4f"/>
      <tc:sentence tokenIDs="w6ca w6cb w6cc w6cd w6ce w6cf w6d0 w6d1 w6d2 w6d3 w6d4 w6d5 w6d6 w6d7" ID="s50"/>
      <tc:sentence tokenIDs="w6d8 w6d9 w6da w6db w6dc w6dd w6de w6df w6e0 w6e1 w6e2" ID="s51"/>
      <tc:sentence tokenIDs="w6e3 w6e4 w6e5 w6e6 w6e7 w6e8 w6e9 w6ea w6eb w6ec w6ed w6ee w6ef" ID="s52"/>
      <tc:sentence tokenIDs="w6f0 w6f1 w6f2 w6f3 w6f4 w6f5 w6f6 w6f7 w6f8 w6f9 w6fa w6fb w6fc w6fd w6fe" ID="s53"/>
      <tc:sentence tokenIDs="w6ff w700 w701 w702 w703 w704 w705 w706 w707 w708 w709 w70a w70b w70c w70d w70e" ID="s54"/>
      <tc:sentence tokenIDs="w70f w710 w711 w712 w713 w714 w715 w716 w717 w718 w719 w71a w71b w71c w71d w71e w71f w720 w721" ID="s55"/>
      <tc:sentence tokenIDs="w722 w723 w724 w725 w726 w727 w728 w729 w72a w72b w72c w72d w72e w72f w730 w731 w732 w733 w734 w735 w736" ID="s56"/>
      <tc:sentence tokenIDs="w737 w738 w739" ID="s57"/>
      <tc:sentence tokenIDs="w73a w73b w73c w73d w73e w73f w740 w741 w742 w743 w744 w745 w746 w747 w748 w749 w74a w74b w74c w74d w74e" ID="s58"/>
      <tc:sentence tokenIDs="w74f w750 w751" ID="s59"/>
      <tc:sentence tokenIDs="w752 w753 w754 w755 w756 w757 w758 w759 w75a w75b w75c w75d w75e w75f w760 w761" ID="s5a"/>
      <tc:sentence tokenIDs="w762 w763 w764 w765 w766 w767 w768 w769 w76a w76b w76c w76d w76e w76f w770 w771 w772 w773 w774 w775 w776" ID="s5b"/>
      <tc:sentence tokenIDs="w777 w778 w779" ID="s5c"/>
      <tc:sentence tokenIDs="w77a w77b w77c w77d w77e w77f w780 w781 w782 w783 w784 w785 w786 w787 w788 w789 w78a w78b w78c w78d w78e w78f w790 w791 w792 w793 w794 w795 w796 w797 w798 w799 w79a w79b w79c w79d w79e w79f w7a0 w7a1 w7a2" ID="s5d"/>
      <tc:sentence tokenIDs="w7a3 w7a4 w7a5 w7a6 w7a7 w7a8 w7a9 w7aa w7ab w7ac w7ad w7ae w7af w7b0 w7b1 w7b2 w7b3" ID="s5e"/>
      <tc:sentence tokenIDs="w7b4 w7b5 w7b6" ID="s5f"/>
      <tc:sentence tokenIDs="w7b7 w7b8 w7b9 w7ba w7bb w7bc w7bd w7be w7bf" ID="s60"/>
      <tc:sentence tokenIDs="w7c0 w7c1 w7c2 w7c3 w7c4 w7c5 w7c6 w7c7 w7c8 w7c9 w7ca w7cb w7cc w7cd w7ce w7cf w7d0 w7d1 w7d2 w7d3 w7d4 w7d5 w7d6 w7d7 w7d8 w7d9 w7da w7db w7dc w7dd w7de w7df w7e0 w7e1 w7e2 w7e3 w7e4 w7e5 w7e6 w7e7 w7e8 w7e9 w7ea" ID="s61"/>
      <tc:sentence tokenIDs="w7eb w7ec w7ed w7ee w7ef w7f0 w7f1 w7f2 w7f3 w7f4 w7f5 w7f6 w7f7 w7f8 w7f9 w7fa w7fb w7fc w7fd w7fe w7ff w800 w801 w802 w803 w804 w805 w806 w807" ID="s62"/>
      <tc:sentence tokenIDs="w808 w809 w80a w80b w80c w80d w80e w80f w810 w811 w812 w813 w814 w815 w816 w817 w818 w819 w81a w81b w81c" ID="s63"/>
      <tc:sentence tokenIDs="w81d w81e w81f w820 w821 w822 w823 w824 w825 w826 w827 w828 w829 w82a w82b w82c w82d w82e w82f w830 w831 w832 w833 w834 w835 w836 w837 w838 w839 w83a w83b w83c w83d w83e w83f w840 w841 w842 w843 w844 w845 w846 w847 w848 w849 w84a w84b w84c w84d w84e w84f w850 w851 w852 w853 w854" ID="s64"/>
      <tc:sentence tokenIDs="w855 w856 w857 w858 w859 w85a w85b w85c w85d w85e w85f w860 w861 w862 w863 w864 w865 w866 w867 w868 w869 w86a w86b w86c w86d w86e w86f w870 w871 w872 w873 w874 w875 w876 w877" ID="s65"/>
      <tc:sentence tokenIDs="w878 w879 w87a w87b w87c w87d w87e w87f w880 w881 w882" ID="s66"/>
      <tc:sentence tokenIDs="w883 w884 w885 w886 w887 w888 w889 w88a w88b w88c w88d w88e w88f w890 w891 w892" ID="s67"/>
      <tc:sentence tokenIDs="w893 w894 w895 w896 w897 w898 w899 w89a w89b w89c w89d w89e w89f w8a0 w8a1 w8a2 w8a3 w8a4" ID="s68"/>
      <tc:sentence tokenIDs="w8a5 w8a6 w8a7 w8a8 w8a9 w8aa" ID="s69"/>
      <tc:sentence tokenIDs="w8ab w8ac w8ad w8ae w8af w8b0 w8b1 w8b2 w8b3 w8b4 w8b5 w8b6 w8b7 w8b8 w8b9 w8ba w8bb w8bc w8bd w8be w8bf w8c0 w8c1 w8c2 w8c3 w8c4 w8c5 w8c6" ID="s6a"/>
      <tc:sentence tokenIDs="w8c7 w8c8 w8c9 w8ca w8cb w8cc w8cd w8ce w8cf w8d0 w8d1 w8d2 w8d3 w8d4 w8d5 w8d6 w8d7 w8d8 w8d9 w8da w8db w8dc w8dd" ID="s6b"/>
      <tc:sentence tokenIDs="w8de w8df w8e0 w8e1 w8e2 w8e3 w8e4 w8e5 w8e6 w8e7 w8e8 w8e9 w8ea w8eb w8ec w8ed w8ee w8ef w8f0 w8f1 w8f2 w8f3 w8f4 w8f5 w8f6 w8f7 w8f8 w8f9 w8fa w8fb w8fc w8fd w8fe w8ff w900 w901" ID="s6c"/>
      <tc:sentence tokenIDs="w902 w903 w904 w905 w906 w907 w908 w909 w90a w90b w90c w90d w90e w90f w910 w911 w912" ID="s6d"/>
      <tc:sentence tokenIDs="w913 w914 w915 w916 w917 w918 w919 w91a w91b w91c w91d w91e w91f w920 w921 w922 w923 w924 w925 w926 w927 w928 w929 w92a" ID="s6e"/>
      <tc:sentence tokenIDs="w92b w92c w92d w92e w92f w930 w931 w932 w933 w934 w935 w936 w937" ID="s6f"/>
      <tc:sentence tokenIDs="w938 w939 w93a w93b w93c w93d w93e w93f w940 w941 w942 w943 w944" ID="s70"/>
      <tc:sentence tokenIDs="w945 w946 w947 w948 w949 w94a w94b w94c w94d w94e w94f w950 w951 w952 w953 w954 w955 w956" ID="s71"/>
      <tc:sentence tokenIDs="w957 w958 w959 w95a w95b w95c w95d w95e w95f w960 w961" ID="s72"/>
      <tc:sentence tokenIDs="w962 w963 w964 w965 w966 w967 w968 w969 w96a w96b w96c w96d w96e w96f w970 w971 w972 w973 w974 w975 w976 w977 w978 w979 w97a w97b w97c w97d w97e w97f w980 w981 w982 w983 w984 w985 w986 w987 w988" ID="s73"/>
      <tc:sentence tokenIDs="w989 w98a w98b w98c w98d w98e w98f w990 w991 w992 w993 w994" ID="s74"/>
      <tc:sentence tokenIDs="w995 w996 w997 w998 w999 w99a w99b w99c w99d w99e w99f" ID="s75"/>
      <tc:sentence tokenIDs="w9a0 w9a1 w9a2 w9a3 w9a4 w9a5 w9a6 w9a7 w9a8 w9a9 w9aa w9ab w9ac w9ad w9ae w9af w9b0 w9b1 w9b2 w9b3 w9b4 w9b5 w9b6 w9b7 w9b8 w9b9 w9ba w9bb w9bc w9bd w9be w9bf w9c0 w9c1 w9c2 w9c3 w9c4 w9c5 w9c6 w9c7 w9c8 w9c9" ID="s76"/>
      <tc:sentence tokenIDs="w9ca w9cb w9cc w9cd w9ce w9cf w9d0 w9d1 w9d2 w9d3 w9d4 w9d5 w9d6 w9d7 w9d8" ID="s77"/>
      <tc:sentence tokenIDs="w9d9 w9da w9db w9dc w9dd w9de w9df w9e0 w9e1 w9e2 w9e3 w9e4 w9e5 w9e6 w9e7 w9e8 w9e9 w9ea w9eb w9ec w9ed w9ee w9ef" ID="s78"/>
      <tc:sentence tokenIDs="w9f0 w9f1 w9f2 w9f3 w9f4 w9f5" ID="s79"/>
      <tc:sentence tokenIDs="w9f6 w9f7 w9f8 w9f9 w9fa w9fb w9fc w9fd w9fe w9ff wa00" ID="s7a"/>
      <tc:sentence tokenIDs="wa01 wa02 wa03 wa04 wa05 wa06 wa07 wa08 wa09 wa0a wa0b wa0c wa0d wa0e wa0f wa10 wa11 wa12 wa13 wa14 wa15 wa16 wa17 wa18" ID="s7b"/>
      <tc:sentence tokenIDs="wa19 wa1a wa1b wa1c wa1d wa1e wa1f wa20 wa21 wa22 wa23 wa24 wa25 wa26 wa27 wa28 wa29 wa2a wa2b wa2c wa2d wa2e wa2f wa30 wa31 wa32 wa33" ID="s7c"/>
      <tc:sentence tokenIDs="wa34 wa35 wa36 wa37 wa38 wa39 wa3a wa3b wa3c wa3d wa3e wa3f wa40 wa41 wa42 wa43 wa44 wa45 wa46 wa47 wa48 wa49 wa4a wa4b wa4c wa4d" ID="s7d"/>
      <tc:sentence tokenIDs="wa4e wa4f wa50 wa51 wa52 wa53 wa54" ID="s7e"/>
      <tc:sentence tokenIDs="wa55 wa56 wa57 wa58 wa59 wa5a wa5b wa5c wa5d" ID="s7f"/>
      <tc:sentence tokenIDs="wa5e wa5f wa60 wa61 wa62 wa63 wa64 wa65 wa66 wa67 wa68 wa69 wa6a wa6b wa6c wa6d wa6e wa6f wa70" ID="s80"/>
      <tc:sentence tokenIDs="wa71 wa72 wa73 wa74 wa75" ID="s81"/>
      <tc:sentence tokenIDs="wa76 wa77 wa78 wa79 wa7a wa7b wa7c wa7d wa7e wa7f wa80 wa81 wa82 wa83 wa84 wa85 wa86 wa87 wa88 wa89 wa8a wa8b wa8c wa8d wa8e wa8f wa90 wa91 wa92 wa93 wa94 wa95 wa96 wa97 wa98 wa99 wa9a wa9b wa9c wa9d wa9e wa9f waa0 waa1 waa2 waa3 waa4 waa5 waa6 waa7 waa8" ID="s82"/>
      <tc:sentence tokenIDs="waa9 waaa waab waac waad waae waaf wab0 wab1 wab2 wab3 wab4 wab5 wab6 wab7 wab8 wab9 waba wabb wabc wabd wabe wabf wac0 wac1 wac2 wac3" ID="s83"/>
      <tc:sentence tokenIDs="wac4 wac5 wac6 wac7 wac8 wac9 waca wacb wacc wacd wace wacf wad0 wad1 wad2 wad3 wad4 wad5 wad6 wad7 wad8 wad9 wada wadb wadc wadd wade wadf wae0 wae1 wae2" ID="s84"/>
      <tc:sentence tokenIDs="wae3 wae4 wae5 wae6 wae7 wae8 wae9 waea waeb waec waed waee waef" ID="s85"/>
      <tc:sentence tokenIDs="waf0 waf1 waf2 waf3 waf4 waf5 waf6 waf7" ID="s86"/>
      <tc:sentence tokenIDs="waf8 waf9 wafa wafb wafc wafd wafe waff wb00 wb01 wb02 wb03 wb04 wb05 wb06 wb07 wb08" ID="s87"/>
      <tc:sentence tokenIDs="wb09 wb0a wb0b wb0c wb0d wb0e wb0f wb10 wb11 wb12 wb13 wb14 wb15 wb16 wb17 wb18 wb19 wb1a wb1b wb1c wb1d wb1e" ID="s88"/>
      <tc:sentence tokenIDs="wb1f wb20 wb21 wb22 wb23 wb24 wb25 wb26 wb27 wb28 wb29 wb2a wb2b wb2c wb2d wb2e wb2f wb30 wb31 wb32 wb33 wb34 wb35 wb36 wb37 wb38 wb39 wb3a wb3b wb3c" ID="s89"/>
      <tc:sentence tokenIDs="wb3d wb3e wb3f wb40 wb41 wb42 wb43 wb44 wb45 wb46 wb47 wb48 wb49 wb4a wb4b wb4c wb4d wb4e wb4f wb50 wb51 wb52 wb53 wb54 wb55" ID="s8a"/>
      <tc:sentence tokenIDs="wb56 wb57 wb58 wb59 wb5a wb5b wb5c wb5d wb5e wb5f wb60 wb61 wb62 wb63 wb64 wb65 wb66 wb67 wb68 wb69 wb6a wb6b wb6c wb6d wb6e wb6f wb70 wb71 wb72 wb73 wb74" ID="s8b"/>
      <tc:sentence tokenIDs="wb75 wb76 wb77 wb78 wb79 wb7a wb7b wb7c wb7d" ID="s8c"/>
      <tc:sentence tokenIDs="wb7e wb7f wb80 wb81 wb82 wb83 wb84 wb85 wb86 wb87 wb88" ID="s8d"/>
      <tc:sentence tokenIDs="wb89 wb8a wb8b wb8c wb8d wb8e wb8f wb90 wb91 wb92 wb93 wb94 wb95 wb96 wb97 wb98 wb99 wb9a wb9b wb9c wb9d wb9e wb9f wba0 wba1" ID="s8e"/>
      <tc:sentence tokenIDs="wba2 wba3 wba4 wba5 wba6 wba7 wba8 wba9 wbaa wbab wbac wbad wbae wbaf wbb0" ID="s8f"/>
      <tc:sentence tokenIDs="wbb1 wbb2 wbb3 wbb4 wbb5 wbb6 wbb7 wbb8 wbb9 wbba wbbb wbbc wbbd wbbe wbbf wbc0 wbc1 wbc2 wbc3 wbc4 wbc5 wbc6 wbc7 wbc8" ID="s90"/>
      <tc:sentence tokenIDs="wbc9 wbca wbcb wbcc wbcd wbce wbcf" ID="s91"/>
      <tc:sentence tokenIDs="wbd0 wbd1 wbd2 wbd3 wbd4 wbd5 wbd6 wbd7 wbd8 wbd9 wbda wbdb wbdc wbdd wbde wbdf wbe0 wbe1 wbe2 wbe3 wbe4 wbe5 wbe6 wbe7 wbe8 wbe9 wbea wbeb wbec wbed wbee wbef wbf0 wbf1 wbf2 wbf3 wbf4 wbf5 wbf6 wbf7 wbf8 wbf9 wbfa wbfb wbfc wbfd wbfe wbff wc00 wc01 wc02 wc03 wc04 wc05 wc06 wc07 wc08 wc09 wc0a wc0b" ID="s92"/>
      <tc:sentence tokenIDs="wc0c wc0d wc0e wc0f wc10 wc11" ID="s93"/>
      <tc:sentence tokenIDs="wc12 wc13 wc14 wc15 wc16 wc17 wc18 wc19 wc1a wc1b wc1c" ID="s94"/>
      <tc:sentence tokenIDs="wc1d wc1e wc1f wc20 wc21 wc22 wc23 wc24 wc25 wc26 wc27 wc28 wc29 wc2a wc2b wc2c wc2d wc2e wc2f wc30 wc31 wc32 wc33 wc34 wc35 wc36 wc37 wc38 wc39 wc3a wc3b wc3c wc3d wc3e" ID="s95"/>
      <tc:sentence tokenIDs="wc3f wc40 wc41 wc42 wc43 wc44 wc45 wc46 wc47 wc48 wc49" ID="s96"/>
      <tc:sentence tokenIDs="wc4a wc4b wc4c wc4d wc4e wc4f wc50 wc51 wc52 wc53 wc54 wc55 wc56 wc57 wc58 wc59 wc5a wc5b wc5c wc5d wc5e wc5f wc60 wc61 wc62 wc63 wc64 wc65 wc66 wc67 wc68" ID="s97"/>
      <tc:sentence tokenIDs="wc69 wc6a wc6b wc6c wc6d wc6e wc6f wc70 wc71 wc72 wc73" ID="s98"/>
      <tc:sentence tokenIDs="wc74 wc75 wc76 wc77 wc78 wc79 wc7a wc7b wc7c wc7d wc7e wc7f wc80 wc81 wc82 wc83" ID="s99"/>
      <tc:sentence tokenIDs="wc84 wc85 wc86 wc87 wc88 wc89 wc8a wc8b wc8c wc8d wc8e wc8f wc90 wc91 wc92 wc93" ID="s9a"/>
      <tc:sentence tokenIDs="wc94" ID="s9b"/>
    </tc:sentences>
    <tc:namedEntities xmlns:tc="http://www.dspin.de/data/textcorpus" type="tuebadz8">
      <tc:entity class="PER" tokenIDs="w3c"/>
      <tc:entity class="PER" tokenIDs="w3e"/>
      <tc:entity class="OTH" tokenIDs="w68"/>
      <tc:entity class="OTH" tokenIDs="w6a w6b w6c"/>
      <tc:entity class="PER" tokenIDs="wb9"/>
      <tc:entity class="PER" tokenIDs="we8"/>
      <tc:entity class="PER" tokenIDs="wea"/>
      <tc:entity class="PER" tokenIDs="wee"/>
      <tc:entity class="PER" tokenIDs="wf0"/>
      <tc:entity class="PER" tokenIDs="wfa"/>
      <tc:entity class="PER" tokenIDs="wfc"/>
      <tc:entity class="PER" tokenIDs="w11d"/>
      <tc:entity class="PER" tokenIDs="w121"/>
      <tc:entity class="PER" tokenIDs="w14e"/>
      <tc:entity class="PER" tokenIDs="w150"/>
      <tc:entity class="ORG" tokenIDs="w15d w15e w15f w160"/>
      <tc:entity class="PER" tokenIDs="w190 w191"/>
      <tc:entity class="OTH" tokenIDs="w195 w196 w197"/>
      <tc:entity class="PER" tokenIDs="w19d"/>
      <tc:entity class="PER" tokenIDs="w19f"/>
      <tc:entity class="ORG" tokenIDs="w1df w1e0 w1e1"/>
      <tc:entity class="ORG" tokenIDs="w1e3 w1e4 w1e5"/>
      <tc:entity class="PER" tokenIDs="w1f0"/>
      <tc:entity class="PER" tokenIDs="w1f2"/>
      <tc:entity class="ORG" tokenIDs="w204"/>
      <tc:entity class="ORG" tokenIDs="w20a"/>
      <tc:entity class="OTH" tokenIDs="w21e w21f w220 w221"/>
      <tc:entity class="OTH" tokenIDs="w234 w235 w236 w237"/>
      <tc:entity class="PER" tokenIDs="w23b"/>
      <tc:entity class="PER" tokenIDs="w23d"/>
      <tc:entity class="PER" tokenIDs="w246"/>
      <tc:entity class="OTH" tokenIDs="w270 w271 w272"/>
      <tc:entity class="ORG" tokenIDs="w279"/>
      <tc:entity class="PER" tokenIDs="w289"/>
      <tc:entity class="PER" tokenIDs="w28b"/>
      <tc:entity class="ORG" tokenIDs="w2a8 w2a9"/>
      <tc:entity class="OTH" tokenIDs="w313 w314 w315"/>
      <tc:entity class="OTH" tokenIDs="w339 w33a w33b w33c"/>
      <tc:entity class="PER" tokenIDs="w38e"/>
      <tc:entity class="OTH" tokenIDs="w390 w391 w392 w393"/>
      <tc:entity class="ORG" tokenIDs="w439 w43a"/>
      <tc:entity class="PER" tokenIDs="w44d"/>
      <tc:entity class="PER" tokenIDs="w44f"/>
      <tc:entity class="OTH" tokenIDs="w47a w47b w47c"/>
      <tc:entity class="PER" tokenIDs="w4e3"/>
      <tc:entity class="PER" tokenIDs="w4f6"/>
      <tc:entity class="ORG" tokenIDs="w4fb"/>
      <tc:entity class="OTH" tokenIDs="w551 w552 w553"/>
      <tc:entity class="PER" tokenIDs="w56c"/>
      <tc:entity class="PER" tokenIDs="w5b6 w5b7"/>
      <tc:entity class="PER" tokenIDs="w5d9"/>
      <tc:entity class="PER" tokenIDs="w5db"/>
      <tc:entity class="OTH" tokenIDs="w5e0 w5e1 w5e2 w5e3"/>
      <tc:entity class="PER" tokenIDs="w68b"/>
      <tc:entity class="PER" tokenIDs="w6d2"/>
      <tc:entity class="PER" tokenIDs="w7f0 w7f1 w7f2 w7f3"/>
      <tc:entity class="PER" tokenIDs="w842"/>
      <tc:entity class="PER" tokenIDs="w844 w845 w846"/>
      <tc:entity class="PER" tokenIDs="w848"/>
      <tc:entity class="PER" tokenIDs="w84a w84b"/>
      <tc:entity class="PER" tokenIDs="w84d"/>
      <tc:entity class="PER" tokenIDs="w84f w850"/>
      <tc:entity class="ORG" tokenIDs="w863 w864 w865 w866 w867 w868 w869 w86a w86b w86c w86d w86e w86f w870 w871"/>
      <tc:entity class="LOC" tokenIDs="w873"/>
      <tc:entity class="LOC" tokenIDs="w875"/>
      <tc:entity class="PER" tokenIDs="w878"/>
      <tc:entity class="PER" tokenIDs="w87a"/>
      <tc:entity class="PER" tokenIDs="w87c"/>
      <tc:entity class="PER" tokenIDs="w87e"/>
      <tc:entity class="OTH" tokenIDs="w895 w896 w897 w898 w899 w89a w89b w89c w89d w89e w89f w8a0 w8a1 w8a2 w8a3"/>
      <tc:entity class="GPE" tokenIDs="w8a5"/>
      <tc:entity class="GPE" tokenIDs="w8a7"/>
      <tc:entity class="PER" tokenIDs="w8ab"/>
      <tc:entity class="PER" tokenIDs="w8ad"/>
      <tc:entity class="PER" tokenIDs="w8af"/>
      <tc:entity class="PER" tokenIDs="w8b1"/>
      <tc:entity class="PER" tokenIDs="w8c7"/>
      <tc:entity class="PER" tokenIDs="w8c9"/>
      <tc:entity class="PER" tokenIDs="w8cb"/>
      <tc:entity class="PER" tokenIDs="w8cd"/>
      <tc:entity class="PER" tokenIDs="w8cf"/>
      <tc:entity class="PER" tokenIDs="w8d1"/>
      <tc:entity class="PER" tokenIDs="w8d3"/>
      <tc:entity class="PER" tokenIDs="w8d5"/>
      <tc:entity class="PER" tokenIDs="w8d7"/>
      <tc:entity class="PER" tokenIDs="w8d9"/>
      <tc:entity class="ORG" tokenIDs="w8ee w8ef w8f0 w8f1"/>
      <tc:entity class="PER" tokenIDs="w902"/>
      <tc:entity class="PER" tokenIDs="w904 w905"/>
      <tc:entity class="PER" tokenIDs="w907"/>
      <tc:entity class="PER" tokenIDs="w909"/>
      <tc:entity class="PER" tokenIDs="w90b"/>
      <tc:entity class="PER" tokenIDs="w90d w90e"/>
      <tc:entity class="ORG" tokenIDs="w92b w92c w92d w92e w92f"/>
      <tc:entity class="PER" tokenIDs="w938"/>
      <tc:entity class="PER" tokenIDs="w93a w93b"/>
      <tc:entity class="PER" tokenIDs="w93d"/>
      <tc:entity class="PER" tokenIDs="w93f w940"/>
      <tc:entity class="OTH" tokenIDs="w946 w947 w948 w949 w94a w94b w94c w94d"/>
      <tc:entity class="OTH" tokenIDs="w952 w953 w954"/>
      <tc:entity class="PER" tokenIDs="w957"/>
      <tc:entity class="PER" tokenIDs="w959"/>
      <tc:entity class="PER" tokenIDs="w95b"/>
      <tc:entity class="PER" tokenIDs="w95d"/>
      <tc:entity class="ORG" tokenIDs="w989 w98a w98b w98c w98d w98e w98f w990 w991"/>
      <tc:entity class="PER" tokenIDs="w995"/>
      <tc:entity class="PER" tokenIDs="w997"/>
      <tc:entity class="PER" tokenIDs="w999"/>
      <tc:entity class="PER" tokenIDs="w99b"/>
      <tc:entity class="ORG" tokenIDs="w9af w9b0 w9b1 w9b2 w9b3 w9b4 w9b5 w9b6 w9b7 w9b8 w9b9 w9ba w9bb w9bc"/>
      <tc:entity class="ORG" tokenIDs="w9be w9bf"/>
      <tc:entity class="PER" tokenIDs="w9ca"/>
      <tc:entity class="PER" tokenIDs="w9cc"/>
      <tc:entity class="PER" tokenIDs="w9ce"/>
      <tc:entity class="PER" tokenIDs="w9d0"/>
      <tc:entity class="PER" tokenIDs="w9d2"/>
      <tc:entity class="PER" tokenIDs="w9d4"/>
      <tc:entity class="OTH" tokenIDs="w9da w9db w9dc w9dd w9de"/>
      <tc:entity class="ORG" tokenIDs="w9e3 w9e4 w9e5 w9e6 w9e7 w9e8 w9e9 w9ea w9eb w9ec w9ed w9ee"/>
      <tc:entity class="GPE" tokenIDs="w9f0"/>
      <tc:entity class="ORG" tokenIDs="w9f2"/>
      <tc:entity class="PER" tokenIDs="w9f6"/>
      <tc:entity class="PER" tokenIDs="w9f8"/>
      <tc:entity class="PER" tokenIDs="w9fa"/>
      <tc:entity class="PER" tokenIDs="w9fc"/>
      <tc:entity class="OTH" tokenIDs="wa02 wa03 wa04 wa05 wa06 wa07 wa08 wa09 wa0a wa0b wa0c wa0d wa0e wa0f"/>
      <tc:entity class="ORG" tokenIDs="wa14"/>
      <tc:entity class="PER" tokenIDs="wa19"/>
      <tc:entity class="PER" tokenIDs="wa1b"/>
      <tc:entity class="PER" tokenIDs="wa1d"/>
      <tc:entity class="PER" tokenIDs="wa1f"/>
      <tc:entity class="PER" tokenIDs="wa21"/>
      <tc:entity class="PER" tokenIDs="wa23"/>
      <tc:entity class="PER" tokenIDs="wa25"/>
      <tc:entity class="PER" tokenIDs="wa27"/>
      <tc:entity class="PER" tokenIDs="wa29"/>
      <tc:entity class="PER" tokenIDs="wa2b"/>
      <tc:entity class="PER" tokenIDs="wa2d"/>
      <tc:entity class="PER" tokenIDs="wa2f"/>
      <tc:entity class="OTH" tokenIDs="wa40 wa41 wa42 wa43 wa44"/>
      <tc:entity class="ORG" tokenIDs="wa46 wa47"/>
      <tc:entity class="GPE" tokenIDs="wa4a"/>
      <tc:entity class="ORG" tokenIDs="wa4c"/>
      <tc:entity class="PER" tokenIDs="wa4e"/>
      <tc:entity class="PER" tokenIDs="wa50"/>
      <tc:entity class="OTH" tokenIDs="wa65 wa66 wa67 wa68 wa69 wa6a wa6b wa6c wa6d wa6e"/>
      <tc:entity class="GPE" tokenIDs="wa71 wa72"/>
      <tc:entity class="ORG" tokenIDs="wa74"/>
      <tc:entity class="PER" tokenIDs="wa76"/>
      <tc:entity class="PER" tokenIDs="wa78"/>
      <tc:entity class="PER" tokenIDs="wa7a"/>
      <tc:entity class="PER" tokenIDs="wa7c"/>
      <tc:entity class="PER" tokenIDs="wa7e"/>
      <tc:entity class="PER" tokenIDs="wa80"/>
      <tc:entity class="PER" tokenIDs="wa82"/>
      <tc:entity class="PER" tokenIDs="wa84"/>
      <tc:entity class="PER" tokenIDs="wa86"/>
      <tc:entity class="PER" tokenIDs="wa88"/>
      <tc:entity class="PER" tokenIDs="wa8a"/>
      <tc:entity class="PER" tokenIDs="wa8c"/>
      <tc:entity class="OTH" tokenIDs="wa96 wa97 wa98"/>
      <tc:entity class="OTH" tokenIDs="wa9d wa9e wa9f waa0 waa1 waa2 waa3 waa4 waa5 waa6"/>
      <tc:entity class="PER" tokenIDs="waa9"/>
      <tc:entity class="PER" tokenIDs="waab"/>
      <tc:entity class="PER" tokenIDs="waad"/>
      <tc:entity class="PER" tokenIDs="waaf"/>
      <tc:entity class="PER" tokenIDs="wab1"/>
      <tc:entity class="PER" tokenIDs="wab3"/>
      <tc:entity class="PER" tokenIDs="wab5"/>
      <tc:entity class="PER" tokenIDs="wab7"/>
      <tc:entity class="PER" tokenIDs="wab9"/>
      <tc:entity class="PER" tokenIDs="wabb"/>
      <tc:entity class="PER" tokenIDs="wabd"/>
      <tc:entity class="PER" tokenIDs="wabf"/>
      <tc:entity class="ORG" tokenIDs="wac5"/>
      <tc:entity class="OTH" tokenIDs="wae0 wae1"/>
      <tc:entity class="ORG" tokenIDs="wae3 wae4 wae5 wae6 wae7"/>
      <tc:entity class="PER" tokenIDs="waf0"/>
      <tc:entity class="PER" tokenIDs="waf2 waf3"/>
      <tc:entity class="OTH" tokenIDs="wafa wafb wafc wafd wafe waff wb00"/>
      <tc:entity class="PER" tokenIDs="wb09"/>
      <tc:entity class="PER" tokenIDs="wb0b"/>
      <tc:entity class="PER" tokenIDs="wb0d"/>
      <tc:entity class="PER" tokenIDs="wb0f"/>
      <tc:entity class="PER" tokenIDs="wb11"/>
      <tc:entity class="PER" tokenIDs="wb13"/>
      <tc:entity class="PER" tokenIDs="wb15"/>
      <tc:entity class="PER" tokenIDs="wb17"/>
      <tc:entity class="PER" tokenIDs="wb19 wb1a"/>
      <tc:entity class="PER" tokenIDs="wb3d wb3e"/>
      <tc:entity class="PER" tokenIDs="wb40"/>
      <tc:entity class="PER" tokenIDs="wb42"/>
      <tc:entity class="PER" tokenIDs="wb44"/>
      <tc:entity class="PER" tokenIDs="wb46"/>
      <tc:entity class="PER" tokenIDs="wb48 wb49"/>
      <tc:entity class="PER" tokenIDs="wb4b"/>
      <tc:entity class="PER" tokenIDs="wb4d"/>
      <tc:entity class="PER" tokenIDs="wb4f"/>
      <tc:entity class="PER" tokenIDs="wb51"/>
      <tc:entity class="OTH" tokenIDs="wb62 wb63 wb64 wb65 wb66 wb67 wb68 wb69 wb6a wb6b wb6c wb6d wb6e wb6f wb70 wb71 wb72 wb73"/>
      <tc:entity class="ORG" tokenIDs="wb75 wb76 wb77 wb78"/>
      <tc:entity class="PER" tokenIDs="wb7e"/>
      <tc:entity class="PER" tokenIDs="wb80"/>
      <tc:entity class="PER" tokenIDs="wb82"/>
      <tc:entity class="PER" tokenIDs="wb84"/>
      <tc:entity class="ORG" tokenIDs="wb99 wb9a wb9b wb9c wb9d"/>
      <tc:entity class="PER" tokenIDs="wba2"/>
      <tc:entity class="PER" tokenIDs="wba4"/>
      <tc:entity class="PER" tokenIDs="wba6"/>
      <tc:entity class="PER" tokenIDs="wba8"/>
      <tc:entity class="PER" tokenIDs="wbaa"/>
      <tc:entity class="PER" tokenIDs="wbac"/>
      <tc:entity class="OTH" tokenIDs="wbbb wbbc wbbd wbbe wbbf wbc0 wbc1 wbc2 wbc3"/>
      <tc:entity class="ORG" tokenIDs="wbc5"/>
      <tc:entity class="PER" tokenIDs="wbc9 wbca wbcb"/>
      <tc:entity class="PER" tokenIDs="wbde"/>
      <tc:entity class="PER" tokenIDs="wbe0"/>
      <tc:entity class="PER" tokenIDs="wbe2"/>
      <tc:entity class="PER" tokenIDs="wbe4"/>
      <tc:entity class="PER" tokenIDs="wbe6"/>
      <tc:entity class="PER" tokenIDs="wbe8"/>
      <tc:entity class="PER" tokenIDs="wbea"/>
      <tc:entity class="PER" tokenIDs="wbec"/>
      <tc:entity class="PER" tokenIDs="wbee"/>
      <tc:entity class="PER" tokenIDs="wbf0"/>
      <tc:entity class="PER" tokenIDs="wbf2"/>
      <tc:entity class="PER" tokenIDs="wbf4"/>
      <tc:entity class="GPE" tokenIDs="wc0c wc0d"/>
      <tc:entity class="ORG" tokenIDs="wc0f"/>
      <tc:entity class="PER" tokenIDs="wc12"/>
      <tc:entity class="PER" tokenIDs="wc14"/>
      <tc:entity class="PER" tokenIDs="wc16"/>
      <tc:entity class="PER" tokenIDs="wc18"/>
      <tc:entity class="OTH" tokenIDs="wc30 wc31 wc32 wc33 wc34 wc35 wc36 wc37 wc38"/>
      <tc:entity class="PER" tokenIDs="wc3f"/>
      <tc:entity class="PER" tokenIDs="wc41"/>
      <tc:entity class="PER" tokenIDs="wc43"/>
      <tc:entity class="PER" tokenIDs="wc45"/>
      <tc:entity class="PER" tokenIDs="wc58"/>
      <tc:entity class="PER" tokenIDs="wc5a"/>
      <tc:entity class="PER" tokenIDs="wc5c"/>
      <tc:entity class="PER" tokenIDs="wc5e"/>
      <tc:entity class="GPE" tokenIDs="wc69"/>
      <tc:entity class="ORG" tokenIDs="wc6b"/>
      <tc:entity class="GPE" tokenIDs="wc6d"/>
      <tc:entity class="ORG" tokenIDs="wc6f wc70 wc71 wc72"/>
      <tc:entity class="PER" tokenIDs="wc74"/>
      <tc:entity class="PER" tokenIDs="wc76 wc77"/>
      <tc:entity class="PER" tokenIDs="wc79 wc7a wc7b"/>
      <tc:entity class="PER" tokenIDs="wc7d"/>
      <tc:entity class="PER" tokenIDs="wc7f"/>
      <tc:entity class="ORG" tokenIDs="wc91"/>
    </tc:namedEntities>
  </TextCorpus>
</D-Spin>