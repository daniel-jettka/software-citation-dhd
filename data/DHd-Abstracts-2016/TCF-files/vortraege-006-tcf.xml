<?xml version='1.0' encoding='UTF-8'?><D-Spin xmlns="http://www.dspin.de/data" version="5">
  <MetaData xmlns="http://www.dspin.de/data/metadata"><Services><cmd:CMD xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:cmd="http://www.clarin.eu/cmd/1" CMDVersion="1.2" xsi:schemaLocation="http://www.clarin.eu/cmd/1 http://catalog.clarin.eu/ds/ComponentRegistry/rest/registry/profiles/clarin.eu:cr1:p_1320657629623/xsd"><cmd:Resources><cmd:ResourceProxyList/><cmd:JournalFileProxyList/><cmd:ResourceRelationList/></cmd:Resources><cmd:Components><cmd:WebServiceToolChain><cmd:GeneralInfo><cmd:Descriptions><cmd:Description/></cmd:Descriptions><cmd:ResourceName>Custom chain</cmd:ResourceName><cmd:ResourceClass>Toolchain</cmd:ResourceClass></cmd:GeneralInfo><cmd:Toolchain><cmd:ToolInChain><cmd:PID>https://hdl.handle.net/21.11120/0000-0008-319A-3</cmd:PID><cmd:Parameter value="de" name="lang"/></cmd:ToolInChain><cmd:ToolInChain><cmd:PID>https://hdl.handle.net/21.11120/0000-0008-3183-C</cmd:PID><cmd:Parameter value="5" name="version"/></cmd:ToolInChain><cmd:ToolInChain><cmd:PID>http://hdl.handle.net/11022/0000-0007-DA29-6</cmd:PID><cmd:Parameter value="de" name="lang"/><cmd:Parameter value="5" name="version"/></cmd:ToolInChain></cmd:Toolchain></cmd:WebServiceToolChain></cmd:Components></cmd:CMD></Services></MetaData>
  <TextCorpus xmlns="http://www.dspin.de/data/textcorpus" lang="de">
    <textSource type="application/tei+xml;format-variant=tei-dta;tokenized=0">&lt;?xml version="1.0" encoding="UTF-8"?>
&lt;TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="vortraege-006">
&lt;teiHeader>
&lt;fileDesc>
&lt;titleStmt>
&lt;title>Automatische Textanalysen in der Geschichtswissenschaft – Auswertung, Interpretation und Relevanz &lt;/title>
&lt;author>
&lt;name>
&lt;surname>Fiedler&lt;/surname>
&lt;forename>Maik&lt;/forename>
&lt;/name>
&lt;affiliation>Georg Eckert Institut für internationale Schulbuchforschung, Deutschland&lt;/affiliation>
&lt;email>fiedler@gei.de&lt;/email>
&lt;/author>
&lt;author>
&lt;name>
&lt;surname>Weiß&lt;/surname>
&lt;forename>Andreas&lt;/forename>
&lt;/name>
&lt;affiliation>Georg Eckert Institut für internationale Schulbuchforschung, Deutschland&lt;/affiliation>
&lt;email>weiss@gei.de&lt;/email>
&lt;/author>
&lt;author>
&lt;name>
&lt;surname>Heuwing&lt;/surname>
&lt;forename>Ben&lt;/forename>
&lt;/name>
&lt;affiliation>Institut für Informationswissenschaft &amp;amp; Sprachtechnologie, Universität Hildesheim&lt;/affiliation>
&lt;email>heuwing@uni-hildesheim.de&lt;/email>
&lt;/author>
&lt;author>
&lt;name>
&lt;surname>Schnober&lt;/surname>
&lt;forename>Carsten&lt;/forename>
&lt;/name>
&lt;affiliation>Ubiquitous Knowledge Processing Lab, Deutsches Institut für Internationale Pädagogische Forschung / Technische Universität Darmstadt&lt;/affiliation>
&lt;email>schnober@ukp.informatik.tu-darmstadt.de&lt;/email>
&lt;/author>
&lt;/titleStmt>
&lt;editionStmt>
&lt;edition>
&lt;date>2015-10-15T15:22:00Z&lt;/date>
&lt;/edition>
&lt;/editionStmt>
&lt;publicationStmt>
&lt;publisher>Elisabeth Burr, Universität Leipzig&lt;/publisher>
&lt;address>
&lt;addrLine>Beethovenstr. 15&lt;/addrLine>
&lt;addrLine>04107 Leipzig&lt;/addrLine>
&lt;addrLine>Deutschland&lt;/addrLine>
&lt;addrLine>Elisabeth Burr&lt;/addrLine>
&lt;/address>
&lt;/publicationStmt>
&lt;sourceDesc>
&lt;p>Converted from a Word document &lt;/p>
&lt;/sourceDesc>
&lt;/fileDesc>
&lt;encodingDesc>
&lt;appInfo>
&lt;application ident="DHCONVALIDATOR" version="1.14">
&lt;label>DHConvalidator&lt;/label>
&lt;/application>
&lt;/appInfo>
&lt;/encodingDesc>
&lt;profileDesc>
&lt;textClass>
&lt;keywords scheme="ConfTool" n="category">
&lt;term>Vortrag&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="subcategory">
&lt;term>&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="keywords">
&lt;term>Meta-Analyse&lt;/term>
&lt;term>Validierung&lt;/term>
&lt;term>Topic Modelling&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="topics">
&lt;term>Teilen&lt;/term>
&lt;term>Umwandlung&lt;/term>
&lt;term>Datenerkennung&lt;/term>
&lt;term>Inhaltsanalyse&lt;/term>
&lt;term>Übersetzung&lt;/term>
&lt;term>Modellierung&lt;/term>
&lt;term>Kommunikation&lt;/term>
&lt;term>Theoretisierung&lt;/term>
&lt;term>Bereinigung&lt;/term>
&lt;term>Bewertung&lt;/term>
&lt;term>Webentwicklung&lt;/term>
&lt;term>Visualisierung&lt;/term>
&lt;term>Daten&lt;/term>
&lt;term>Infrastruktur&lt;/term>
&lt;term>Metadaten&lt;/term>
&lt;term>Methoden&lt;/term&gt;
&lt;term>Forschungsprozess&lt;/term>
&lt;term>Text&lt;/term>
&lt;/keywords>
&lt;/textClass>
&lt;/profileDesc>
&lt;/teiHeader>
&lt;text>
&lt;body>
&lt;div type="div1" rend="DH-Heading">
&lt;head>Motivation und Fragestellung&lt;/head>
&lt;p>In jedem Digital-Humanities-Projekt (DH) stellt sich die Frage von neuem: Welche

          „Relevanz haben die Modellierung, Vernetzung und Visualisierung für die

          Geistesartefakte selbst und für den Gewinn reproduzierbarer wissenschaftlicher

          Erkenntnisse über sie? Im Projekt „Welt der Kinder“ (WdK) wurden diese Punkte

          mit Hilfe von Topic Modeling und Text-Mining-Werkzeugen mit in der

          Geschichtswissenschaft anerkannten Thesen in einem kontrollierten Verfahren

          überprüft. Es handelt sich bei WdK mit seinem repräsentativen Textkorpus von

          über 3000 historischen Schulbüchern um ein bisher weltweit einzigartiges

          Projekt, das für künftige ähnliche Vorhaben vorbildhaft sein will. &lt;/p>
&lt;p>Aus Sicht der klassischen Geschichtswissenschaften gibt es bei der Bearbeitung

            großer Datenmengen häufig Argwohn gegenüber der Sekundäranalyse maschinell

            generierter Ergebnisse, verstärkt durch mangelndes Wissen über fachfremde

            Methodik. Dies lässt die Ergebnisse der DH oft als zweifelhaft oder nicht

            neuwertig erscheinen. Zusätzlich können Verzerrungen durch die Zusammensetzung

            einer Textsammlung entstehen, durch die Dokumentenauswahl und des zu

            analysierenden Vokabulars sowie aus den darauf aufbauenden Aggregierungen und

            Visualisierungen (Chuang et al. 2012). Große Datenmengen erfordern ein anderes

            Vorgehen bei der Auswertung als die traditionell in den Geschichtswissenschaften

            üblichen Verfahren. Die Methode der automatischen Textanalyse stellen trotzdem

            eine durch die Forschungsziele beeinflusste subjektive Sichtweise auf die

            vorhandenen Daten dar (DiMaggio et al. 2013). Wir zeigen an Hand eines in WdK

            vorgenommen Validierungsexperiments, welche Aushandlungsprozesse notwendig

            waren, um nachnutzbare und nachvollziehbare Ergebnisse zu erhalten. &lt;/p>
&lt;p>Für die Meta-Analyse von klassischen und digitalen geschichtswissenschaftlichen

              Herangehensweisen ist die Beantwortung folgender Fragen prioritär:&lt;/p>
&lt;p>
&lt;hi rend="bold">Erstens)&lt;/hi> Wie können auf klassischem Weg erbrachte

                Ergebnisse für die DH so codifiziert werden, dass sie nicht nur für Menschen

                interpretierbar, sondern auch durch die digitalen Werkzeuge reproduzierbar sind?

                Sinn dieses Verfahrens ist es, Versuchsanordnungen und Analysen so aufzubauen,

                dass diese nicht immer „bei Null“ beginnen müssen, sondern, wie ein klassischer

                Fachtext, anerkannte Annahmen und Erkenntnisse implizit transportieren und

                wiederholen. &lt;/p>
&lt;p>
&lt;hi rend="bold">Zweitens)&lt;/hi> Wie kann die Belastbarkeit von Ergebnissen, die

                  mit Hilfe von Methoden der automatischen Textmodellierung auf einem

                  umfangreichen Korpus erbracht worden sind, validiert werden? &lt;/p>
&lt;p>
&lt;hi rend="bold">Drittens)&lt;/hi> Wie kann man die Leistung digitaler Methoden für

                    explorative Analysen anwenden, ohne auf ein bereits feststehendes Ziel

                    hinzuarbeiten? &lt;/p>
&lt;p>
&lt;hi rend="bold">Viertens)&lt;/hi> Wie müssen die Versuchsanordnung und das Projekt

                      aufgebaut werden, um den Daten zu vertrauen und sie interpretieren sowie

                      kontextualisieren zu können? &lt;/p>
&lt;p>Der Vortrag wird den Arbeitsprozess (interdisziplinäre Arbeit an historischen

                        Thesen mit Hilfe digitaler Tools) analysieren, die verschiedenen

                        fachspezifischen Methoden problematisieren sowie schlaglichtartig Wege

                        beleuchten, die zu möglichen Antworten auf die gestellten Fragen führen können.
&lt;/p>
&lt;/div>
&lt;div type="div1" rend="DH-Heading">
&lt;head>Werkzeuge&lt;/head>
&lt;p>Die Grundlage der Topic-Modelling-basierten Analyse besteht auf im Bereich DH

                        etablierter Methoden wie LDA (&lt;hi rend="italic">Latent Dirichlet

                        Allocation&lt;/hi>; Blei et al. 2003). Dieses Verfahren ordnet Begriffe auf Basis

                        von Kookkurrenz und statistischen Analysen einander zu und extrahiert Topics in

                        Form gewichteter Wortlisten. Diese ergeben für menschliche Benutzer

                        interpretierbare Listen, und erlauben eine automatische Inferenz von

                        Topic-Verteilungen innerhalb eines Dokuments.&lt;/p>
&lt;p>Die Validierungsstudie wurde mit einem interaktiven Prototyp durchgeführt, der

                          die Texte im Korpus und Statistiken über die Ergebnismengen zugänglich macht.

                          Suchanfragen können sich auf Metadaten – beispielsweise Jahr und Ort der

                          Veröffentlichung oder Schultyp – Termanfragen und Topic-Verteilungen beziehen.

                          Ergebnisse werden mit Statistiken zur Topic-Intensität und relativen

                          Dokumentenhäufigkeit im Zeitverlauf ausgegeben. &lt;/p>
&lt;/div>
&lt;div type="div1" rend="DH-Heading">
&lt;head>Vorgehen bei der Validierung:&lt;/head>
&lt;p>Belastbarkeitsüberprüfungen bauen Vertrauen in datenbasierte, historische

                            Schlussfolgerungen und Annahmen auf. So wird überprüft, ob die statistischen

                            Modelle existierende Erkenntnisse mehrheitlich bestätigen, und als wie

                            zuverlässig bestätigende oder widerlegende Ergebnisse eingeschätzt werden

                            (DiMaggio et al. 2013; Evans 2014). Die im Experiment bearbeiteten historischen

                            Thesen stellten Sachverhalte dar, die sich quantitativ überprüfen lassen, etwa

                            durch den Vergleich von Topic-Verteilungen (Newman / Block 2006; Yang et al.

                            2011), und im Nachhinein von Experten für das jeweilige Fachgebiet in Hinblick

                            auf ihre Plausibilität überprüft werden. &lt;/p>
&lt;p>Für die Validierungsstudie wurden zu überprüfende Thesen vorab definiert, um

                              Abweichungen von der ursprünglichen Fragestellung zu dokumentieren. Sie sind

                              repräsentativ für reale historische Fragestellungen im Rahmen des Projektes

                              (Kolonien und Auswanderung; Französische Revolution und Befreiungskriege;

                              deutsche Kriegsflotte). Dabei wurden in einem ersten Schritt Begrifflichkeiten

                              und Interpretationen der Fragestellungen in interdisziplinären Arbeitsgruppen

                              diskutiert, um fachliche Verständnisschwierigkeiten auszuräumen. Da die Thesen

                              erschöpfend und präzise mit den vorhandenen Werkzeugen untersucht wurden, bilden

                              auch die Auswertungsstrategien mögliche Vorgehensweisen für die Überprüfung

                              bereits vorliegender Hypothesen ab.&lt;/p>
&lt;/div>
&lt;div type="div1" rend="DH-Heading">
&lt;head>Auswertung&lt;/head>
&lt;p>Bei der Analyse der Thesen zeigten sich unterschiedliche Strategien für die

                                einzelnen Schritte der Auswertung. Wichtig hierbei war, ob unterschiedliche

                                Herangehensweisen, vergleichbare Ergebnisse reproduzierten. Die Ergebnisse der

                                einzelnen Arbeitsgruppen widersprachen einander an wenigen Stellen, und

                                gegebenenfalls primär in ihrer Bewertung der Verlässlichkeit der Ergebnisse. Die

                                vorgegebenen geschichtswissenschaftlichen Thesen wurden in den Versuchen mit

                                Topic-Modellen größtenteils bestätigt und zusätzlich mittels Termanfragen

                                validiert.&lt;/p>
&lt;p>Das Vorgehen bei den Topic-Modelling-basierten Analysen beinhaltete im ersten

                                  Schritt eine Suche nach relevanten Topics an Hand einzelner Terme. Dabei zeigte

                                  sich, dass die Topics in Modellen mit einer manuell überschaubaren Topic-Anzahl

                                  (50, 100, 200) für spezielle historische Forschungsfragen zu allgemein oder auch

                                  zu spezifisch ausfielen. Teilweise wurden daraufhin die Thesen stellvertretend

                                  an Hand thematischer Teilgebiete oder übergeordneter Themen untersucht.&lt;/p>
&lt;p>Für eine höhere Genauigkeit wurden auch Kombinationen aus Termsuche und

                                    Dokumentenfiltern auf Basis automatisch generierter Topics eingesetzt. Für eine

                                    Bewertung der Abfragegenauigkeit wurden manuelle Inspektionen der relevantesten

                                    Trefferdokumente durchgeführt und Anfragen iterativ neu formuliert. Um für die

                                    Validierung eine Vergleichsebene bereitzustellen, wurden zusätzliche Analysen

                                    nur auf der Grundlage manuell und mittels historischen Vorwissens gewählter

                                    Terme durchgeführt.&lt;/p>
&lt;/div>
&lt;div type="div1" rend="DH-Heading">
&lt;head>Schlussfolgerungen&lt;/head>
&lt;p>
&lt;anchor xml:id="move43120845513"/>Zusammengefasst kann zwischen zwei

                                      grundlegenden Vorgehensweisen unterschieden werden. In der ersten Variante

                                      werden die aufgestellten Thesen konfirmatorisch überprüft. Diese werden dafür

                                      formalisiert und in Form von Suchanfragen und zu erwartenden Ergebnissen

                                      operationalisiert. Die Ergebnisse werden dann vor allem hinsichtlich der

                                      erwarteten Zeitverläufe und relativen Unterschiede zwischen Untermengen

                                      interpretiert. &lt;/p>
&lt;p>Die explorative Herangehensweise an die Datenanalyse berücksichtigt dagegen auch

                                        andere Hinweise aus den Ergebnissen, und sucht nach Erklärungen für beobachtete

                                        Auffälligkeiten. Die Aussagekraft der Ergebnisse kann dabei jedoch dadurch

                                        eingeschränkt werden, dass die untersuchten Thesen erst mit Kenntnis der Daten

                                        formuliert worden sind. Eine Strategie, um diese Unsicherheit auszugleichen,

                                        besteht darin, Evidenz für eine Aussage mit mehreren unterschiedlichen

                                        Vorgehensweisen zu sammeln.&lt;/p>
&lt;p>
&lt;anchor xml:id="move431207206"/>
&lt;anchor xml:id="move43120720614"/>Diese Ergebnisse zeigen den potentiellen

                                          Mehrwert von DH an, da mit Hilfe computerlinguistischer und

                                          informationswissenschaftlicher Methoden klassische Thesen aus der

                                          Geschichtswissenschaft präzisiert werden konnten. Die Interpretation

                                          quantitativer Ergebnisse, etwa als Diagramm visualisiert, konnte sich nach

                                          Bedarf auf die vorab definierten Vorannahmen beschränken. Die Einbeziehung

                                          größerer zeitlicher Kontexte erforderte teilweise, die dargestellten Verläufe

                                          und Tendenzen mit verschiedenen Zeitspannen neu zu interpretieren. Als wichtige

                                          Vorgehensweise hat sich hier die Bildung eines gleitenden Durchschnitts über

                                          längere Zeiträume erwiesen, um thematische Tendenzen zuverlässiger

                                          interpretieren zu können. &lt;/p>
&lt;p>Als wichtiger Faktor stellte sich auch die Qualität der OCR-Digitalisierung

                                            heraus. Bei Daten aus historischen Quellen (Schriftbild Sütterlin / Fraktur)

                                            werden auch mit aktueller Technologie aufgrund der verwendeten Schriftarten

                                            teilweise über 10 Prozent der Zeichen falsch erkannt, was bei der Auswertung der

                                            maschinell generierten Topics durch die Benutzer zu Problemen bei der

                                            Interpretation und Weiterverwendung führt. Daher muss die Frage gestellt werden,

                                            wie Daten zukünftig in den Vorverarbeitungsschritten aufbereitet werden, damit

                                            Topic Modelling und andere automatische Methoden zu hilfreichen und

                                            interpretierbaren Ergebnissen führen.&lt;/p>
&lt;p>Neben der Einbeziehung von Topic Models, die auf unterschiedliche Perspektiven

                                              optimiert wurden, werden im Rahmen des Projektes andere Herangehensweisen an die

                                              statistische Textmodellierung, wie z. B. Clustering-Verfahren, in Hinblick auf

                                              ihre Anwendbarkeit und Robustheit vergleichend evaluiert. In diesem Zusammenhang

                                              ist es wichtig, thematisch relevante Topics einfach auffindbar zu machen und sie

                                              für Anfragen kombinieren zu können. Des Weiteren sollten Topics geordnet nach

                                              Themen oder Diskursfeldern und / oder -strängen präsentiert werden sowie in

                                              einer leicht lesbaren Anzeige deren synchrone und diachrone Verteilungen

                                              herausstellen, wobei Ungleichverteilungen innerhalb der Untersuchungsmenge und

                                              die Zuverlässigkeit statistischer Aggregierungen deutlich gemacht werden müssen. &lt;/p>
&lt;/div>
&lt;/body>
&lt;back>
&lt;div type="bibliogr">
&lt;listBibl>
&lt;head>Bibliographie&lt;/head>
&lt;bibl>
&lt;hi rend="bold">Blei, David. M. / Ng, Andrew. Y. / Jordan, Michael I.&lt;/hi>

                                                  (2003): "Latent Dirichlet allocation", in: &lt;hi rend="italic">Journal of

                                                  Machine Learning Research&lt;/hi> 3: 993–1022.&lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Chuang, Jason / Ramage, Daniel / Manning, Chistopher / Heer,

                                                      Jeffrey &lt;/hi> (2012): "Interpretation and Trust: Designing Model-driven

                                                      Visualizations for Text Analysis", in: &lt;hi rend="italic">Proceedings of the

                                                      SIGCHI Conference on Human Factors in Computing Systems&lt;/hi>, &lt;hi

                                                      rend="italic">CHI ’12&lt;/hi>. New York, NY, USA: ACM 443–452. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">DiMaggio, Paul / Nag, Manish / Blei, David&lt;/hi> (2013):

                                                        "Exploiting affinities between topic modeling and the sociological

                                                        perspective on culture: Application to newspaper coverage of U.S. government

                                                        arts funding", in: &lt;hi rend="italic">Poetics&lt;/hi> 41, 6: 570–606. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Evans, Michael S.&lt;/hi> (2014): "A Computational Approach to

                                                          Qualitative Analysis in Large Textual Datasets", in: &lt;hi rend="italic">PLoS

                                                          ONE&lt;/hi>9, 2, e87908. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Kaplan, Frédéric&lt;/hi> (2015): "A map for Big Data research

                                                            in Digital Humanities", in: &lt;hi rend="italic">Frontiers in Digital

                                                            Humanities&lt;/hi> 2, 1: &lt;ref

                                                            target="http://journal.frontiersin.org/article/10.3389/fdigh.2015.00001/abstract"
>http://journal.frontiersin.org/article/10.3389/fdigh.2015.00001/abstract&lt;/ref>

                                                            [letzter Zugriff 08. Januar 2016]. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Newman, David J. / Block, Sharon &lt;/hi> (2006):

                                                              "Probabilistic topic decomposition of an eighteenth-century American

                                                              newspaper", in: &lt;hi rend="italic">Journal of the American Society for

                                                              Information Science and Technology&lt;/hi> 57, 6: 753–767. &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Yang, Tze-I. / Torget, Andrew J. / Mihalcea, Rada &lt;/hi>

                                                                (2011): "Topic modeling on historical newspapers", in: &lt;hi rend="italic"
>Proceedings of the 5th ACL-HLT Workshop on Language Technology for

                                                                Cultural Heritage, Social Sciences, and Humanities&lt;/hi>. Association for

                                                                Computational Linguistics 96–104. &lt;/bibl>
&lt;/listBibl>
&lt;/div>
&lt;/back>
&lt;/text>
&lt;/TEI>
    </textSource>
    <text>


In jedem Digital-Humanities-Projekt (DH) stellt sich die Frage von neuem: Welche           „Relevanz haben die Modellierung, Vernetzung und Visualisierung für die           Geistesartefakte selbst und für den Gewinn reproduzierbarer wissenschaftlicher           Erkenntnisse über sie? Im Projekt „Welt der Kinder“ (WdK) wurden diese Punkte           mit Hilfe von Topic Modeling und Text-Mining-Werkzeugen mit in der           Geschichtswissenschaft anerkannten Thesen in einem kontrollierten Verfahren           überprüft. Es handelt sich bei WdK mit seinem repräsentativen Textkorpus von           über 3000 historischen Schulbüchern um ein bisher weltweit einzigartiges           Projekt, das für künftige ähnliche Vorhaben vorbildhaft sein will. 

  

Aus Sicht der klassischen Geschichtswissenschaften gibt es bei der Bearbeitung             großer Datenmengen häufig Argwohn gegenüber der Sekundäranalyse maschinell             generierter Ergebnisse, verstärkt durch mangelndes Wissen über fachfremde             Methodik. Dies lässt die Ergebnisse der DH oft als zweifelhaft oder nicht             neuwertig erscheinen. Zusätzlich können Verzerrungen durch die Zusammensetzung             einer Textsammlung entstehen, durch die Dokumentenauswahl und des zu             analysierenden Vokabulars sowie aus den darauf aufbauenden Aggregierungen und             Visualisierungen (Chuang et al. 2012). Große Datenmengen erfordern ein anderes             Vorgehen bei der Auswertung als die traditionell in den Geschichtswissenschaften             üblichen Verfahren. Die Methode der automatischen Textanalyse stellen trotzdem             eine durch die Forschungsziele beeinflusste subjektive Sichtweise auf die             vorhandenen Daten dar (DiMaggio et al. 2013). Wir zeigen an Hand eines in WdK             vorgenommen Validierungsexperiments, welche Aushandlungsprozesse notwendig             waren, um nachnutzbare und nachvollziehbare Ergebnisse zu erhalten. 

  

Für die Meta-Analyse von klassischen und digitalen geschichtswissenschaftlichen               Herangehensweisen ist die Beantwortung folgender Fragen prioritär:

  

  Erstens) Wie können auf klassischem Weg erbrachte                 Ergebnisse für die DH so codifiziert werden, dass sie nicht nur für Menschen                 interpretierbar, sondern auch durch die digitalen Werkzeuge reproduzierbar sind?                 Sinn dieses Verfahrens ist es, Versuchsanordnungen und Analysen so aufzubauen,                 dass diese nicht immer „bei Null“ beginnen müssen, sondern, wie ein klassischer                 Fachtext, anerkannte Annahmen und Erkenntnisse implizit transportieren und                 wiederholen. 

  

  Zweitens) Wie kann die Belastbarkeit von Ergebnissen, die                   mit Hilfe von Methoden der automatischen Textmodellierung auf einem                   umfangreichen Korpus erbracht worden sind, validiert werden? 

  

  Drittens) Wie kann man die Leistung digitaler Methoden für                     explorative Analysen anwenden, ohne auf ein bereits feststehendes Ziel                     hinzuarbeiten? 

  

  Viertens) Wie müssen die Versuchsanordnung und das Projekt                       aufgebaut werden, um den Daten zu vertrauen und sie interpretieren sowie                       kontextualisieren zu können? 

  

Der Vortrag wird den Arbeitsprozess (interdisziplinäre Arbeit an historischen                         Thesen mit Hilfe digitaler Tools) analysieren, die verschiedenen                         fachspezifischen Methoden problematisieren sowie schlaglichtartig Wege                         beleuchten, die zu möglichen Antworten auf die gestellten Fragen führen können.  

  


Die Grundlage der Topic-Modelling-basierten Analyse besteht auf im Bereich DH                         etablierter Methoden wie LDA (Latent Dirichlet                      Allocation; Blei et al. 2003). Dieses Verfahren ordnet Begriffe auf Basis                         von Kookkurrenz und statistischen Analysen einander zu und extrahiert Topics in                         Form gewichteter Wortlisten. Diese ergeben für menschliche Benutzer                         interpretierbare Listen, und erlauben eine automatische Inferenz von                         Topic-Verteilungen innerhalb eines Dokuments.

  

Die Validierungsstudie wurde mit einem interaktiven Prototyp durchgeführt, der                           die Texte im Korpus und Statistiken über die Ergebnismengen zugänglich macht.                           Suchanfragen können sich auf Metadaten – beispielsweise Jahr und Ort der                           Veröffentlichung oder Schultyp – Termanfragen und Topic-Verteilungen beziehen.                           Ergebnisse werden mit Statistiken zur Topic-Intensität und relativen                           Dokumentenhäufigkeit im Zeitverlauf ausgegeben. 


    

Belastbarkeitsüberprüfungen bauen Vertrauen in datenbasierte, historische                             Schlussfolgerungen und Annahmen auf. So wird überprüft, ob die statistischen                             Modelle existierende Erkenntnisse mehrheitlich bestätigen, und als wie                             zuverlässig bestätigende oder widerlegende Ergebnisse eingeschätzt werden                             (DiMaggio et al. 2013; Evans 2014). Die im Experiment bearbeiteten historischen                             Thesen stellten Sachverhalte dar, die sich quantitativ überprüfen lassen, etwa                             durch den Vergleich von Topic-Verteilungen (Newman / Block 2006; Yang et al.                             2011), und im Nachhinein von Experten für das jeweilige Fachgebiet in Hinblick                             auf ihre Plausibilität überprüft werden. 

  

Für die Validierungsstudie wurden zu überprüfende Thesen vorab definiert, um                               Abweichungen von der ursprünglichen Fragestellung zu dokumentieren. Sie sind                               repräsentativ für reale historische Fragestellungen im Rahmen des Projektes                               (Kolonien und Auswanderung; Französische Revolution und Befreiungskriege;                               deutsche Kriegsflotte). Dabei wurden in einem ersten Schritt Begrifflichkeiten                               und Interpretationen der Fragestellungen in interdisziplinären Arbeitsgruppen                               diskutiert, um fachliche Verständnisschwierigkeiten auszuräumen. Da die Thesen                               erschöpfend und präzise mit den vorhandenen Werkzeugen untersucht wurden, bilden                               auch die Auswertungsstrategien mögliche Vorgehensweisen für die Überprüfung                               bereits vorliegender Hypothesen ab.


    

Bei der Analyse der Thesen zeigten sich unterschiedliche Strategien für die                                 einzelnen Schritte der Auswertung. Wichtig hierbei war, ob unterschiedliche                                 Herangehensweisen, vergleichbare Ergebnisse reproduzierten. Die Ergebnisse der                                 einzelnen Arbeitsgruppen widersprachen einander an wenigen Stellen, und                                 gegebenenfalls primär in ihrer Bewertung der Verlässlichkeit der Ergebnisse. Die                                 vorgegebenen geschichtswissenschaftlichen Thesen wurden in den Versuchen mit                                 Topic-Modellen größtenteils bestätigt und zusätzlich mittels Termanfragen                                 validiert.

  

Das Vorgehen bei den Topic-Modelling-basierten Analysen beinhaltete im ersten                                   Schritt eine Suche nach relevanten Topics an Hand einzelner Terme. Dabei zeigte                                   sich, dass die Topics in Modellen mit einer manuell überschaubaren Topic-Anzahl                                   (50, 100, 200) für spezielle historische Forschungsfragen zu allgemein oder auch                                   zu spezifisch ausfielen. Teilweise wurden daraufhin die Thesen stellvertretend                                   an Hand thematischer Teilgebiete oder übergeordneter Themen untersucht.

  

Für eine höhere Genauigkeit wurden auch Kombinationen aus Termsuche und                                     Dokumentenfiltern auf Basis automatisch generierter Topics eingesetzt. Für eine                                     Bewertung der Abfragegenauigkeit wurden manuelle Inspektionen der relevantesten                                     Trefferdokumente durchgeführt und Anfragen iterativ neu formuliert. Um für die                                     Validierung eine Vergleichsebene bereitzustellen, wurden zusätzliche Analysen                                     nur auf der Grundlage manuell und mittels historischen Vorwissens gewählter                                     Terme durchgeführt.


    

  Zusammengefasst kann zwischen zwei                                       grundlegenden Vorgehensweisen unterschieden werden. In der ersten Variante                                       werden die aufgestellten Thesen konfirmatorisch überprüft. Diese werden dafür                                       formalisiert und in Form von Suchanfragen und zu erwartenden Ergebnissen                                       operationalisiert. Die Ergebnisse werden dann vor allem hinsichtlich der                                       erwarteten Zeitverläufe und relativen Unterschiede zwischen Untermengen                                       interpretiert. 

  

Die explorative Herangehensweise an die Datenanalyse berücksichtigt dagegen auch                                         andere Hinweise aus den Ergebnissen, und sucht nach Erklärungen für beobachtete                                         Auffälligkeiten. Die Aussagekraft der Ergebnisse kann dabei jedoch dadurch                                         eingeschränkt werden, dass die untersuchten Thesen erst mit Kenntnis der Daten                                         formuliert worden sind. Eine Strategie, um diese Unsicherheit auszugleichen,                                         besteht darin, Evidenz für eine Aussage mit mehreren unterschiedlichen                                         Vorgehensweisen zu sammeln.

  

    Diese Ergebnisse zeigen den potentiellen                                           Mehrwert von DH an, da mit Hilfe computerlinguistischer und                                           informationswissenschaftlicher Methoden klassische Thesen aus der                                           Geschichtswissenschaft präzisiert werden konnten. Die Interpretation                                           quantitativer Ergebnisse, etwa als Diagramm visualisiert, konnte sich nach                                           Bedarf auf die vorab definierten Vorannahmen beschränken. Die Einbeziehung                                           größerer zeitlicher Kontexte erforderte teilweise, die dargestellten Verläufe                                           und Tendenzen mit verschiedenen Zeitspannen neu zu interpretieren. Als wichtige                                           Vorgehensweise hat sich hier die Bildung eines gleitenden Durchschnitts über                                           längere Zeiträume erwiesen, um thematische Tendenzen zuverlässiger                                           interpretieren zu können. 

  

Als wichtiger Faktor stellte sich auch die Qualität der OCR-Digitalisierung                                             heraus. Bei Daten aus historischen Quellen (Schriftbild Sütterlin / Fraktur)                                             werden auch mit aktueller Technologie aufgrund der verwendeten Schriftarten                                             teilweise über 10 Prozent der Zeichen falsch erkannt, was bei der Auswertung der                                             maschinell generierten Topics durch die Benutzer zu Problemen bei der                                             Interpretation und Weiterverwendung führt. Daher muss die Frage gestellt werden,                                             wie Daten zukünftig in den Vorverarbeitungsschritten aufbereitet werden, damit                                             Topic Modelling und andere automatische Methoden zu hilfreichen und                                             interpretierbaren Ergebnissen führen.

  

Neben der Einbeziehung von Topic Models, die auf unterschiedliche Perspektiven                                               optimiert wurden, werden im Rahmen des Projektes andere Herangehensweisen an die                                               statistische Textmodellierung, wie z. B. Clustering-Verfahren, in Hinblick auf                                               ihre Anwendbarkeit und Robustheit vergleichend evaluiert. In diesem Zusammenhang                                               ist es wichtig, thematisch relevante Topics einfach auffindbar zu machen und sie                                               für Anfragen kombinieren zu können. Des Weiteren sollten Topics geordnet nach                                               Themen oder Diskursfeldern und / oder -strängen präsentiert werden sowie in                                               einer leicht lesbaren Anzeige deren synchrone und diachrone Verteilungen                                               herausstellen, wobei Ungleichverteilungen innerhalb der Untersuchungsmenge und                                               die Zuverlässigkeit statistischer Aggregierungen deutlich gemacht werden müssen. 

  

  



Motivation und Fragestellung



Werkzeuge



Vorgehen bei der Validierung:



Auswertung



Schlussfolgerungen



  

        Blei, David. M. / Ng, Andrew. Y. / Jordan, Michael I.                                                   (2003): "Latent Dirichlet allocation", in: Journal of                                                   Machine Learning Research 3: 993–1022.    Chuang, Jason / Ramage, Daniel / Manning, Chistopher / Heer,                                                       Jeffrey  (2012): "Interpretation and Trust: Designing Model-driven                                                       Visualizations for Text Analysis", in: Proceedings of the                                                       SIGCHI Conference on Human Factors in Computing Systems, CHI ’12. New York, NY, USA: ACM 443–452.     DiMaggio, Paul / Nag, Manish / Blei, David (2013):                                                         "Exploiting affinities between topic modeling and the sociological                                                         perspective on culture: Application to newspaper coverage of U.S. government                                                         arts funding", in: Poetics 41, 6: 570–606.     Evans, Michael S. (2014): "A Computational Approach to                                                           Qualitative Analysis in Large Textual Datasets", in: PLoS                                                           ONE9, 2, e87908.     Kaplan, Frédéric (2015): "A map for Big Data research                                                             in Digital Humanities", in: Frontiers in Digital                                                             Humanities 2, 1: 
http://journal.frontiersin.org/article/10.3389/fdigh.2015.00001/abstract
                                                             [letzter Zugriff 08. Januar 2016].     Newman, David J. / Block, Sharon  (2006):                                                               "Probabilistic topic decomposition of an eighteenth-century American                                                               newspaper", in: Journal of the American Society for                                                               Information Science and Technology 57, 6: 753–767.     Yang, Tze-I. / Torget, Andrew J. / Mihalcea, Rada                                                                  (2011): "Topic modeling on historical newspapers", in: Proceedings of the 5th ACL-HLT Workshop on Language Technology for                                                                 Cultural Heritage, Social Sciences, and Humanities. Association for                                                                 Computational Linguistics 96–104.     

  



Bibliographie

</text>
    <tc:tokens xmlns:tc="http://www.dspin.de/data/textcorpus">
      <tc:token ID="w1">In</tc:token>
      <tc:token ID="w2">jedem</tc:token>
      <tc:token ID="w3">Digital-Humanities-Projekt</tc:token>
      <tc:token ID="w4">(</tc:token>
      <tc:token ID="w5">DH</tc:token>
      <tc:token ID="w6">)</tc:token>
      <tc:token ID="w7">stellt</tc:token>
      <tc:token ID="w8">sich</tc:token>
      <tc:token ID="w9">die</tc:token>
      <tc:token ID="wa">Frage</tc:token>
      <tc:token ID="wb">von</tc:token>
      <tc:token ID="wc">neuem</tc:token>
      <tc:token ID="wd">:</tc:token>
      <tc:token ID="we">Welche</tc:token>
      <tc:token ID="wf">„</tc:token>
      <tc:token ID="w10">Relevanz</tc:token>
      <tc:token ID="w11">haben</tc:token>
      <tc:token ID="w12">die</tc:token>
      <tc:token ID="w13">Modellierung</tc:token>
      <tc:token ID="w14">,</tc:token>
      <tc:token ID="w15">Vernetzung</tc:token>
      <tc:token ID="w16">und</tc:token>
      <tc:token ID="w17">Visualisierung</tc:token>
      <tc:token ID="w18">für</tc:token>
      <tc:token ID="w19">die</tc:token>
      <tc:token ID="w1a">Geistesartefakte</tc:token>
      <tc:token ID="w1b">selbst</tc:token>
      <tc:token ID="w1c">und</tc:token>
      <tc:token ID="w1d">für</tc:token>
      <tc:token ID="w1e">den</tc:token>
      <tc:token ID="w1f">Gewinn</tc:token>
      <tc:token ID="w20">reproduzierbarer</tc:token>
      <tc:token ID="w21">wissenschaftlicher</tc:token>
      <tc:token ID="w22">Erkenntnisse</tc:token>
      <tc:token ID="w23">über</tc:token>
      <tc:token ID="w24">sie</tc:token>
      <tc:token ID="w25">?</tc:token>
      <tc:token ID="w26">Im</tc:token>
      <tc:token ID="w27">Projekt</tc:token>
      <tc:token ID="w28">„</tc:token>
      <tc:token ID="w29">Welt</tc:token>
      <tc:token ID="w2a">der</tc:token>
      <tc:token ID="w2b">Kinder</tc:token>
      <tc:token ID="w2c">“</tc:token>
      <tc:token ID="w2d">(</tc:token>
      <tc:token ID="w2e">WdK</tc:token>
      <tc:token ID="w2f">)</tc:token>
      <tc:token ID="w30">wurden</tc:token>
      <tc:token ID="w31">diese</tc:token>
      <tc:token ID="w32">Punkte</tc:token>
      <tc:token ID="w33">mit</tc:token>
      <tc:token ID="w34">Hilfe</tc:token>
      <tc:token ID="w35">von</tc:token>
      <tc:token ID="w36">Topic</tc:token>
      <tc:token ID="w37">Modeling</tc:token>
      <tc:token ID="w38">und</tc:token>
      <tc:token ID="w39">Text-Mining-Werkzeugen</tc:token>
      <tc:token ID="w3a">mit</tc:token>
      <tc:token ID="w3b">in</tc:token>
      <tc:token ID="w3c">der</tc:token>
      <tc:token ID="w3d">Geschichtswissenschaft</tc:token>
      <tc:token ID="w3e">anerkannten</tc:token>
      <tc:token ID="w3f">Thesen</tc:token>
      <tc:token ID="w40">in</tc:token>
      <tc:token ID="w41">einem</tc:token>
      <tc:token ID="w42">kontrollierten</tc:token>
      <tc:token ID="w43">Verfahren</tc:token>
      <tc:token ID="w44">überprüft</tc:token>
      <tc:token ID="w45">.</tc:token>
      <tc:token ID="w46">Es</tc:token>
      <tc:token ID="w47">handelt</tc:token>
      <tc:token ID="w48">sich</tc:token>
      <tc:token ID="w49">bei</tc:token>
      <tc:token ID="w4a">WdK</tc:token>
      <tc:token ID="w4b">mit</tc:token>
      <tc:token ID="w4c">seinem</tc:token>
      <tc:token ID="w4d">repräsentativen</tc:token>
      <tc:token ID="w4e">Textkorpus</tc:token>
      <tc:token ID="w4f">von</tc:token>
      <tc:token ID="w50">über</tc:token>
      <tc:token ID="w51">3000</tc:token>
      <tc:token ID="w52">historischen</tc:token>
      <tc:token ID="w53">Schulbüchern</tc:token>
      <tc:token ID="w54">um</tc:token>
      <tc:token ID="w55">ein</tc:token>
      <tc:token ID="w56">bisher</tc:token>
      <tc:token ID="w57">weltweit</tc:token>
      <tc:token ID="w58">einzigartiges</tc:token>
      <tc:token ID="w59">Projekt</tc:token>
      <tc:token ID="w5a">,</tc:token>
      <tc:token ID="w5b">das</tc:token>
      <tc:token ID="w5c">für</tc:token>
      <tc:token ID="w5d">künftige</tc:token>
      <tc:token ID="w5e">ähnliche</tc:token>
      <tc:token ID="w5f">Vorhaben</tc:token>
      <tc:token ID="w60">vorbildhaft</tc:token>
      <tc:token ID="w61">sein</tc:token>
      <tc:token ID="w62">will</tc:token>
      <tc:token ID="w63">.</tc:token>
      <tc:token ID="w64">Aus</tc:token>
      <tc:token ID="w65">Sicht</tc:token>
      <tc:token ID="w66">der</tc:token>
      <tc:token ID="w67">klassischen</tc:token>
      <tc:token ID="w68">Geschichtswissenschaften</tc:token>
      <tc:token ID="w69">gibt</tc:token>
      <tc:token ID="w6a">es</tc:token>
      <tc:token ID="w6b">bei</tc:token>
      <tc:token ID="w6c">der</tc:token>
      <tc:token ID="w6d">Bearbeitung</tc:token>
      <tc:token ID="w6e">großer</tc:token>
      <tc:token ID="w6f">Datenmengen</tc:token>
      <tc:token ID="w70">häufig</tc:token>
      <tc:token ID="w71">Argwohn</tc:token>
      <tc:token ID="w72">gegenüber</tc:token>
      <tc:token ID="w73">der</tc:token>
      <tc:token ID="w74">Sekundäranalyse</tc:token>
      <tc:token ID="w75">maschinell</tc:token>
      <tc:token ID="w76">generierter</tc:token>
      <tc:token ID="w77">Ergebnisse</tc:token>
      <tc:token ID="w78">,</tc:token>
      <tc:token ID="w79">verstärkt</tc:token>
      <tc:token ID="w7a">durch</tc:token>
      <tc:token ID="w7b">mangelndes</tc:token>
      <tc:token ID="w7c">Wissen</tc:token>
      <tc:token ID="w7d">über</tc:token>
      <tc:token ID="w7e">fachfremde</tc:token>
      <tc:token ID="w7f">Methodik</tc:token>
      <tc:token ID="w80">.</tc:token>
      <tc:token ID="w81">Dies</tc:token>
      <tc:token ID="w82">lässt</tc:token>
      <tc:token ID="w83">die</tc:token>
      <tc:token ID="w84">Ergebnisse</tc:token>
      <tc:token ID="w85">der</tc:token>
      <tc:token ID="w86">DH</tc:token>
      <tc:token ID="w87">oft</tc:token>
      <tc:token ID="w88">als</tc:token>
      <tc:token ID="w89">zweifelhaft</tc:token>
      <tc:token ID="w8a">oder</tc:token>
      <tc:token ID="w8b">nicht</tc:token>
      <tc:token ID="w8c">neuwertig</tc:token>
      <tc:token ID="w8d">erscheinen</tc:token>
      <tc:token ID="w8e">.</tc:token>
      <tc:token ID="w8f">Zusätzlich</tc:token>
      <tc:token ID="w90">können</tc:token>
      <tc:token ID="w91">Verzerrungen</tc:token>
      <tc:token ID="w92">durch</tc:token>
      <tc:token ID="w93">die</tc:token>
      <tc:token ID="w94">Zusammensetzung</tc:token>
      <tc:token ID="w95">einer</tc:token>
      <tc:token ID="w96">Textsammlung</tc:token>
      <tc:token ID="w97">entstehen</tc:token>
      <tc:token ID="w98">,</tc:token>
      <tc:token ID="w99">durch</tc:token>
      <tc:token ID="w9a">die</tc:token>
      <tc:token ID="w9b">Dokumentenauswahl</tc:token>
      <tc:token ID="w9c">und</tc:token>
      <tc:token ID="w9d">des</tc:token>
      <tc:token ID="w9e">zu</tc:token>
      <tc:token ID="w9f">analysierenden</tc:token>
      <tc:token ID="wa0">Vokabulars</tc:token>
      <tc:token ID="wa1">sowie</tc:token>
      <tc:token ID="wa2">aus</tc:token>
      <tc:token ID="wa3">den</tc:token>
      <tc:token ID="wa4">darauf</tc:token>
      <tc:token ID="wa5">aufbauenden</tc:token>
      <tc:token ID="wa6">Aggregierungen</tc:token>
      <tc:token ID="wa7">und</tc:token>
      <tc:token ID="wa8">Visualisierungen</tc:token>
      <tc:token ID="wa9">(</tc:token>
      <tc:token ID="waa">Chuang</tc:token>
      <tc:token ID="wab">et</tc:token>
      <tc:token ID="wac">al.</tc:token>
      <tc:token ID="wad">2012</tc:token>
      <tc:token ID="wae">)</tc:token>
      <tc:token ID="waf">.</tc:token>
      <tc:token ID="wb0">Große</tc:token>
      <tc:token ID="wb1">Datenmengen</tc:token>
      <tc:token ID="wb2">erfordern</tc:token>
      <tc:token ID="wb3">ein</tc:token>
      <tc:token ID="wb4">anderes</tc:token>
      <tc:token ID="wb5">Vorgehen</tc:token>
      <tc:token ID="wb6">bei</tc:token>
      <tc:token ID="wb7">der</tc:token>
      <tc:token ID="wb8">Auswertung</tc:token>
      <tc:token ID="wb9">als</tc:token>
      <tc:token ID="wba">die</tc:token>
      <tc:token ID="wbb">traditionell</tc:token>
      <tc:token ID="wbc">in</tc:token>
      <tc:token ID="wbd">den</tc:token>
      <tc:token ID="wbe">Geschichtswissenschaften</tc:token>
      <tc:token ID="wbf">üblichen</tc:token>
      <tc:token ID="wc0">Verfahren</tc:token>
      <tc:token ID="wc1">.</tc:token>
      <tc:token ID="wc2">Die</tc:token>
      <tc:token ID="wc3">Methode</tc:token>
      <tc:token ID="wc4">der</tc:token>
      <tc:token ID="wc5">automatischen</tc:token>
      <tc:token ID="wc6">Textanalyse</tc:token>
      <tc:token ID="wc7">stellen</tc:token>
      <tc:token ID="wc8">trotzdem</tc:token>
      <tc:token ID="wc9">eine</tc:token>
      <tc:token ID="wca">durch</tc:token>
      <tc:token ID="wcb">die</tc:token>
      <tc:token ID="wcc">Forschungsziele</tc:token>
      <tc:token ID="wcd">beeinflusste</tc:token>
      <tc:token ID="wce">subjektive</tc:token>
      <tc:token ID="wcf">Sichtweise</tc:token>
      <tc:token ID="wd0">auf</tc:token>
      <tc:token ID="wd1">die</tc:token>
      <tc:token ID="wd2">vorhandenen</tc:token>
      <tc:token ID="wd3">Daten</tc:token>
      <tc:token ID="wd4">dar</tc:token>
      <tc:token ID="wd5">(</tc:token>
      <tc:token ID="wd6">DiMaggio</tc:token>
      <tc:token ID="wd7">et</tc:token>
      <tc:token ID="wd8">al.</tc:token>
      <tc:token ID="wd9">2013</tc:token>
      <tc:token ID="wda">)</tc:token>
      <tc:token ID="wdb">.</tc:token>
      <tc:token ID="wdc">Wir</tc:token>
      <tc:token ID="wdd">zeigen</tc:token>
      <tc:token ID="wde">an</tc:token>
      <tc:token ID="wdf">Hand</tc:token>
      <tc:token ID="we0">eines</tc:token>
      <tc:token ID="we1">in</tc:token>
      <tc:token ID="we2">WdK</tc:token>
      <tc:token ID="we3">vorgenommen</tc:token>
      <tc:token ID="we4">Validierungsexperiments</tc:token>
      <tc:token ID="we5">,</tc:token>
      <tc:token ID="we6">welche</tc:token>
      <tc:token ID="we7">Aushandlungsprozesse</tc:token>
      <tc:token ID="we8">notwendig</tc:token>
      <tc:token ID="we9">waren</tc:token>
      <tc:token ID="wea">,</tc:token>
      <tc:token ID="web">um</tc:token>
      <tc:token ID="wec">nachnutzbare</tc:token>
      <tc:token ID="wed">und</tc:token>
      <tc:token ID="wee">nachvollziehbare</tc:token>
      <tc:token ID="wef">Ergebnisse</tc:token>
      <tc:token ID="wf0">zu</tc:token>
      <tc:token ID="wf1">erhalten</tc:token>
      <tc:token ID="wf2">.</tc:token>
      <tc:token ID="wf3">Für</tc:token>
      <tc:token ID="wf4">die</tc:token>
      <tc:token ID="wf5">Meta-Analyse</tc:token>
      <tc:token ID="wf6">von</tc:token>
      <tc:token ID="wf7">klassischen</tc:token>
      <tc:token ID="wf8">und</tc:token>
      <tc:token ID="wf9">digitalen</tc:token>
      <tc:token ID="wfa">geschichtswissenschaftlichen</tc:token>
      <tc:token ID="wfb">Herangehensweisen</tc:token>
      <tc:token ID="wfc">ist</tc:token>
      <tc:token ID="wfd">die</tc:token>
      <tc:token ID="wfe">Beantwortung</tc:token>
      <tc:token ID="wff">folgender</tc:token>
      <tc:token ID="w100">Fragen</tc:token>
      <tc:token ID="w101">prioritär</tc:token>
      <tc:token ID="w102">:</tc:token>
      <tc:token ID="w103">Erstens</tc:token>
      <tc:token ID="w104">)</tc:token>
      <tc:token ID="w105">Wie</tc:token>
      <tc:token ID="w106">können</tc:token>
      <tc:token ID="w107">auf</tc:token>
      <tc:token ID="w108">klassischem</tc:token>
      <tc:token ID="w109">Weg</tc:token>
      <tc:token ID="w10a">erbrachte</tc:token>
      <tc:token ID="w10b">Ergebnisse</tc:token>
      <tc:token ID="w10c">für</tc:token>
      <tc:token ID="w10d">die</tc:token>
      <tc:token ID="w10e">DH</tc:token>
      <tc:token ID="w10f">so</tc:token>
      <tc:token ID="w110">codifiziert</tc:token>
      <tc:token ID="w111">werden</tc:token>
      <tc:token ID="w112">,</tc:token>
      <tc:token ID="w113">dass</tc:token>
      <tc:token ID="w114">sie</tc:token>
      <tc:token ID="w115">nicht</tc:token>
      <tc:token ID="w116">nur</tc:token>
      <tc:token ID="w117">für</tc:token>
      <tc:token ID="w118">Menschen</tc:token>
      <tc:token ID="w119">interpretierbar</tc:token>
      <tc:token ID="w11a">,</tc:token>
      <tc:token ID="w11b">sondern</tc:token>
      <tc:token ID="w11c">auch</tc:token>
      <tc:token ID="w11d">durch</tc:token>
      <tc:token ID="w11e">die</tc:token>
      <tc:token ID="w11f">digitalen</tc:token>
      <tc:token ID="w120">Werkzeuge</tc:token>
      <tc:token ID="w121">reproduzierbar</tc:token>
      <tc:token ID="w122">sind</tc:token>
      <tc:token ID="w123">?</tc:token>
      <tc:token ID="w124">Sinn</tc:token>
      <tc:token ID="w125">dieses</tc:token>
      <tc:token ID="w126">Verfahrens</tc:token>
      <tc:token ID="w127">ist</tc:token>
      <tc:token ID="w128">es</tc:token>
      <tc:token ID="w129">,</tc:token>
      <tc:token ID="w12a">Versuchsanordnungen</tc:token>
      <tc:token ID="w12b">und</tc:token>
      <tc:token ID="w12c">Analysen</tc:token>
      <tc:token ID="w12d">so</tc:token>
      <tc:token ID="w12e">aufzubauen</tc:token>
      <tc:token ID="w12f">,</tc:token>
      <tc:token ID="w130">dass</tc:token>
      <tc:token ID="w131">diese</tc:token>
      <tc:token ID="w132">nicht</tc:token>
      <tc:token ID="w133">immer</tc:token>
      <tc:token ID="w134">„</tc:token>
      <tc:token ID="w135">bei</tc:token>
      <tc:token ID="w136">Null</tc:token>
      <tc:token ID="w137">“</tc:token>
      <tc:token ID="w138">beginnen</tc:token>
      <tc:token ID="w139">müssen</tc:token>
      <tc:token ID="w13a">,</tc:token>
      <tc:token ID="w13b">sondern</tc:token>
      <tc:token ID="w13c">,</tc:token>
      <tc:token ID="w13d">wie</tc:token>
      <tc:token ID="w13e">ein</tc:token>
      <tc:token ID="w13f">klassischer</tc:token>
      <tc:token ID="w140">Fachtext</tc:token>
      <tc:token ID="w141">,</tc:token>
      <tc:token ID="w142">anerkannte</tc:token>
      <tc:token ID="w143">Annahmen</tc:token>
      <tc:token ID="w144">und</tc:token>
      <tc:token ID="w145">Erkenntnisse</tc:token>
      <tc:token ID="w146">implizit</tc:token>
      <tc:token ID="w147">transportieren</tc:token>
      <tc:token ID="w148">und</tc:token>
      <tc:token ID="w149">wiederholen</tc:token>
      <tc:token ID="w14a">.</tc:token>
      <tc:token ID="w14b">Zweitens</tc:token>
      <tc:token ID="w14c">)</tc:token>
      <tc:token ID="w14d">Wie</tc:token>
      <tc:token ID="w14e">kann</tc:token>
      <tc:token ID="w14f">die</tc:token>
      <tc:token ID="w150">Belastbarkeit</tc:token>
      <tc:token ID="w151">von</tc:token>
      <tc:token ID="w152">Ergebnissen</tc:token>
      <tc:token ID="w153">,</tc:token>
      <tc:token ID="w154">die</tc:token>
      <tc:token ID="w155">mit</tc:token>
      <tc:token ID="w156">Hilfe</tc:token>
      <tc:token ID="w157">von</tc:token>
      <tc:token ID="w158">Methoden</tc:token>
      <tc:token ID="w159">der</tc:token>
      <tc:token ID="w15a">automatischen</tc:token>
      <tc:token ID="w15b">Textmodellierung</tc:token>
      <tc:token ID="w15c">auf</tc:token>
      <tc:token ID="w15d">einem</tc:token>
      <tc:token ID="w15e">umfangreichen</tc:token>
      <tc:token ID="w15f">Korpus</tc:token>
      <tc:token ID="w160">erbracht</tc:token>
      <tc:token ID="w161">worden</tc:token>
      <tc:token ID="w162">sind</tc:token>
      <tc:token ID="w163">,</tc:token>
      <tc:token ID="w164">validiert</tc:token>
      <tc:token ID="w165">werden</tc:token>
      <tc:token ID="w166">?</tc:token>
      <tc:token ID="w167">Drittens</tc:token>
      <tc:token ID="w168">)</tc:token>
      <tc:token ID="w169">Wie</tc:token>
      <tc:token ID="w16a">kann</tc:token>
      <tc:token ID="w16b">man</tc:token>
      <tc:token ID="w16c">die</tc:token>
      <tc:token ID="w16d">Leistung</tc:token>
      <tc:token ID="w16e">digitaler</tc:token>
      <tc:token ID="w16f">Methoden</tc:token>
      <tc:token ID="w170">für</tc:token>
      <tc:token ID="w171">explorative</tc:token>
      <tc:token ID="w172">Analysen</tc:token>
      <tc:token ID="w173">anwenden</tc:token>
      <tc:token ID="w174">,</tc:token>
      <tc:token ID="w175">ohne</tc:token>
      <tc:token ID="w176">auf</tc:token>
      <tc:token ID="w177">ein</tc:token>
      <tc:token ID="w178">bereits</tc:token>
      <tc:token ID="w179">feststehendes</tc:token>
      <tc:token ID="w17a">Ziel</tc:token>
      <tc:token ID="w17b">hinzuarbeiten</tc:token>
      <tc:token ID="w17c">?</tc:token>
      <tc:token ID="w17d">Viertens</tc:token>
      <tc:token ID="w17e">)</tc:token>
      <tc:token ID="w17f">Wie</tc:token>
      <tc:token ID="w180">müssen</tc:token>
      <tc:token ID="w181">die</tc:token>
      <tc:token ID="w182">Versuchsanordnung</tc:token>
      <tc:token ID="w183">und</tc:token>
      <tc:token ID="w184">das</tc:token>
      <tc:token ID="w185">Projekt</tc:token>
      <tc:token ID="w186">aufgebaut</tc:token>
      <tc:token ID="w187">werden</tc:token>
      <tc:token ID="w188">,</tc:token>
      <tc:token ID="w189">um</tc:token>
      <tc:token ID="w18a">den</tc:token>
      <tc:token ID="w18b">Daten</tc:token>
      <tc:token ID="w18c">zu</tc:token>
      <tc:token ID="w18d">vertrauen</tc:token>
      <tc:token ID="w18e">und</tc:token>
      <tc:token ID="w18f">sie</tc:token>
      <tc:token ID="w190">interpretieren</tc:token>
      <tc:token ID="w191">sowie</tc:token>
      <tc:token ID="w192">kontextualisieren</tc:token>
      <tc:token ID="w193">zu</tc:token>
      <tc:token ID="w194">können</tc:token>
      <tc:token ID="w195">?</tc:token>
      <tc:token ID="w196">Der</tc:token>
      <tc:token ID="w197">Vortrag</tc:token>
      <tc:token ID="w198">wird</tc:token>
      <tc:token ID="w199">den</tc:token>
      <tc:token ID="w19a">Arbeitsprozess</tc:token>
      <tc:token ID="w19b">(</tc:token>
      <tc:token ID="w19c">interdisziplinäre</tc:token>
      <tc:token ID="w19d">Arbeit</tc:token>
      <tc:token ID="w19e">an</tc:token>
      <tc:token ID="w19f">historischen</tc:token>
      <tc:token ID="w1a0">Thesen</tc:token>
      <tc:token ID="w1a1">mit</tc:token>
      <tc:token ID="w1a2">Hilfe</tc:token>
      <tc:token ID="w1a3">digitaler</tc:token>
      <tc:token ID="w1a4">Tools</tc:token>
      <tc:token ID="w1a5">)</tc:token>
      <tc:token ID="w1a6">analysieren</tc:token>
      <tc:token ID="w1a7">,</tc:token>
      <tc:token ID="w1a8">die</tc:token>
      <tc:token ID="w1a9">verschiedenen</tc:token>
      <tc:token ID="w1aa">fachspezifischen</tc:token>
      <tc:token ID="w1ab">Methoden</tc:token>
      <tc:token ID="w1ac">problematisieren</tc:token>
      <tc:token ID="w1ad">sowie</tc:token>
      <tc:token ID="w1ae">schlaglichtartig</tc:token>
      <tc:token ID="w1af">Wege</tc:token>
      <tc:token ID="w1b0">beleuchten</tc:token>
      <tc:token ID="w1b1">,</tc:token>
      <tc:token ID="w1b2">die</tc:token>
      <tc:token ID="w1b3">zu</tc:token>
      <tc:token ID="w1b4">möglichen</tc:token>
      <tc:token ID="w1b5">Antworten</tc:token>
      <tc:token ID="w1b6">auf</tc:token>
      <tc:token ID="w1b7">die</tc:token>
      <tc:token ID="w1b8">gestellten</tc:token>
      <tc:token ID="w1b9">Fragen</tc:token>
      <tc:token ID="w1ba">führen</tc:token>
      <tc:token ID="w1bb">können</tc:token>
      <tc:token ID="w1bc">.</tc:token>
      <tc:token ID="w1bd">Die</tc:token>
      <tc:token ID="w1be">Grundlage</tc:token>
      <tc:token ID="w1bf">der</tc:token>
      <tc:token ID="w1c0">Topic-Modelling-basierten</tc:token>
      <tc:token ID="w1c1">Analyse</tc:token>
      <tc:token ID="w1c2">besteht</tc:token>
      <tc:token ID="w1c3">auf</tc:token>
      <tc:token ID="w1c4">im</tc:token>
      <tc:token ID="w1c5">Bereich</tc:token>
      <tc:token ID="w1c6">DH</tc:token>
      <tc:token ID="w1c7">etablierter</tc:token>
      <tc:token ID="w1c8">Methoden</tc:token>
      <tc:token ID="w1c9">wie</tc:token>
      <tc:token ID="w1ca">LDA</tc:token>
      <tc:token ID="w1cb">(</tc:token>
      <tc:token ID="w1cc">Latent</tc:token>
      <tc:token ID="w1cd">Dirichlet</tc:token>
      <tc:token ID="w1ce">Allocation</tc:token>
      <tc:token ID="w1cf">;</tc:token>
      <tc:token ID="w1d0">Blei</tc:token>
      <tc:token ID="w1d1">et</tc:token>
      <tc:token ID="w1d2">al.</tc:token>
      <tc:token ID="w1d3">2003</tc:token>
      <tc:token ID="w1d4">)</tc:token>
      <tc:token ID="w1d5">.</tc:token>
      <tc:token ID="w1d6">Dieses</tc:token>
      <tc:token ID="w1d7">Verfahren</tc:token>
      <tc:token ID="w1d8">ordnet</tc:token>
      <tc:token ID="w1d9">Begriffe</tc:token>
      <tc:token ID="w1da">auf</tc:token>
      <tc:token ID="w1db">Basis</tc:token>
      <tc:token ID="w1dc">von</tc:token>
      <tc:token ID="w1dd">Kookkurrenz</tc:token>
      <tc:token ID="w1de">und</tc:token>
      <tc:token ID="w1df">statistischen</tc:token>
      <tc:token ID="w1e0">Analysen</tc:token>
      <tc:token ID="w1e1">einander</tc:token>
      <tc:token ID="w1e2">zu</tc:token>
      <tc:token ID="w1e3">und</tc:token>
      <tc:token ID="w1e4">extrahiert</tc:token>
      <tc:token ID="w1e5">Topics</tc:token>
      <tc:token ID="w1e6">in</tc:token>
      <tc:token ID="w1e7">Form</tc:token>
      <tc:token ID="w1e8">gewichteter</tc:token>
      <tc:token ID="w1e9">Wortlisten</tc:token>
      <tc:token ID="w1ea">.</tc:token>
      <tc:token ID="w1eb">Diese</tc:token>
      <tc:token ID="w1ec">ergeben</tc:token>
      <tc:token ID="w1ed">für</tc:token>
      <tc:token ID="w1ee">menschliche</tc:token>
      <tc:token ID="w1ef">Benutzer</tc:token>
      <tc:token ID="w1f0">interpretierbare</tc:token>
      <tc:token ID="w1f1">Listen</tc:token>
      <tc:token ID="w1f2">,</tc:token>
      <tc:token ID="w1f3">und</tc:token>
      <tc:token ID="w1f4">erlauben</tc:token>
      <tc:token ID="w1f5">eine</tc:token>
      <tc:token ID="w1f6">automatische</tc:token>
      <tc:token ID="w1f7">Inferenz</tc:token>
      <tc:token ID="w1f8">von</tc:token>
      <tc:token ID="w1f9">Topic-Verteilungen</tc:token>
      <tc:token ID="w1fa">innerhalb</tc:token>
      <tc:token ID="w1fb">eines</tc:token>
      <tc:token ID="w1fc">Dokuments</tc:token>
      <tc:token ID="w1fd">.</tc:token>
      <tc:token ID="w1fe">Die</tc:token>
      <tc:token ID="w1ff">Validierungsstudie</tc:token>
      <tc:token ID="w200">wurde</tc:token>
      <tc:token ID="w201">mit</tc:token>
      <tc:token ID="w202">einem</tc:token>
      <tc:token ID="w203">interaktiven</tc:token>
      <tc:token ID="w204">Prototyp</tc:token>
      <tc:token ID="w205">durchgeführt</tc:token>
      <tc:token ID="w206">,</tc:token>
      <tc:token ID="w207">der</tc:token>
      <tc:token ID="w208">die</tc:token>
      <tc:token ID="w209">Texte</tc:token>
      <tc:token ID="w20a">im</tc:token>
      <tc:token ID="w20b">Korpus</tc:token>
      <tc:token ID="w20c">und</tc:token>
      <tc:token ID="w20d">Statistiken</tc:token>
      <tc:token ID="w20e">über</tc:token>
      <tc:token ID="w20f">die</tc:token>
      <tc:token ID="w210">Ergebnismengen</tc:token>
      <tc:token ID="w211">zugänglich</tc:token>
      <tc:token ID="w212">macht</tc:token>
      <tc:token ID="w213">.</tc:token>
      <tc:token ID="w214">Suchanfragen</tc:token>
      <tc:token ID="w215">können</tc:token>
      <tc:token ID="w216">sich</tc:token>
      <tc:token ID="w217">auf</tc:token>
      <tc:token ID="w218">Metadaten</tc:token>
      <tc:token ID="w219">–</tc:token>
      <tc:token ID="w21a">beispielsweise</tc:token>
      <tc:token ID="w21b">Jahr</tc:token>
      <tc:token ID="w21c">und</tc:token>
      <tc:token ID="w21d">Ort</tc:token>
      <tc:token ID="w21e">der</tc:token>
      <tc:token ID="w21f">Veröffentlichung</tc:token>
      <tc:token ID="w220">oder</tc:token>
      <tc:token ID="w221">Schultyp</tc:token>
      <tc:token ID="w222">–</tc:token>
      <tc:token ID="w223">Termanfragen</tc:token>
      <tc:token ID="w224">und</tc:token>
      <tc:token ID="w225">Topic-Verteilungen</tc:token>
      <tc:token ID="w226">beziehen</tc:token>
      <tc:token ID="w227">.</tc:token>
      <tc:token ID="w228">Ergebnisse</tc:token>
      <tc:token ID="w229">werden</tc:token>
      <tc:token ID="w22a">mit</tc:token>
      <tc:token ID="w22b">Statistiken</tc:token>
      <tc:token ID="w22c">zur</tc:token>
      <tc:token ID="w22d">Topic-Intensität</tc:token>
      <tc:token ID="w22e">und</tc:token>
      <tc:token ID="w22f">relativen</tc:token>
      <tc:token ID="w230">Dokumentenhäufigkeit</tc:token>
      <tc:token ID="w231">im</tc:token>
      <tc:token ID="w232">Zeitverlauf</tc:token>
      <tc:token ID="w233">ausgegeben</tc:token>
      <tc:token ID="w234">.</tc:token>
      <tc:token ID="w235">Belastbarkeitsüberprüfungen</tc:token>
      <tc:token ID="w236">bauen</tc:token>
      <tc:token ID="w237">Vertrauen</tc:token>
      <tc:token ID="w238">in</tc:token>
      <tc:token ID="w239">datenbasierte</tc:token>
      <tc:token ID="w23a">,</tc:token>
      <tc:token ID="w23b">historische</tc:token>
      <tc:token ID="w23c">Schlussfolgerungen</tc:token>
      <tc:token ID="w23d">und</tc:token>
      <tc:token ID="w23e">Annahmen</tc:token>
      <tc:token ID="w23f">auf</tc:token>
      <tc:token ID="w240">.</tc:token>
      <tc:token ID="w241">So</tc:token>
      <tc:token ID="w242">wird</tc:token>
      <tc:token ID="w243">überprüft</tc:token>
      <tc:token ID="w244">,</tc:token>
      <tc:token ID="w245">ob</tc:token>
      <tc:token ID="w246">die</tc:token>
      <tc:token ID="w247">statistischen</tc:token>
      <tc:token ID="w248">Modelle</tc:token>
      <tc:token ID="w249">existierende</tc:token>
      <tc:token ID="w24a">Erkenntnisse</tc:token>
      <tc:token ID="w24b">mehrheitlich</tc:token>
      <tc:token ID="w24c">bestätigen</tc:token>
      <tc:token ID="w24d">,</tc:token>
      <tc:token ID="w24e">und</tc:token>
      <tc:token ID="w24f">als</tc:token>
      <tc:token ID="w250">wie</tc:token>
      <tc:token ID="w251">zuverlässig</tc:token>
      <tc:token ID="w252">bestätigende</tc:token>
      <tc:token ID="w253">oder</tc:token>
      <tc:token ID="w254">widerlegende</tc:token>
      <tc:token ID="w255">Ergebnisse</tc:token>
      <tc:token ID="w256">eingeschätzt</tc:token>
      <tc:token ID="w257">werden</tc:token>
      <tc:token ID="w258">(</tc:token>
      <tc:token ID="w259">DiMaggio</tc:token>
      <tc:token ID="w25a">et</tc:token>
      <tc:token ID="w25b">al.</tc:token>
      <tc:token ID="w25c">2013</tc:token>
      <tc:token ID="w25d">;</tc:token>
      <tc:token ID="w25e">Evans</tc:token>
      <tc:token ID="w25f">2014</tc:token>
      <tc:token ID="w260">)</tc:token>
      <tc:token ID="w261">.</tc:token>
      <tc:token ID="w262">Die</tc:token>
      <tc:token ID="w263">im</tc:token>
      <tc:token ID="w264">Experiment</tc:token>
      <tc:token ID="w265">bearbeiteten</tc:token>
      <tc:token ID="w266">historischen</tc:token>
      <tc:token ID="w267">Thesen</tc:token>
      <tc:token ID="w268">stellten</tc:token>
      <tc:token ID="w269">Sachverhalte</tc:token>
      <tc:token ID="w26a">dar</tc:token>
      <tc:token ID="w26b">,</tc:token>
      <tc:token ID="w26c">die</tc:token>
      <tc:token ID="w26d">sich</tc:token>
      <tc:token ID="w26e">quantitativ</tc:token>
      <tc:token ID="w26f">überprüfen</tc:token>
      <tc:token ID="w270">lassen</tc:token>
      <tc:token ID="w271">,</tc:token>
      <tc:token ID="w272">etwa</tc:token>
      <tc:token ID="w273">durch</tc:token>
      <tc:token ID="w274">den</tc:token>
      <tc:token ID="w275">Vergleich</tc:token>
      <tc:token ID="w276">von</tc:token>
      <tc:token ID="w277">Topic-Verteilungen</tc:token>
      <tc:token ID="w278">(</tc:token>
      <tc:token ID="w279">Newman</tc:token>
      <tc:token ID="w27a">/</tc:token>
      <tc:token ID="w27b">Block</tc:token>
      <tc:token ID="w27c">2006</tc:token>
      <tc:token ID="w27d">;</tc:token>
      <tc:token ID="w27e">Yang</tc:token>
      <tc:token ID="w27f">et</tc:token>
      <tc:token ID="w280">al.</tc:token>
      <tc:token ID="w281">2011</tc:token>
      <tc:token ID="w282">)</tc:token>
      <tc:token ID="w283">,</tc:token>
      <tc:token ID="w284">und</tc:token>
      <tc:token ID="w285">im</tc:token>
      <tc:token ID="w286">Nachhinein</tc:token>
      <tc:token ID="w287">von</tc:token>
      <tc:token ID="w288">Experten</tc:token>
      <tc:token ID="w289">für</tc:token>
      <tc:token ID="w28a">das</tc:token>
      <tc:token ID="w28b">jeweilige</tc:token>
      <tc:token ID="w28c">Fachgebiet</tc:token>
      <tc:token ID="w28d">in</tc:token>
      <tc:token ID="w28e">Hinblick</tc:token>
      <tc:token ID="w28f">auf</tc:token>
      <tc:token ID="w290">ihre</tc:token>
      <tc:token ID="w291">Plausibilität</tc:token>
      <tc:token ID="w292">überprüft</tc:token>
      <tc:token ID="w293">werden</tc:token>
      <tc:token ID="w294">.</tc:token>
      <tc:token ID="w295">Für</tc:token>
      <tc:token ID="w296">die</tc:token>
      <tc:token ID="w297">Validierungsstudie</tc:token>
      <tc:token ID="w298">wurden</tc:token>
      <tc:token ID="w299">zu</tc:token>
      <tc:token ID="w29a">überprüfende</tc:token>
      <tc:token ID="w29b">Thesen</tc:token>
      <tc:token ID="w29c">vorab</tc:token>
      <tc:token ID="w29d">definiert</tc:token>
      <tc:token ID="w29e">,</tc:token>
      <tc:token ID="w29f">um</tc:token>
      <tc:token ID="w2a0">Abweichungen</tc:token>
      <tc:token ID="w2a1">von</tc:token>
      <tc:token ID="w2a2">der</tc:token>
      <tc:token ID="w2a3">ursprünglichen</tc:token>
      <tc:token ID="w2a4">Fragestellung</tc:token>
      <tc:token ID="w2a5">zu</tc:token>
      <tc:token ID="w2a6">dokumentieren</tc:token>
      <tc:token ID="w2a7">.</tc:token>
      <tc:token ID="w2a8">Sie</tc:token>
      <tc:token ID="w2a9">sind</tc:token>
      <tc:token ID="w2aa">repräsentativ</tc:token>
      <tc:token ID="w2ab">für</tc:token>
      <tc:token ID="w2ac">reale</tc:token>
      <tc:token ID="w2ad">historische</tc:token>
      <tc:token ID="w2ae">Fragestellungen</tc:token>
      <tc:token ID="w2af">im</tc:token>
      <tc:token ID="w2b0">Rahmen</tc:token>
      <tc:token ID="w2b1">des</tc:token>
      <tc:token ID="w2b2">Projektes</tc:token>
      <tc:token ID="w2b3">(</tc:token>
      <tc:token ID="w2b4">Kolonien</tc:token>
      <tc:token ID="w2b5">und</tc:token>
      <tc:token ID="w2b6">Auswanderung</tc:token>
      <tc:token ID="w2b7">;</tc:token>
      <tc:token ID="w2b8">Französische</tc:token>
      <tc:token ID="w2b9">Revolution</tc:token>
      <tc:token ID="w2ba">und</tc:token>
      <tc:token ID="w2bb">Befreiungskriege</tc:token>
      <tc:token ID="w2bc">;</tc:token>
      <tc:token ID="w2bd">deutsche</tc:token>
      <tc:token ID="w2be">Kriegsflotte</tc:token>
      <tc:token ID="w2bf">)</tc:token>
      <tc:token ID="w2c0">.</tc:token>
      <tc:token ID="w2c1">Dabei</tc:token>
      <tc:token ID="w2c2">wurden</tc:token>
      <tc:token ID="w2c3">in</tc:token>
      <tc:token ID="w2c4">einem</tc:token>
      <tc:token ID="w2c5">ersten</tc:token>
      <tc:token ID="w2c6">Schritt</tc:token>
      <tc:token ID="w2c7">Begrifflichkeiten</tc:token>
      <tc:token ID="w2c8">und</tc:token>
      <tc:token ID="w2c9">Interpretationen</tc:token>
      <tc:token ID="w2ca">der</tc:token>
      <tc:token ID="w2cb">Fragestellungen</tc:token>
      <tc:token ID="w2cc">in</tc:token>
      <tc:token ID="w2cd">interdisziplinären</tc:token>
      <tc:token ID="w2ce">Arbeitsgruppen</tc:token>
      <tc:token ID="w2cf">diskutiert</tc:token>
      <tc:token ID="w2d0">,</tc:token>
      <tc:token ID="w2d1">um</tc:token>
      <tc:token ID="w2d2">fachliche</tc:token>
      <tc:token ID="w2d3">Verständnisschwierigkeiten</tc:token>
      <tc:token ID="w2d4">auszuräumen</tc:token>
      <tc:token ID="w2d5">.</tc:token>
      <tc:token ID="w2d6">Da</tc:token>
      <tc:token ID="w2d7">die</tc:token>
      <tc:token ID="w2d8">Thesen</tc:token>
      <tc:token ID="w2d9">erschöpfend</tc:token>
      <tc:token ID="w2da">und</tc:token>
      <tc:token ID="w2db">präzise</tc:token>
      <tc:token ID="w2dc">mit</tc:token>
      <tc:token ID="w2dd">den</tc:token>
      <tc:token ID="w2de">vorhandenen</tc:token>
      <tc:token ID="w2df">Werkzeugen</tc:token>
      <tc:token ID="w2e0">untersucht</tc:token>
      <tc:token ID="w2e1">wurden</tc:token>
      <tc:token ID="w2e2">,</tc:token>
      <tc:token ID="w2e3">bilden</tc:token>
      <tc:token ID="w2e4">auch</tc:token>
      <tc:token ID="w2e5">die</tc:token>
      <tc:token ID="w2e6">Auswertungsstrategien</tc:token>
      <tc:token ID="w2e7">mögliche</tc:token>
      <tc:token ID="w2e8">Vorgehensweisen</tc:token>
      <tc:token ID="w2e9">für</tc:token>
      <tc:token ID="w2ea">die</tc:token>
      <tc:token ID="w2eb">Überprüfung</tc:token>
      <tc:token ID="w2ec">bereits</tc:token>
      <tc:token ID="w2ed">vorliegender</tc:token>
      <tc:token ID="w2ee">Hypothesen</tc:token>
      <tc:token ID="w2ef">ab</tc:token>
      <tc:token ID="w2f0">.</tc:token>
      <tc:token ID="w2f1">Bei</tc:token>
      <tc:token ID="w2f2">der</tc:token>
      <tc:token ID="w2f3">Analyse</tc:token>
      <tc:token ID="w2f4">der</tc:token>
      <tc:token ID="w2f5">Thesen</tc:token>
      <tc:token ID="w2f6">zeigten</tc:token>
      <tc:token ID="w2f7">sich</tc:token>
      <tc:token ID="w2f8">unterschiedliche</tc:token>
      <tc:token ID="w2f9">Strategien</tc:token>
      <tc:token ID="w2fa">für</tc:token>
      <tc:token ID="w2fb">die</tc:token>
      <tc:token ID="w2fc">einzelnen</tc:token>
      <tc:token ID="w2fd">Schritte</tc:token>
      <tc:token ID="w2fe">der</tc:token>
      <tc:token ID="w2ff">Auswertung</tc:token>
      <tc:token ID="w300">.</tc:token>
      <tc:token ID="w301">Wichtig</tc:token>
      <tc:token ID="w302">hierbei</tc:token>
      <tc:token ID="w303">war</tc:token>
      <tc:token ID="w304">,</tc:token>
      <tc:token ID="w305">ob</tc:token>
      <tc:token ID="w306">unterschiedliche</tc:token>
      <tc:token ID="w307">Herangehensweisen</tc:token>
      <tc:token ID="w308">,</tc:token>
      <tc:token ID="w309">vergleichbare</tc:token>
      <tc:token ID="w30a">Ergebnisse</tc:token>
      <tc:token ID="w30b">reproduzierten</tc:token>
      <tc:token ID="w30c">.</tc:token>
      <tc:token ID="w30d">Die</tc:token>
      <tc:token ID="w30e">Ergebnisse</tc:token>
      <tc:token ID="w30f">der</tc:token>
      <tc:token ID="w310">einzelnen</tc:token>
      <tc:token ID="w311">Arbeitsgruppen</tc:token>
      <tc:token ID="w312">widersprachen</tc:token>
      <tc:token ID="w313">einander</tc:token>
      <tc:token ID="w314">an</tc:token>
      <tc:token ID="w315">wenigen</tc:token>
      <tc:token ID="w316">Stellen</tc:token>
      <tc:token ID="w317">,</tc:token>
      <tc:token ID="w318">und</tc:token>
      <tc:token ID="w319">gegebenenfalls</tc:token>
      <tc:token ID="w31a">primär</tc:token>
      <tc:token ID="w31b">in</tc:token>
      <tc:token ID="w31c">ihrer</tc:token>
      <tc:token ID="w31d">Bewertung</tc:token>
      <tc:token ID="w31e">der</tc:token>
      <tc:token ID="w31f">Verlässlichkeit</tc:token>
      <tc:token ID="w320">der</tc:token>
      <tc:token ID="w321">Ergebnisse</tc:token>
      <tc:token ID="w322">.</tc:token>
      <tc:token ID="w323">Die</tc:token>
      <tc:token ID="w324">vorgegebenen</tc:token>
      <tc:token ID="w325">geschichtswissenschaftlichen</tc:token>
      <tc:token ID="w326">Thesen</tc:token>
      <tc:token ID="w327">wurden</tc:token>
      <tc:token ID="w328">in</tc:token>
      <tc:token ID="w329">den</tc:token>
      <tc:token ID="w32a">Versuchen</tc:token>
      <tc:token ID="w32b">mit</tc:token>
      <tc:token ID="w32c">Topic-Modellen</tc:token>
      <tc:token ID="w32d">größtenteils</tc:token>
      <tc:token ID="w32e">bestätigt</tc:token>
      <tc:token ID="w32f">und</tc:token>
      <tc:token ID="w330">zusätzlich</tc:token>
      <tc:token ID="w331">mittels</tc:token>
      <tc:token ID="w332">Termanfragen</tc:token>
      <tc:token ID="w333">validiert</tc:token>
      <tc:token ID="w334">.</tc:token>
      <tc:token ID="w335">Das</tc:token>
      <tc:token ID="w336">Vorgehen</tc:token>
      <tc:token ID="w337">bei</tc:token>
      <tc:token ID="w338">den</tc:token>
      <tc:token ID="w339">Topic-Modelling-basierten</tc:token>
      <tc:token ID="w33a">Analysen</tc:token>
      <tc:token ID="w33b">beinhaltete</tc:token>
      <tc:token ID="w33c">im</tc:token>
      <tc:token ID="w33d">ersten</tc:token>
      <tc:token ID="w33e">Schritt</tc:token>
      <tc:token ID="w33f">eine</tc:token>
      <tc:token ID="w340">Suche</tc:token>
      <tc:token ID="w341">nach</tc:token>
      <tc:token ID="w342">relevanten</tc:token>
      <tc:token ID="w343">Topics</tc:token>
      <tc:token ID="w344">an</tc:token>
      <tc:token ID="w345">Hand</tc:token>
      <tc:token ID="w346">einzelner</tc:token>
      <tc:token ID="w347">Terme</tc:token>
      <tc:token ID="w348">.</tc:token>
      <tc:token ID="w349">Dabei</tc:token>
      <tc:token ID="w34a">zeigte</tc:token>
      <tc:token ID="w34b">sich</tc:token>
      <tc:token ID="w34c">,</tc:token>
      <tc:token ID="w34d">dass</tc:token>
      <tc:token ID="w34e">die</tc:token>
      <tc:token ID="w34f">Topics</tc:token>
      <tc:token ID="w350">in</tc:token>
      <tc:token ID="w351">Modellen</tc:token>
      <tc:token ID="w352">mit</tc:token>
      <tc:token ID="w353">einer</tc:token>
      <tc:token ID="w354">manuell</tc:token>
      <tc:token ID="w355">überschaubaren</tc:token>
      <tc:token ID="w356">Topic-Anzahl</tc:token>
      <tc:token ID="w357">(</tc:token>
      <tc:token ID="w358">50,</tc:token>
      <tc:token ID="w359">100</tc:token>
      <tc:token ID="w35a">,</tc:token>
      <tc:token ID="w35b">200</tc:token>
      <tc:token ID="w35c">)</tc:token>
      <tc:token ID="w35d">für</tc:token>
      <tc:token ID="w35e">spezielle</tc:token>
      <tc:token ID="w35f">historische</tc:token>
      <tc:token ID="w360">Forschungsfragen</tc:token>
      <tc:token ID="w361">zu</tc:token>
      <tc:token ID="w362">allgemein</tc:token>
      <tc:token ID="w363">oder</tc:token>
      <tc:token ID="w364">auch</tc:token>
      <tc:token ID="w365">zu</tc:token>
      <tc:token ID="w366">spezifisch</tc:token>
      <tc:token ID="w367">ausfielen</tc:token>
      <tc:token ID="w368">.</tc:token>
      <tc:token ID="w369">Teilweise</tc:token>
      <tc:token ID="w36a">wurden</tc:token>
      <tc:token ID="w36b">daraufhin</tc:token>
      <tc:token ID="w36c">die</tc:token>
      <tc:token ID="w36d">Thesen</tc:token>
      <tc:token ID="w36e">stellvertretend</tc:token>
      <tc:token ID="w36f">an</tc:token>
      <tc:token ID="w370">Hand</tc:token>
      <tc:token ID="w371">thematischer</tc:token>
      <tc:token ID="w372">Teilgebiete</tc:token>
      <tc:token ID="w373">oder</tc:token>
      <tc:token ID="w374">übergeordneter</tc:token>
      <tc:token ID="w375">Themen</tc:token>
      <tc:token ID="w376">untersucht</tc:token>
      <tc:token ID="w377">.</tc:token>
      <tc:token ID="w378">Für</tc:token>
      <tc:token ID="w379">eine</tc:token>
      <tc:token ID="w37a">höhere</tc:token>
      <tc:token ID="w37b">Genauigkeit</tc:token>
      <tc:token ID="w37c">wurden</tc:token>
      <tc:token ID="w37d">auch</tc:token>
      <tc:token ID="w37e">Kombinationen</tc:token>
      <tc:token ID="w37f">aus</tc:token>
      <tc:token ID="w380">Termsuche</tc:token>
      <tc:token ID="w381">und</tc:token>
      <tc:token ID="w382">Dokumentenfiltern</tc:token>
      <tc:token ID="w383">auf</tc:token>
      <tc:token ID="w384">Basis</tc:token>
      <tc:token ID="w385">automatisch</tc:token>
      <tc:token ID="w386">generierter</tc:token>
      <tc:token ID="w387">Topics</tc:token>
      <tc:token ID="w388">eingesetzt</tc:token>
      <tc:token ID="w389">.</tc:token>
      <tc:token ID="w38a">Für</tc:token>
      <tc:token ID="w38b">eine</tc:token>
      <tc:token ID="w38c">Bewertung</tc:token>
      <tc:token ID="w38d">der</tc:token>
      <tc:token ID="w38e">Abfragegenauigkeit</tc:token>
      <tc:token ID="w38f">wurden</tc:token>
      <tc:token ID="w390">manuelle</tc:token>
      <tc:token ID="w391">Inspektionen</tc:token>
      <tc:token ID="w392">der</tc:token>
      <tc:token ID="w393">relevantesten</tc:token>
      <tc:token ID="w394">Trefferdokumente</tc:token>
      <tc:token ID="w395">durchgeführt</tc:token>
      <tc:token ID="w396">und</tc:token>
      <tc:token ID="w397">Anfragen</tc:token>
      <tc:token ID="w398">iterativ</tc:token>
      <tc:token ID="w399">neu</tc:token>
      <tc:token ID="w39a">formuliert</tc:token>
      <tc:token ID="w39b">.</tc:token>
      <tc:token ID="w39c">Um</tc:token>
      <tc:token ID="w39d">für</tc:token>
      <tc:token ID="w39e">die</tc:token>
      <tc:token ID="w39f">Validierung</tc:token>
      <tc:token ID="w3a0">eine</tc:token>
      <tc:token ID="w3a1">Vergleichsebene</tc:token>
      <tc:token ID="w3a2">bereitzustellen</tc:token>
      <tc:token ID="w3a3">,</tc:token>
      <tc:token ID="w3a4">wurden</tc:token>
      <tc:token ID="w3a5">zusätzliche</tc:token>
      <tc:token ID="w3a6">Analysen</tc:token>
      <tc:token ID="w3a7">nur</tc:token>
      <tc:token ID="w3a8">auf</tc:token>
      <tc:token ID="w3a9">der</tc:token>
      <tc:token ID="w3aa">Grundlage</tc:token>
      <tc:token ID="w3ab">manuell</tc:token>
      <tc:token ID="w3ac">und</tc:token>
      <tc:token ID="w3ad">mittels</tc:token>
      <tc:token ID="w3ae">historischen</tc:token>
      <tc:token ID="w3af">Vorwissens</tc:token>
      <tc:token ID="w3b0">gewählter</tc:token>
      <tc:token ID="w3b1">Terme</tc:token>
      <tc:token ID="w3b2">durchgeführt</tc:token>
      <tc:token ID="w3b3">.</tc:token>
      <tc:token ID="w3b4">Zusammengefasst</tc:token>
      <tc:token ID="w3b5">kann</tc:token>
      <tc:token ID="w3b6">zwischen</tc:token>
      <tc:token ID="w3b7">zwei</tc:token>
      <tc:token ID="w3b8">grundlegenden</tc:token>
      <tc:token ID="w3b9">Vorgehensweisen</tc:token>
      <tc:token ID="w3ba">unterschieden</tc:token>
      <tc:token ID="w3bb">werden</tc:token>
      <tc:token ID="w3bc">.</tc:token>
      <tc:token ID="w3bd">In</tc:token>
      <tc:token ID="w3be">der</tc:token>
      <tc:token ID="w3bf">ersten</tc:token>
      <tc:token ID="w3c0">Variante</tc:token>
      <tc:token ID="w3c1">werden</tc:token>
      <tc:token ID="w3c2">die</tc:token>
      <tc:token ID="w3c3">aufgestellten</tc:token>
      <tc:token ID="w3c4">Thesen</tc:token>
      <tc:token ID="w3c5">konfirmatorisch</tc:token>
      <tc:token ID="w3c6">überprüft</tc:token>
      <tc:token ID="w3c7">.</tc:token>
      <tc:token ID="w3c8">Diese</tc:token>
      <tc:token ID="w3c9">werden</tc:token>
      <tc:token ID="w3ca">dafür</tc:token>
      <tc:token ID="w3cb">formalisiert</tc:token>
      <tc:token ID="w3cc">und</tc:token>
      <tc:token ID="w3cd">in</tc:token>
      <tc:token ID="w3ce">Form</tc:token>
      <tc:token ID="w3cf">von</tc:token>
      <tc:token ID="w3d0">Suchanfragen</tc:token>
      <tc:token ID="w3d1">und</tc:token>
      <tc:token ID="w3d2">zu</tc:token>
      <tc:token ID="w3d3">erwartenden</tc:token>
      <tc:token ID="w3d4">Ergebnissen</tc:token>
      <tc:token ID="w3d5">operationalisiert</tc:token>
      <tc:token ID="w3d6">.</tc:token>
      <tc:token ID="w3d7">Die</tc:token>
      <tc:token ID="w3d8">Ergebnisse</tc:token>
      <tc:token ID="w3d9">werden</tc:token>
      <tc:token ID="w3da">dann</tc:token>
      <tc:token ID="w3db">vor</tc:token>
      <tc:token ID="w3dc">allem</tc:token>
      <tc:token ID="w3dd">hinsichtlich</tc:token>
      <tc:token ID="w3de">der</tc:token>
      <tc:token ID="w3df">erwarteten</tc:token>
      <tc:token ID="w3e0">Zeitverläufe</tc:token>
      <tc:token ID="w3e1">und</tc:token>
      <tc:token ID="w3e2">relativen</tc:token>
      <tc:token ID="w3e3">Unterschiede</tc:token>
      <tc:token ID="w3e4">zwischen</tc:token>
      <tc:token ID="w3e5">Untermengen</tc:token>
      <tc:token ID="w3e6">interpretiert</tc:token>
      <tc:token ID="w3e7">.</tc:token>
      <tc:token ID="w3e8">Die</tc:token>
      <tc:token ID="w3e9">explorative</tc:token>
      <tc:token ID="w3ea">Herangehensweise</tc:token>
      <tc:token ID="w3eb">an</tc:token>
      <tc:token ID="w3ec">die</tc:token>
      <tc:token ID="w3ed">Datenanalyse</tc:token>
      <tc:token ID="w3ee">berücksichtigt</tc:token>
      <tc:token ID="w3ef">dagegen</tc:token>
      <tc:token ID="w3f0">auch</tc:token>
      <tc:token ID="w3f1">andere</tc:token>
      <tc:token ID="w3f2">Hinweise</tc:token>
      <tc:token ID="w3f3">aus</tc:token>
      <tc:token ID="w3f4">den</tc:token>
      <tc:token ID="w3f5">Ergebnissen</tc:token>
      <tc:token ID="w3f6">,</tc:token>
      <tc:token ID="w3f7">und</tc:token>
      <tc:token ID="w3f8">sucht</tc:token>
      <tc:token ID="w3f9">nach</tc:token>
      <tc:token ID="w3fa">Erklärungen</tc:token>
      <tc:token ID="w3fb">für</tc:token>
      <tc:token ID="w3fc">beobachtete</tc:token>
      <tc:token ID="w3fd">Auffälligkeiten</tc:token>
      <tc:token ID="w3fe">.</tc:token>
      <tc:token ID="w3ff">Die</tc:token>
      <tc:token ID="w400">Aussagekraft</tc:token>
      <tc:token ID="w401">der</tc:token>
      <tc:token ID="w402">Ergebnisse</tc:token>
      <tc:token ID="w403">kann</tc:token>
      <tc:token ID="w404">dabei</tc:token>
      <tc:token ID="w405">jedoch</tc:token>
      <tc:token ID="w406">dadurch</tc:token>
      <tc:token ID="w407">eingeschränkt</tc:token>
      <tc:token ID="w408">werden</tc:token>
      <tc:token ID="w409">,</tc:token>
      <tc:token ID="w40a">dass</tc:token>
      <tc:token ID="w40b">die</tc:token>
      <tc:token ID="w40c">untersuchten</tc:token>
      <tc:token ID="w40d">Thesen</tc:token>
      <tc:token ID="w40e">erst</tc:token>
      <tc:token ID="w40f">mit</tc:token>
      <tc:token ID="w410">Kenntnis</tc:token>
      <tc:token ID="w411">der</tc:token>
      <tc:token ID="w412">Daten</tc:token>
      <tc:token ID="w413">formuliert</tc:token>
      <tc:token ID="w414">worden</tc:token>
      <tc:token ID="w415">sind</tc:token>
      <tc:token ID="w416">.</tc:token>
      <tc:token ID="w417">Eine</tc:token>
      <tc:token ID="w418">Strategie</tc:token>
      <tc:token ID="w419">,</tc:token>
      <tc:token ID="w41a">um</tc:token>
      <tc:token ID="w41b">diese</tc:token>
      <tc:token ID="w41c">Unsicherheit</tc:token>
      <tc:token ID="w41d">auszugleichen</tc:token>
      <tc:token ID="w41e">,</tc:token>
      <tc:token ID="w41f">besteht</tc:token>
      <tc:token ID="w420">darin</tc:token>
      <tc:token ID="w421">,</tc:token>
      <tc:token ID="w422">Evidenz</tc:token>
      <tc:token ID="w423">für</tc:token>
      <tc:token ID="w424">eine</tc:token>
      <tc:token ID="w425">Aussage</tc:token>
      <tc:token ID="w426">mit</tc:token>
      <tc:token ID="w427">mehreren</tc:token>
      <tc:token ID="w428">unterschiedlichen</tc:token>
      <tc:token ID="w429">Vorgehensweisen</tc:token>
      <tc:token ID="w42a">zu</tc:token>
      <tc:token ID="w42b">sammeln</tc:token>
      <tc:token ID="w42c">.</tc:token>
      <tc:token ID="w42d">Diese</tc:token>
      <tc:token ID="w42e">Ergebnisse</tc:token>
      <tc:token ID="w42f">zeigen</tc:token>
      <tc:token ID="w430">den</tc:token>
      <tc:token ID="w431">potentiellen</tc:token>
      <tc:token ID="w432">Mehrwert</tc:token>
      <tc:token ID="w433">von</tc:token>
      <tc:token ID="w434">DH</tc:token>
      <tc:token ID="w435">an</tc:token>
      <tc:token ID="w436">,</tc:token>
      <tc:token ID="w437">da</tc:token>
      <tc:token ID="w438">mit</tc:token>
      <tc:token ID="w439">Hilfe</tc:token>
      <tc:token ID="w43a">computerlinguistischer</tc:token>
      <tc:token ID="w43b">und</tc:token>
      <tc:token ID="w43c">informationswissenschaftlicher</tc:token>
      <tc:token ID="w43d">Methoden</tc:token>
      <tc:token ID="w43e">klassische</tc:token>
      <tc:token ID="w43f">Thesen</tc:token>
      <tc:token ID="w440">aus</tc:token>
      <tc:token ID="w441">der</tc:token>
      <tc:token ID="w442">Geschichtswissenschaft</tc:token>
      <tc:token ID="w443">präzisiert</tc:token>
      <tc:token ID="w444">werden</tc:token>
      <tc:token ID="w445">konnten</tc:token>
      <tc:token ID="w446">.</tc:token>
      <tc:token ID="w447">Die</tc:token>
      <tc:token ID="w448">Interpretation</tc:token>
      <tc:token ID="w449">quantitativer</tc:token>
      <tc:token ID="w44a">Ergebnisse</tc:token>
      <tc:token ID="w44b">,</tc:token>
      <tc:token ID="w44c">etwa</tc:token>
      <tc:token ID="w44d">als</tc:token>
      <tc:token ID="w44e">Diagramm</tc:token>
      <tc:token ID="w44f">visualisiert</tc:token>
      <tc:token ID="w450">,</tc:token>
      <tc:token ID="w451">konnte</tc:token>
      <tc:token ID="w452">sich</tc:token>
      <tc:token ID="w453">nach</tc:token>
      <tc:token ID="w454">Bedarf</tc:token>
      <tc:token ID="w455">auf</tc:token>
      <tc:token ID="w456">die</tc:token>
      <tc:token ID="w457">vorab</tc:token>
      <tc:token ID="w458">definierten</tc:token>
      <tc:token ID="w459">Vorannahmen</tc:token>
      <tc:token ID="w45a">beschränken</tc:token>
      <tc:token ID="w45b">.</tc:token>
      <tc:token ID="w45c">Die</tc:token>
      <tc:token ID="w45d">Einbeziehung</tc:token>
      <tc:token ID="w45e">größerer</tc:token>
      <tc:token ID="w45f">zeitlicher</tc:token>
      <tc:token ID="w460">Kontexte</tc:token>
      <tc:token ID="w461">erforderte</tc:token>
      <tc:token ID="w462">teilweise</tc:token>
      <tc:token ID="w463">,</tc:token>
      <tc:token ID="w464">die</tc:token>
      <tc:token ID="w465">dargestellten</tc:token>
      <tc:token ID="w466">Verläufe</tc:token>
      <tc:token ID="w467">und</tc:token>
      <tc:token ID="w468">Tendenzen</tc:token>
      <tc:token ID="w469">mit</tc:token>
      <tc:token ID="w46a">verschiedenen</tc:token>
      <tc:token ID="w46b">Zeitspannen</tc:token>
      <tc:token ID="w46c">neu</tc:token>
      <tc:token ID="w46d">zu</tc:token>
      <tc:token ID="w46e">interpretieren</tc:token>
      <tc:token ID="w46f">.</tc:token>
      <tc:token ID="w470">Als</tc:token>
      <tc:token ID="w471">wichtige</tc:token>
      <tc:token ID="w472">Vorgehensweise</tc:token>
      <tc:token ID="w473">hat</tc:token>
      <tc:token ID="w474">sich</tc:token>
      <tc:token ID="w475">hier</tc:token>
      <tc:token ID="w476">die</tc:token>
      <tc:token ID="w477">Bildung</tc:token>
      <tc:token ID="w478">eines</tc:token>
      <tc:token ID="w479">gleitenden</tc:token>
      <tc:token ID="w47a">Durchschnitts</tc:token>
      <tc:token ID="w47b">über</tc:token>
      <tc:token ID="w47c">längere</tc:token>
      <tc:token ID="w47d">Zeiträume</tc:token>
      <tc:token ID="w47e">erwiesen</tc:token>
      <tc:token ID="w47f">,</tc:token>
      <tc:token ID="w480">um</tc:token>
      <tc:token ID="w481">thematische</tc:token>
      <tc:token ID="w482">Tendenzen</tc:token>
      <tc:token ID="w483">zuverlässiger</tc:token>
      <tc:token ID="w484">interpretieren</tc:token>
      <tc:token ID="w485">zu</tc:token>
      <tc:token ID="w486">können</tc:token>
      <tc:token ID="w487">.</tc:token>
      <tc:token ID="w488">Als</tc:token>
      <tc:token ID="w489">wichtiger</tc:token>
      <tc:token ID="w48a">Faktor</tc:token>
      <tc:token ID="w48b">stellte</tc:token>
      <tc:token ID="w48c">sich</tc:token>
      <tc:token ID="w48d">auch</tc:token>
      <tc:token ID="w48e">die</tc:token>
      <tc:token ID="w48f">Qualität</tc:token>
      <tc:token ID="w490">der</tc:token>
      <tc:token ID="w491">OCR-Digitalisierung</tc:token>
      <tc:token ID="w492">heraus</tc:token>
      <tc:token ID="w493">.</tc:token>
      <tc:token ID="w494">Bei</tc:token>
      <tc:token ID="w495">Daten</tc:token>
      <tc:token ID="w496">aus</tc:token>
      <tc:token ID="w497">historischen</tc:token>
      <tc:token ID="w498">Quellen</tc:token>
      <tc:token ID="w499">(</tc:token>
      <tc:token ID="w49a">Schriftbild</tc:token>
      <tc:token ID="w49b">Sütterlin</tc:token>
      <tc:token ID="w49c">/</tc:token>
      <tc:token ID="w49d">Fraktur</tc:token>
      <tc:token ID="w49e">)</tc:token>
      <tc:token ID="w49f">werden</tc:token>
      <tc:token ID="w4a0">auch</tc:token>
      <tc:token ID="w4a1">mit</tc:token>
      <tc:token ID="w4a2">aktueller</tc:token>
      <tc:token ID="w4a3">Technologie</tc:token>
      <tc:token ID="w4a4">aufgrund</tc:token>
      <tc:token ID="w4a5">der</tc:token>
      <tc:token ID="w4a6">verwendeten</tc:token>
      <tc:token ID="w4a7">Schriftarten</tc:token>
      <tc:token ID="w4a8">teilweise</tc:token>
      <tc:token ID="w4a9">über</tc:token>
      <tc:token ID="w4aa">10</tc:token>
      <tc:token ID="w4ab">Prozent</tc:token>
      <tc:token ID="w4ac">der</tc:token>
      <tc:token ID="w4ad">Zeichen</tc:token>
      <tc:token ID="w4ae">falsch</tc:token>
      <tc:token ID="w4af">erkannt</tc:token>
      <tc:token ID="w4b0">,</tc:token>
      <tc:token ID="w4b1">was</tc:token>
      <tc:token ID="w4b2">bei</tc:token>
      <tc:token ID="w4b3">der</tc:token>
      <tc:token ID="w4b4">Auswertung</tc:token>
      <tc:token ID="w4b5">der</tc:token>
      <tc:token ID="w4b6">maschinell</tc:token>
      <tc:token ID="w4b7">generierten</tc:token>
      <tc:token ID="w4b8">Topics</tc:token>
      <tc:token ID="w4b9">durch</tc:token>
      <tc:token ID="w4ba">die</tc:token>
      <tc:token ID="w4bb">Benutzer</tc:token>
      <tc:token ID="w4bc">zu</tc:token>
      <tc:token ID="w4bd">Problemen</tc:token>
      <tc:token ID="w4be">bei</tc:token>
      <tc:token ID="w4bf">der</tc:token>
      <tc:token ID="w4c0">Interpretation</tc:token>
      <tc:token ID="w4c1">und</tc:token>
      <tc:token ID="w4c2">Weiterverwendung</tc:token>
      <tc:token ID="w4c3">führt</tc:token>
      <tc:token ID="w4c4">.</tc:token>
      <tc:token ID="w4c5">Daher</tc:token>
      <tc:token ID="w4c6">muss</tc:token>
      <tc:token ID="w4c7">die</tc:token>
      <tc:token ID="w4c8">Frage</tc:token>
      <tc:token ID="w4c9">gestellt</tc:token>
      <tc:token ID="w4ca">werden</tc:token>
      <tc:token ID="w4cb">,</tc:token>
      <tc:token ID="w4cc">wie</tc:token>
      <tc:token ID="w4cd">Daten</tc:token>
      <tc:token ID="w4ce">zukünftig</tc:token>
      <tc:token ID="w4cf">in</tc:token>
      <tc:token ID="w4d0">den</tc:token>
      <tc:token ID="w4d1">Vorverarbeitungsschritten</tc:token>
      <tc:token ID="w4d2">aufbereitet</tc:token>
      <tc:token ID="w4d3">werden</tc:token>
      <tc:token ID="w4d4">,</tc:token>
      <tc:token ID="w4d5">damit</tc:token>
      <tc:token ID="w4d6">Topic</tc:token>
      <tc:token ID="w4d7">Modelling</tc:token>
      <tc:token ID="w4d8">und</tc:token>
      <tc:token ID="w4d9">andere</tc:token>
      <tc:token ID="w4da">automatische</tc:token>
      <tc:token ID="w4db">Methoden</tc:token>
      <tc:token ID="w4dc">zu</tc:token>
      <tc:token ID="w4dd">hilfreichen</tc:token>
      <tc:token ID="w4de">und</tc:token>
      <tc:token ID="w4df">interpretierbaren</tc:token>
      <tc:token ID="w4e0">Ergebnissen</tc:token>
      <tc:token ID="w4e1">führen</tc:token>
      <tc:token ID="w4e2">.</tc:token>
      <tc:token ID="w4e3">Neben</tc:token>
      <tc:token ID="w4e4">der</tc:token>
      <tc:token ID="w4e5">Einbeziehung</tc:token>
      <tc:token ID="w4e6">von</tc:token>
      <tc:token ID="w4e7">Topic</tc:token>
      <tc:token ID="w4e8">Models</tc:token>
      <tc:token ID="w4e9">,</tc:token>
      <tc:token ID="w4ea">die</tc:token>
      <tc:token ID="w4eb">auf</tc:token>
      <tc:token ID="w4ec">unterschiedliche</tc:token>
      <tc:token ID="w4ed">Perspektiven</tc:token>
      <tc:token ID="w4ee">optimiert</tc:token>
      <tc:token ID="w4ef">wurden</tc:token>
      <tc:token ID="w4f0">,</tc:token>
      <tc:token ID="w4f1">werden</tc:token>
      <tc:token ID="w4f2">im</tc:token>
      <tc:token ID="w4f3">Rahmen</tc:token>
      <tc:token ID="w4f4">des</tc:token>
      <tc:token ID="w4f5">Projektes</tc:token>
      <tc:token ID="w4f6">andere</tc:token>
      <tc:token ID="w4f7">Herangehensweisen</tc:token>
      <tc:token ID="w4f8">an</tc:token>
      <tc:token ID="w4f9">die</tc:token>
      <tc:token ID="w4fa">statistische</tc:token>
      <tc:token ID="w4fb">Textmodellierung</tc:token>
      <tc:token ID="w4fc">,</tc:token>
      <tc:token ID="w4fd">wie</tc:token>
      <tc:token ID="w4fe">z.</tc:token>
      <tc:token ID="w4ff">B.</tc:token>
      <tc:token ID="w500">Clustering-Verfahren</tc:token>
      <tc:token ID="w501">,</tc:token>
      <tc:token ID="w502">in</tc:token>
      <tc:token ID="w503">Hinblick</tc:token>
      <tc:token ID="w504">auf</tc:token>
      <tc:token ID="w505">ihre</tc:token>
      <tc:token ID="w506">Anwendbarkeit</tc:token>
      <tc:token ID="w507">und</tc:token>
      <tc:token ID="w508">Robustheit</tc:token>
      <tc:token ID="w509">vergleichend</tc:token>
      <tc:token ID="w50a">evaluiert</tc:token>
      <tc:token ID="w50b">.</tc:token>
      <tc:token ID="w50c">In</tc:token>
      <tc:token ID="w50d">diesem</tc:token>
      <tc:token ID="w50e">Zusammenhang</tc:token>
      <tc:token ID="w50f">ist</tc:token>
      <tc:token ID="w510">es</tc:token>
      <tc:token ID="w511">wichtig</tc:token>
      <tc:token ID="w512">,</tc:token>
      <tc:token ID="w513">thematisch</tc:token>
      <tc:token ID="w514">relevante</tc:token>
      <tc:token ID="w515">Topics</tc:token>
      <tc:token ID="w516">einfach</tc:token>
      <tc:token ID="w517">auffindbar</tc:token>
      <tc:token ID="w518">zu</tc:token>
      <tc:token ID="w519">machen</tc:token>
      <tc:token ID="w51a">und</tc:token>
      <tc:token ID="w51b">sie</tc:token>
      <tc:token ID="w51c">für</tc:token>
      <tc:token ID="w51d">Anfragen</tc:token>
      <tc:token ID="w51e">kombinieren</tc:token>
      <tc:token ID="w51f">zu</tc:token>
      <tc:token ID="w520">können</tc:token>
      <tc:token ID="w521">.</tc:token>
      <tc:token ID="w522">Des</tc:token>
      <tc:token ID="w523">Weiteren</tc:token>
      <tc:token ID="w524">sollten</tc:token>
      <tc:token ID="w525">Topics</tc:token>
      <tc:token ID="w526">geordnet</tc:token>
      <tc:token ID="w527">nach</tc:token>
      <tc:token ID="w528">Themen</tc:token>
      <tc:token ID="w529">oder</tc:token>
      <tc:token ID="w52a">Diskursfeldern</tc:token>
      <tc:token ID="w52b">und</tc:token>
      <tc:token ID="w52c">/</tc:token>
      <tc:token ID="w52d">oder</tc:token>
      <tc:token ID="w52e">-strängen</tc:token>
      <tc:token ID="w52f">präsentiert</tc:token>
      <tc:token ID="w530">werden</tc:token>
      <tc:token ID="w531">sowie</tc:token>
      <tc:token ID="w532">in</tc:token>
      <tc:token ID="w533">einer</tc:token>
      <tc:token ID="w534">leicht</tc:token>
      <tc:token ID="w535">lesbaren</tc:token>
      <tc:token ID="w536">Anzeige</tc:token>
      <tc:token ID="w537">deren</tc:token>
      <tc:token ID="w538">synchrone</tc:token>
      <tc:token ID="w539">und</tc:token>
      <tc:token ID="w53a">diachrone</tc:token>
      <tc:token ID="w53b">Verteilungen</tc:token>
      <tc:token ID="w53c">herausstellen</tc:token>
      <tc:token ID="w53d">,</tc:token>
      <tc:token ID="w53e">wobei</tc:token>
      <tc:token ID="w53f">Ungleichverteilungen</tc:token>
      <tc:token ID="w540">innerhalb</tc:token>
      <tc:token ID="w541">der</tc:token>
      <tc:token ID="w542">Untersuchungsmenge</tc:token>
      <tc:token ID="w543">und</tc:token>
      <tc:token ID="w544">die</tc:token>
      <tc:token ID="w545">Zuverlässigkeit</tc:token>
      <tc:token ID="w546">statistischer</tc:token>
      <tc:token ID="w547">Aggregierungen</tc:token>
      <tc:token ID="w548">deutlich</tc:token>
      <tc:token ID="w549">gemacht</tc:token>
      <tc:token ID="w54a">werden</tc:token>
      <tc:token ID="w54b">müssen</tc:token>
      <tc:token ID="w54c">.</tc:token>
      <tc:token ID="w54d">Motivation</tc:token>
      <tc:token ID="w54e">und</tc:token>
      <tc:token ID="w54f">Fragestellung</tc:token>
      <tc:token ID="w550">Werkzeuge</tc:token>
      <tc:token ID="w551">Vorgehen</tc:token>
      <tc:token ID="w552">bei</tc:token>
      <tc:token ID="w553">der</tc:token>
      <tc:token ID="w554">Validierung</tc:token>
      <tc:token ID="w555">:</tc:token>
      <tc:token ID="w556">Auswertung</tc:token>
      <tc:token ID="w557">Schlussfolgerungen</tc:token>
      <tc:token ID="w558">Blei</tc:token>
      <tc:token ID="w559">,</tc:token>
      <tc:token ID="w55a">David.</tc:token>
      <tc:token ID="w55b">M.</tc:token>
      <tc:token ID="w55c">/</tc:token>
      <tc:token ID="w55d">Ng</tc:token>
      <tc:token ID="w55e">,</tc:token>
      <tc:token ID="w55f">Andrew.</tc:token>
      <tc:token ID="w560">Y.</tc:token>
      <tc:token ID="w561">/</tc:token>
      <tc:token ID="w562">Jordan</tc:token>
      <tc:token ID="w563">,</tc:token>
      <tc:token ID="w564">Michael</tc:token>
      <tc:token ID="w565">I.</tc:token>
      <tc:token ID="w566">(</tc:token>
      <tc:token ID="w567">2003</tc:token>
      <tc:token ID="w568">)</tc:token>
      <tc:token ID="w569">:</tc:token>
      <tc:token ID="w56a">"</tc:token>
      <tc:token ID="w56b">Latent</tc:token>
      <tc:token ID="w56c">Dirichlet</tc:token>
      <tc:token ID="w56d">allocation</tc:token>
      <tc:token ID="w56e">"</tc:token>
      <tc:token ID="w56f">,</tc:token>
      <tc:token ID="w570">in</tc:token>
      <tc:token ID="w571">:</tc:token>
      <tc:token ID="w572">Journal</tc:token>
      <tc:token ID="w573">of</tc:token>
      <tc:token ID="w574">Machine</tc:token>
      <tc:token ID="w575">Learning</tc:token>
      <tc:token ID="w576">Research</tc:token>
      <tc:token ID="w577">3:</tc:token>
      <tc:token ID="w578">993–1022</tc:token>
      <tc:token ID="w579">.</tc:token>
      <tc:token ID="w57a">Chuang</tc:token>
      <tc:token ID="w57b">,</tc:token>
      <tc:token ID="w57c">Jason</tc:token>
      <tc:token ID="w57d">/</tc:token>
      <tc:token ID="w57e">Ramage</tc:token>
      <tc:token ID="w57f">,</tc:token>
      <tc:token ID="w580">Daniel</tc:token>
      <tc:token ID="w581">/</tc:token>
      <tc:token ID="w582">Manning</tc:token>
      <tc:token ID="w583">,</tc:token>
      <tc:token ID="w584">Chistopher</tc:token>
      <tc:token ID="w585">/</tc:token>
      <tc:token ID="w586">Heer</tc:token>
      <tc:token ID="w587">,</tc:token>
      <tc:token ID="w588">Jeffrey</tc:token>
      <tc:token ID="w589">(</tc:token>
      <tc:token ID="w58a">2012</tc:token>
      <tc:token ID="w58b">)</tc:token>
      <tc:token ID="w58c">:</tc:token>
      <tc:token ID="w58d">"</tc:token>
      <tc:token ID="w58e">Interpretation</tc:token>
      <tc:token ID="w58f">and</tc:token>
      <tc:token ID="w590">Trust</tc:token>
      <tc:token ID="w591">:</tc:token>
      <tc:token ID="w592">Designing</tc:token>
      <tc:token ID="w593">Model-driven</tc:token>
      <tc:token ID="w594">Visualizations</tc:token>
      <tc:token ID="w595">for</tc:token>
      <tc:token ID="w596">Text</tc:token>
      <tc:token ID="w597">Analysis</tc:token>
      <tc:token ID="w598">"</tc:token>
      <tc:token ID="w599">,</tc:token>
      <tc:token ID="w59a">in</tc:token>
      <tc:token ID="w59b">:</tc:token>
      <tc:token ID="w59c">Proceedings</tc:token>
      <tc:token ID="w59d">of</tc:token>
      <tc:token ID="w59e">the</tc:token>
      <tc:token ID="w59f">SIGCHI</tc:token>
      <tc:token ID="w5a0">Conference</tc:token>
      <tc:token ID="w5a1">on</tc:token>
      <tc:token ID="w5a2">Human</tc:token>
      <tc:token ID="w5a3">Factors</tc:token>
      <tc:token ID="w5a4">in</tc:token>
      <tc:token ID="w5a5">Computing</tc:token>
      <tc:token ID="w5a6">Systems</tc:token>
      <tc:token ID="w5a7">,</tc:token>
      <tc:token ID="w5a8">CHI</tc:token>
      <tc:token ID="w5a9">’12</tc:token>
      <tc:token ID="w5aa">.</tc:token>
      <tc:token ID="w5ab">New</tc:token>
      <tc:token ID="w5ac">York</tc:token>
      <tc:token ID="w5ad">,</tc:token>
      <tc:token ID="w5ae">NY</tc:token>
      <tc:token ID="w5af">,</tc:token>
      <tc:token ID="w5b0">USA</tc:token>
      <tc:token ID="w5b1">:</tc:token>
      <tc:token ID="w5b2">ACM</tc:token>
      <tc:token ID="w5b3">443–452</tc:token>
      <tc:token ID="w5b4">.</tc:token>
      <tc:token ID="w5b5">DiMaggio</tc:token>
      <tc:token ID="w5b6">,</tc:token>
      <tc:token ID="w5b7">Paul</tc:token>
      <tc:token ID="w5b8">/</tc:token>
      <tc:token ID="w5b9">Nag</tc:token>
      <tc:token ID="w5ba">,</tc:token>
      <tc:token ID="w5bb">Manish</tc:token>
      <tc:token ID="w5bc">/</tc:token>
      <tc:token ID="w5bd">Blei</tc:token>
      <tc:token ID="w5be">,</tc:token>
      <tc:token ID="w5bf">David</tc:token>
      <tc:token ID="w5c0">(</tc:token>
      <tc:token ID="w5c1">2013</tc:token>
      <tc:token ID="w5c2">)</tc:token>
      <tc:token ID="w5c3">:</tc:token>
      <tc:token ID="w5c4">"</tc:token>
      <tc:token ID="w5c5">Exploiting</tc:token>
      <tc:token ID="w5c6">affinities</tc:token>
      <tc:token ID="w5c7">between</tc:token>
      <tc:token ID="w5c8">topic</tc:token>
      <tc:token ID="w5c9">modeling</tc:token>
      <tc:token ID="w5ca">and</tc:token>
      <tc:token ID="w5cb">the</tc:token>
      <tc:token ID="w5cc">sociological</tc:token>
      <tc:token ID="w5cd">perspective</tc:token>
      <tc:token ID="w5ce">on</tc:token>
      <tc:token ID="w5cf">culture</tc:token>
      <tc:token ID="w5d0">:</tc:token>
      <tc:token ID="w5d1">Application</tc:token>
      <tc:token ID="w5d2">to</tc:token>
      <tc:token ID="w5d3">newspaper</tc:token>
      <tc:token ID="w5d4">coverage</tc:token>
      <tc:token ID="w5d5">of</tc:token>
      <tc:token ID="w5d6">U.</tc:token>
      <tc:token ID="w5d7">S.</tc:token>
      <tc:token ID="w5d8">government</tc:token>
      <tc:token ID="w5d9">arts</tc:token>
      <tc:token ID="w5da">funding</tc:token>
      <tc:token ID="w5db">"</tc:token>
      <tc:token ID="w5dc">,</tc:token>
      <tc:token ID="w5dd">in</tc:token>
      <tc:token ID="w5de">:</tc:token>
      <tc:token ID="w5df">Poetics</tc:token>
      <tc:token ID="w5e0">41</tc:token>
      <tc:token ID="w5e1">,</tc:token>
      <tc:token ID="w5e2">6</tc:token>
      <tc:token ID="w5e3">:</tc:token>
      <tc:token ID="w5e4">570–606</tc:token>
      <tc:token ID="w5e5">.</tc:token>
      <tc:token ID="w5e6">Evans</tc:token>
      <tc:token ID="w5e7">,</tc:token>
      <tc:token ID="w5e8">Michael</tc:token>
      <tc:token ID="w5e9">S.</tc:token>
      <tc:token ID="w5ea">(</tc:token>
      <tc:token ID="w5eb">2014</tc:token>
      <tc:token ID="w5ec">)</tc:token>
      <tc:token ID="w5ed">:</tc:token>
      <tc:token ID="w5ee">"</tc:token>
      <tc:token ID="w5ef">A</tc:token>
      <tc:token ID="w5f0">Computational</tc:token>
      <tc:token ID="w5f1">Approach</tc:token>
      <tc:token ID="w5f2">to</tc:token>
      <tc:token ID="w5f3">Qualitative</tc:token>
      <tc:token ID="w5f4">Analysis</tc:token>
      <tc:token ID="w5f5">in</tc:token>
      <tc:token ID="w5f6">Large</tc:token>
      <tc:token ID="w5f7">Textual</tc:token>
      <tc:token ID="w5f8">Datasets</tc:token>
      <tc:token ID="w5f9">"</tc:token>
      <tc:token ID="w5fa">,</tc:token>
      <tc:token ID="w5fb">in</tc:token>
      <tc:token ID="w5fc">:</tc:token>
      <tc:token ID="w5fd">PLoS</tc:token>
      <tc:token ID="w5fe">ONE9</tc:token>
      <tc:token ID="w5ff">,</tc:token>
      <tc:token ID="w600">2</tc:token>
      <tc:token ID="w601">,</tc:token>
      <tc:token ID="w602">e</tc:token>
      <tc:token ID="w603">87908</tc:token>
      <tc:token ID="w604">.</tc:token>
      <tc:token ID="w605">Kaplan</tc:token>
      <tc:token ID="w606">,</tc:token>
      <tc:token ID="w607">Frédéric</tc:token>
      <tc:token ID="w608">(</tc:token>
      <tc:token ID="w609">2015</tc:token>
      <tc:token ID="w60a">)</tc:token>
      <tc:token ID="w60b">:</tc:token>
      <tc:token ID="w60c">"</tc:token>
      <tc:token ID="w60d">A</tc:token>
      <tc:token ID="w60e">map</tc:token>
      <tc:token ID="w60f">for</tc:token>
      <tc:token ID="w610">Big</tc:token>
      <tc:token ID="w611">Data</tc:token>
      <tc:token ID="w612">research</tc:token>
      <tc:token ID="w613">in</tc:token>
      <tc:token ID="w614">Digital</tc:token>
      <tc:token ID="w615">Humanities</tc:token>
      <tc:token ID="w616">"</tc:token>
      <tc:token ID="w617">,</tc:token>
      <tc:token ID="w618">in</tc:token>
      <tc:token ID="w619">:</tc:token>
      <tc:token ID="w61a">Frontiers</tc:token>
      <tc:token ID="w61b">in</tc:token>
      <tc:token ID="w61c">Digital</tc:token>
      <tc:token ID="w61d">Humanities</tc:token>
      <tc:token ID="w61e">2</tc:token>
      <tc:token ID="w61f">,</tc:token>
      <tc:token ID="w620">1</tc:token>
      <tc:token ID="w621">:</tc:token>
      <tc:token ID="w622">http://journal.frontiersin.org/article/10.3389/fdigh.2015.00001/abstract</tc:token>
      <tc:token ID="w623">[</tc:token>
      <tc:token ID="w624">letzter</tc:token>
      <tc:token ID="w625">Zugriff</tc:token>
      <tc:token ID="w626">08.</tc:token>
      <tc:token ID="w627">Januar</tc:token>
      <tc:token ID="w628">2016</tc:token>
      <tc:token ID="w629">]</tc:token>
      <tc:token ID="w62a">.</tc:token>
      <tc:token ID="w62b">Newman</tc:token>
      <tc:token ID="w62c">,</tc:token>
      <tc:token ID="w62d">David</tc:token>
      <tc:token ID="w62e">J.</tc:token>
      <tc:token ID="w62f">/</tc:token>
      <tc:token ID="w630">Block</tc:token>
      <tc:token ID="w631">,</tc:token>
      <tc:token ID="w632">Sharon</tc:token>
      <tc:token ID="w633">(</tc:token>
      <tc:token ID="w634">2006</tc:token>
      <tc:token ID="w635">)</tc:token>
      <tc:token ID="w636">:</tc:token>
      <tc:token ID="w637">"</tc:token>
      <tc:token ID="w638">Probabilistic</tc:token>
      <tc:token ID="w639">topic</tc:token>
      <tc:token ID="w63a">decomposition</tc:token>
      <tc:token ID="w63b">of</tc:token>
      <tc:token ID="w63c">an</tc:token>
      <tc:token ID="w63d">eighteenth-century</tc:token>
      <tc:token ID="w63e">American</tc:token>
      <tc:token ID="w63f">newspaper</tc:token>
      <tc:token ID="w640">"</tc:token>
      <tc:token ID="w641">,</tc:token>
      <tc:token ID="w642">in</tc:token>
      <tc:token ID="w643">:</tc:token>
      <tc:token ID="w644">Journal</tc:token>
      <tc:token ID="w645">of</tc:token>
      <tc:token ID="w646">the</tc:token>
      <tc:token ID="w647">American</tc:token>
      <tc:token ID="w648">Society</tc:token>
      <tc:token ID="w649">for</tc:token>
      <tc:token ID="w64a">Information</tc:token>
      <tc:token ID="w64b">Science</tc:token>
      <tc:token ID="w64c">and</tc:token>
      <tc:token ID="w64d">Technology</tc:token>
      <tc:token ID="w64e">57</tc:token>
      <tc:token ID="w64f">,</tc:token>
      <tc:token ID="w650">6</tc:token>
      <tc:token ID="w651">:</tc:token>
      <tc:token ID="w652">753–767</tc:token>
      <tc:token ID="w653">.</tc:token>
      <tc:token ID="w654">Yang</tc:token>
      <tc:token ID="w655">,</tc:token>
      <tc:token ID="w656">Tze-I</tc:token>
      <tc:token ID="w657">.</tc:token>
      <tc:token ID="w658">/</tc:token>
      <tc:token ID="w659">Torget</tc:token>
      <tc:token ID="w65a">,</tc:token>
      <tc:token ID="w65b">Andrew</tc:token>
      <tc:token ID="w65c">J.</tc:token>
      <tc:token ID="w65d">/</tc:token>
      <tc:token ID="w65e">Mihalcea</tc:token>
      <tc:token ID="w65f">,</tc:token>
      <tc:token ID="w660">Rada</tc:token>
      <tc:token ID="w661">(</tc:token>
      <tc:token ID="w662">2011</tc:token>
      <tc:token ID="w663">)</tc:token>
      <tc:token ID="w664">:</tc:token>
      <tc:token ID="w665">"</tc:token>
      <tc:token ID="w666">Topic</tc:token>
      <tc:token ID="w667">modeling</tc:token>
      <tc:token ID="w668">on</tc:token>
      <tc:token ID="w669">historical</tc:token>
      <tc:token ID="w66a">newspapers</tc:token>
      <tc:token ID="w66b">"</tc:token>
      <tc:token ID="w66c">,</tc:token>
      <tc:token ID="w66d">in</tc:token>
      <tc:token ID="w66e">:</tc:token>
      <tc:token ID="w66f">Proceedings</tc:token>
      <tc:token ID="w670">of</tc:token>
      <tc:token ID="w671">the</tc:token>
      <tc:token ID="w672">5th</tc:token>
      <tc:token ID="w673">ACL-HLT</tc:token>
      <tc:token ID="w674">Workshop</tc:token>
      <tc:token ID="w675">on</tc:token>
      <tc:token ID="w676">Language</tc:token>
      <tc:token ID="w677">Technology</tc:token>
      <tc:token ID="w678">for</tc:token>
      <tc:token ID="w679">Cultural</tc:token>
      <tc:token ID="w67a">Heritage</tc:token>
      <tc:token ID="w67b">,</tc:token>
      <tc:token ID="w67c">Social</tc:token>
      <tc:token ID="w67d">Sciences</tc:token>
      <tc:token ID="w67e">,</tc:token>
      <tc:token ID="w67f">and</tc:token>
      <tc:token ID="w680">Humanities</tc:token>
      <tc:token ID="w681">.</tc:token>
      <tc:token ID="w682">Association</tc:token>
      <tc:token ID="w683">for</tc:token>
      <tc:token ID="w684">Computational</tc:token>
      <tc:token ID="w685">Linguistics</tc:token>
      <tc:token ID="w686">96–104</tc:token>
      <tc:token ID="w687">.</tc:token>
      <tc:token ID="w688">Bibliographie</tc:token>
    </tc:tokens>
    <tc:sentences xmlns:tc="http://www.dspin.de/data/textcorpus">
      <tc:sentence tokenIDs="w1 w2 w3 w4 w5 w6 w7 w8 w9 wa wb wc wd" ID="s1"/>
      <tc:sentence tokenIDs="we wf w10 w11 w12 w13 w14 w15 w16 w17 w18 w19 w1a w1b w1c w1d w1e w1f w20 w21 w22 w23 w24 w25" ID="s2"/>
      <tc:sentence tokenIDs="w26 w27 w28 w29 w2a w2b w2c w2d w2e w2f w30 w31 w32 w33 w34 w35 w36 w37 w38 w39 w3a w3b w3c w3d w3e w3f w40 w41 w42 w43 w44 w45" ID="s3"/>
      <tc:sentence tokenIDs="w46 w47 w48 w49 w4a w4b w4c w4d w4e w4f w50 w51 w52 w53 w54 w55 w56 w57 w58 w59 w5a w5b w5c w5d w5e w5f w60 w61 w62 w63" ID="s4"/>
      <tc:sentence tokenIDs="w64 w65 w66 w67 w68 w69 w6a w6b w6c w6d w6e w6f w70 w71 w72 w73 w74 w75 w76 w77 w78 w79 w7a w7b w7c w7d w7e w7f w80" ID="s5"/>
      <tc:sentence tokenIDs="w81 w82 w83 w84 w85 w86 w87 w88 w89 w8a w8b w8c w8d w8e" ID="s6"/>
      <tc:sentence tokenIDs="w8f w90 w91 w92 w93 w94 w95 w96 w97 w98 w99 w9a w9b w9c w9d w9e w9f wa0 wa1 wa2 wa3 wa4 wa5 wa6 wa7 wa8 wa9 waa wab wac wad wae waf" ID="s7"/>
      <tc:sentence tokenIDs="wb0 wb1 wb2 wb3 wb4 wb5 wb6 wb7 wb8 wb9 wba wbb wbc wbd wbe wbf wc0 wc1" ID="s8"/>
      <tc:sentence tokenIDs="wc2 wc3 wc4 wc5 wc6 wc7 wc8 wc9 wca wcb wcc wcd wce wcf wd0 wd1 wd2 wd3 wd4 wd5 wd6 wd7 wd8 wd9 wda wdb" ID="s9"/>
      <tc:sentence tokenIDs="wdc wdd wde wdf we0 we1 we2 we3 we4 we5 we6 we7 we8 we9 wea web wec wed wee wef wf0 wf1 wf2" ID="sa"/>
      <tc:sentence tokenIDs="wf3 wf4 wf5 wf6 wf7 wf8 wf9 wfa wfb wfc wfd wfe wff w100 w101 w102 w103 w104" ID="sb"/>
      <tc:sentence tokenIDs="w105 w106 w107 w108 w109 w10a w10b w10c w10d w10e w10f w110 w111 w112 w113 w114 w115 w116 w117 w118 w119 w11a w11b w11c w11d w11e w11f w120 w121 w122 w123" ID="sc"/>
      <tc:sentence tokenIDs="w124 w125 w126 w127 w128 w129 w12a w12b w12c w12d w12e w12f w130 w131 w132 w133 w134 w135 w136 w137 w138 w139 w13a w13b w13c w13d w13e w13f w140 w141 w142 w143 w144 w145 w146 w147 w148 w149 w14a" ID="sd"/>
      <tc:sentence tokenIDs="w14b w14c" ID="se"/>
      <tc:sentence tokenIDs="w14d w14e w14f w150 w151 w152 w153 w154 w155 w156 w157 w158 w159 w15a w15b w15c w15d w15e w15f w160 w161 w162 w163 w164 w165 w166" ID="sf"/>
      <tc:sentence tokenIDs="w167 w168" ID="s10"/>
      <tc:sentence tokenIDs="w169 w16a w16b w16c w16d w16e w16f w170 w171 w172 w173 w174 w175 w176 w177 w178 w179 w17a w17b w17c" ID="s11"/>
      <tc:sentence tokenIDs="w17d w17e" ID="s12"/>
      <tc:sentence tokenIDs="w17f w180 w181 w182 w183 w184 w185 w186 w187 w188 w189 w18a w18b w18c w18d w18e w18f w190 w191 w192 w193 w194 w195" ID="s13"/>
      <tc:sentence tokenIDs="w196 w197 w198 w199 w19a w19b w19c w19d w19e w19f w1a0 w1a1 w1a2 w1a3 w1a4 w1a5 w1a6 w1a7 w1a8 w1a9 w1aa w1ab w1ac w1ad w1ae w1af w1b0 w1b1 w1b2 w1b3 w1b4 w1b5 w1b6 w1b7 w1b8 w1b9 w1ba w1bb w1bc" ID="s14"/>
      <tc:sentence tokenIDs="w1bd w1be w1bf w1c0 w1c1 w1c2 w1c3 w1c4 w1c5 w1c6 w1c7 w1c8 w1c9 w1ca w1cb w1cc w1cd w1ce w1cf w1d0 w1d1 w1d2 w1d3 w1d4 w1d5" ID="s15"/>
      <tc:sentence tokenIDs="w1d6 w1d7 w1d8 w1d9 w1da w1db w1dc w1dd w1de w1df w1e0 w1e1 w1e2 w1e3 w1e4 w1e5 w1e6 w1e7 w1e8 w1e9 w1ea" ID="s16"/>
      <tc:sentence tokenIDs="w1eb w1ec w1ed w1ee w1ef w1f0 w1f1 w1f2 w1f3 w1f4 w1f5 w1f6 w1f7 w1f8 w1f9 w1fa w1fb w1fc w1fd" ID="s17"/>
      <tc:sentence tokenIDs="w1fe w1ff w200 w201 w202 w203 w204 w205 w206 w207 w208 w209 w20a w20b w20c w20d w20e w20f w210 w211 w212 w213" ID="s18"/>
      <tc:sentence tokenIDs="w214 w215 w216 w217 w218 w219 w21a w21b w21c w21d w21e w21f w220 w221 w222 w223 w224 w225 w226 w227" ID="s19"/>
      <tc:sentence tokenIDs="w228 w229 w22a w22b w22c w22d w22e w22f w230 w231 w232 w233 w234" ID="s1a"/>
      <tc:sentence tokenIDs="w235 w236 w237 w238 w239 w23a w23b w23c w23d w23e w23f w240" ID="s1b"/>
      <tc:sentence tokenIDs="w241 w242 w243 w244 w245 w246 w247 w248 w249 w24a w24b w24c w24d w24e w24f w250 w251 w252 w253 w254 w255 w256 w257 w258 w259 w25a w25b w25c w25d w25e w25f w260 w261" ID="s1c"/>
      <tc:sentence tokenIDs="w262 w263 w264 w265 w266 w267 w268 w269 w26a w26b w26c w26d w26e w26f w270 w271 w272 w273 w274 w275 w276 w277 w278 w279 w27a w27b w27c w27d w27e w27f w280 w281 w282 w283 w284 w285 w286 w287 w288 w289 w28a w28b w28c w28d w28e w28f w290 w291 w292 w293 w294" ID="s1d"/>
      <tc:sentence tokenIDs="w295 w296 w297 w298 w299 w29a w29b w29c w29d w29e w29f w2a0 w2a1 w2a2 w2a3 w2a4 w2a5 w2a6 w2a7" ID="s1e"/>
      <tc:sentence tokenIDs="w2a8 w2a9 w2aa w2ab w2ac w2ad w2ae w2af w2b0 w2b1 w2b2 w2b3 w2b4 w2b5 w2b6 w2b7 w2b8 w2b9 w2ba w2bb w2bc w2bd w2be w2bf w2c0" ID="s1f"/>
      <tc:sentence tokenIDs="w2c1 w2c2 w2c3 w2c4 w2c5 w2c6 w2c7 w2c8 w2c9 w2ca w2cb w2cc w2cd w2ce w2cf w2d0 w2d1 w2d2 w2d3 w2d4 w2d5" ID="s20"/>
      <tc:sentence tokenIDs="w2d6 w2d7 w2d8 w2d9 w2da w2db w2dc w2dd w2de w2df w2e0 w2e1 w2e2 w2e3 w2e4 w2e5 w2e6 w2e7 w2e8 w2e9 w2ea w2eb w2ec w2ed w2ee w2ef w2f0" ID="s21"/>
      <tc:sentence tokenIDs="w2f1 w2f2 w2f3 w2f4 w2f5 w2f6 w2f7 w2f8 w2f9 w2fa w2fb w2fc w2fd w2fe w2ff w300" ID="s22"/>
      <tc:sentence tokenIDs="w301 w302 w303 w304 w305 w306 w307 w308 w309 w30a w30b w30c" ID="s23"/>
      <tc:sentence tokenIDs="w30d w30e w30f w310 w311 w312 w313 w314 w315 w316 w317 w318 w319 w31a w31b w31c w31d w31e w31f w320 w321 w322" ID="s24"/>
      <tc:sentence tokenIDs="w323 w324 w325 w326 w327 w328 w329 w32a w32b w32c w32d w32e w32f w330 w331 w332 w333 w334" ID="s25"/>
      <tc:sentence tokenIDs="w335 w336 w337 w338 w339 w33a w33b w33c w33d w33e w33f w340 w341 w342 w343 w344 w345 w346 w347 w348" ID="s26"/>
      <tc:sentence tokenIDs="w349 w34a w34b w34c w34d w34e w34f w350 w351 w352 w353 w354 w355 w356 w357 w358 w359 w35a w35b w35c w35d w35e w35f w360 w361 w362 w363 w364 w365 w366 w367 w368" ID="s27"/>
      <tc:sentence tokenIDs="w369 w36a w36b w36c w36d w36e w36f w370 w371 w372 w373 w374 w375 w376 w377" ID="s28"/>
      <tc:sentence tokenIDs="w378 w379 w37a w37b w37c w37d w37e w37f w380 w381 w382 w383 w384 w385 w386 w387 w388 w389" ID="s29"/>
      <tc:sentence tokenIDs="w38a w38b w38c w38d w38e w38f w390 w391 w392 w393 w394 w395 w396 w397 w398 w399 w39a w39b" ID="s2a"/>
      <tc:sentence tokenIDs="w39c w39d w39e w39f w3a0 w3a1 w3a2 w3a3 w3a4 w3a5 w3a6 w3a7 w3a8 w3a9 w3aa w3ab w3ac w3ad w3ae w3af w3b0 w3b1 w3b2 w3b3" ID="s2b"/>
      <tc:sentence tokenIDs="w3b4 w3b5 w3b6 w3b7 w3b8 w3b9 w3ba w3bb w3bc" ID="s2c"/>
      <tc:sentence tokenIDs="w3bd w3be w3bf w3c0 w3c1 w3c2 w3c3 w3c4 w3c5 w3c6 w3c7" ID="s2d"/>
      <tc:sentence tokenIDs="w3c8 w3c9 w3ca w3cb w3cc w3cd w3ce w3cf w3d0 w3d1 w3d2 w3d3 w3d4 w3d5 w3d6" ID="s2e"/>
      <tc:sentence tokenIDs="w3d7 w3d8 w3d9 w3da w3db w3dc w3dd w3de w3df w3e0 w3e1 w3e2 w3e3 w3e4 w3e5 w3e6 w3e7" ID="s2f"/>
      <tc:sentence tokenIDs="w3e8 w3e9 w3ea w3eb w3ec w3ed w3ee w3ef w3f0 w3f1 w3f2 w3f3 w3f4 w3f5 w3f6 w3f7 w3f8 w3f9 w3fa w3fb w3fc w3fd w3fe" ID="s30"/>
      <tc:sentence tokenIDs="w3ff w400 w401 w402 w403 w404 w405 w406 w407 w408 w409 w40a w40b w40c w40d w40e w40f w410 w411 w412 w413 w414 w415 w416" ID="s31"/>
      <tc:sentence tokenIDs="w417 w418 w419 w41a w41b w41c w41d w41e w41f w420 w421 w422 w423 w424 w425 w426 w427 w428 w429 w42a w42b w42c" ID="s32"/>
      <tc:sentence tokenIDs="w42d w42e w42f w430 w431 w432 w433 w434 w435 w436 w437 w438 w439 w43a w43b w43c w43d w43e w43f w440 w441 w442 w443 w444 w445 w446" ID="s33"/>
      <tc:sentence tokenIDs="w447 w448 w449 w44a w44b w44c w44d w44e w44f w450 w451 w452 w453 w454 w455 w456 w457 w458 w459 w45a w45b" ID="s34"/>
      <tc:sentence tokenIDs="w45c w45d w45e w45f w460 w461 w462 w463 w464 w465 w466 w467 w468 w469 w46a w46b w46c w46d w46e w46f" ID="s35"/>
      <tc:sentence tokenIDs="w470 w471 w472 w473 w474 w475 w476 w477 w478 w479 w47a w47b w47c w47d w47e w47f w480 w481 w482 w483 w484 w485 w486 w487" ID="s36"/>
      <tc:sentence tokenIDs="w488 w489 w48a w48b w48c w48d w48e w48f w490 w491 w492 w493" ID="s37"/>
      <tc:sentence tokenIDs="w494 w495 w496 w497 w498 w499 w49a w49b w49c w49d w49e w49f w4a0 w4a1 w4a2 w4a3 w4a4 w4a5 w4a6 w4a7 w4a8 w4a9 w4aa w4ab w4ac w4ad w4ae w4af w4b0 w4b1 w4b2 w4b3 w4b4 w4b5 w4b6 w4b7 w4b8 w4b9 w4ba w4bb w4bc w4bd w4be w4bf w4c0 w4c1 w4c2 w4c3 w4c4" ID="s38"/>
      <tc:sentence tokenIDs="w4c5 w4c6 w4c7 w4c8 w4c9 w4ca w4cb w4cc w4cd w4ce w4cf w4d0 w4d1 w4d2 w4d3 w4d4 w4d5 w4d6 w4d7 w4d8 w4d9 w4da w4db w4dc w4dd w4de w4df w4e0 w4e1 w4e2" ID="s39"/>
      <tc:sentence tokenIDs="w4e3 w4e4 w4e5 w4e6 w4e7 w4e8 w4e9 w4ea w4eb w4ec w4ed w4ee w4ef w4f0 w4f1 w4f2 w4f3 w4f4 w4f5 w4f6 w4f7 w4f8 w4f9 w4fa w4fb w4fc w4fd w4fe w4ff w500 w501 w502 w503 w504 w505 w506 w507 w508 w509 w50a w50b" ID="s3a"/>
      <tc:sentence tokenIDs="w50c w50d w50e w50f w510 w511 w512 w513 w514 w515 w516 w517 w518 w519 w51a w51b w51c w51d w51e w51f w520 w521" ID="s3b"/>
      <tc:sentence tokenIDs="w522 w523 w524 w525 w526 w527 w528 w529 w52a w52b w52c w52d w52e w52f w530 w531 w532 w533 w534 w535 w536 w537 w538 w539 w53a w53b w53c w53d w53e w53f w540 w541 w542 w543 w544 w545 w546 w547 w548 w549 w54a w54b w54c" ID="s3c"/>
      <tc:sentence tokenIDs="w54d w54e w54f w550 w551 w552 w553 w554 w555 w556 w557 w558 w559 w55a w55b w55c w55d w55e w55f w560 w561 w562 w563 w564 w565 w566 w567 w568 w569" ID="s3d"/>
      <tc:sentence tokenIDs="w56a w56b w56c w56d w56e w56f w570 w571 w572 w573 w574 w575 w576 w577 w578 w579" ID="s3e"/>
      <tc:sentence tokenIDs="w57a w57b w57c w57d w57e w57f w580 w581 w582 w583 w584 w585 w586 w587 w588 w589 w58a w58b w58c w58d w58e w58f w590 w591 w592 w593 w594 w595 w596 w597 w598 w599 w59a w59b w59c w59d w59e w59f w5a0 w5a1 w5a2 w5a3 w5a4 w5a5 w5a6 w5a7 w5a8 w5a9 w5aa" ID="s3f"/>
      <tc:sentence tokenIDs="w5ab w5ac w5ad w5ae w5af w5b0 w5b1 w5b2 w5b3 w5b4" ID="s40"/>
      <tc:sentence tokenIDs="w5b5 w5b6 w5b7 w5b8 w5b9 w5ba w5bb w5bc w5bd w5be w5bf w5c0 w5c1 w5c2 w5c3" ID="s41"/>
      <tc:sentence tokenIDs="w5c4 w5c5 w5c6 w5c7 w5c8 w5c9 w5ca w5cb w5cc w5cd w5ce w5cf w5d0" ID="s42"/>
      <tc:sentence tokenIDs="w5d1 w5d2 w5d3 w5d4 w5d5 w5d6 w5d7 w5d8 w5d9 w5da w5db w5dc w5dd w5de w5df w5e0 w5e1 w5e2 w5e3 w5e4 w5e5" ID="s43"/>
      <tc:sentence tokenIDs="w5e6 w5e7 w5e8 w5e9 w5ea w5eb w5ec w5ed" ID="s44"/>
      <tc:sentence tokenIDs="w5ee w5ef w5f0 w5f1 w5f2 w5f3 w5f4 w5f5 w5f6 w5f7 w5f8 w5f9 w5fa w5fb w5fc w5fd w5fe w5ff w600 w601 w602 w603 w604" ID="s45"/>
      <tc:sentence tokenIDs="w605 w606 w607 w608 w609 w60a w60b" ID="s46"/>
      <tc:sentence tokenIDs="w60c w60d w60e w60f w610 w611 w612 w613 w614 w615 w616 w617 w618 w619 w61a w61b w61c w61d w61e w61f w620 w621 w622 w623 w624 w625 w626 w627 w628 w629 w62a" ID="s47"/>
      <tc:sentence tokenIDs="w62b w62c w62d w62e w62f w630 w631 w632 w633 w634 w635 w636" ID="s48"/>
      <tc:sentence tokenIDs="w637 w638 w639 w63a w63b w63c w63d w63e w63f w640 w641 w642 w643 w644 w645 w646 w647 w648 w649 w64a w64b w64c w64d w64e w64f w650 w651 w652 w653 w654 w655 w656 w657 w658 w659 w65a w65b w65c w65d w65e w65f w660 w661 w662 w663 w664" ID="s49"/>
      <tc:sentence tokenIDs="w665 w666 w667 w668 w669 w66a w66b w66c w66d w66e w66f w670 w671 w672 w673 w674 w675 w676 w677 w678 w679 w67a w67b w67c w67d w67e w67f w680 w681" ID="s4a"/>
      <tc:sentence tokenIDs="w682 w683 w684 w685 w686 w687" ID="s4b"/>
      <tc:sentence tokenIDs="w688" ID="s4c"/>
    </tc:sentences>
    <tc:namedEntities xmlns:tc="http://www.dspin.de/data/textcorpus" type="tuebadz8">
      <tc:entity class="ORG" tokenIDs="w28 w29 w2a w2b"/>
      <tc:entity class="ORG" tokenIDs="w2e"/>
      <tc:entity class="ORG" tokenIDs="w36 w37"/>
      <tc:entity class="PER" tokenIDs="wd6"/>
      <tc:entity class="OTH" tokenIDs="w1d0 w1d1 w1d2 w1d3"/>
      <tc:entity class="OTH" tokenIDs="w259 w25a w25b"/>
      <tc:entity class="PER" tokenIDs="w25e"/>
      <tc:entity class="PER" tokenIDs="w279"/>
      <tc:entity class="PER" tokenIDs="w27b"/>
      <tc:entity class="PER" tokenIDs="w27e"/>
      <tc:entity class="OTH" tokenIDs="w2b8 w2b9"/>
      <tc:entity class="ORG" tokenIDs="w4e7 w4e8"/>
      <tc:entity class="PER" tokenIDs="w558"/>
      <tc:entity class="PER" tokenIDs="w55a w55b"/>
      <tc:entity class="PER" tokenIDs="w55d"/>
      <tc:entity class="PER" tokenIDs="w55f w560"/>
      <tc:entity class="PER" tokenIDs="w562"/>
      <tc:entity class="PER" tokenIDs="w564 w565"/>
      <tc:entity class="OTH" tokenIDs="w56b w56c w56d"/>
      <tc:entity class="ORG" tokenIDs="w572 w573 w574 w575 w576"/>
      <tc:entity class="PER" tokenIDs="w57a"/>
      <tc:entity class="PER" tokenIDs="w57c"/>
      <tc:entity class="PER" tokenIDs="w57e"/>
      <tc:entity class="PER" tokenIDs="w580"/>
      <tc:entity class="PER" tokenIDs="w582"/>
      <tc:entity class="PER" tokenIDs="w584"/>
      <tc:entity class="PER" tokenIDs="w586"/>
      <tc:entity class="PER" tokenIDs="w588"/>
      <tc:entity class="OTH" tokenIDs="w59c w59d w59e w59f w5a0 w5a1 w5a2 w5a3 w5a4 w5a5 w5a6"/>
      <tc:entity class="ORG" tokenIDs="w5a8 w5a9"/>
      <tc:entity class="GPE" tokenIDs="w5ab w5ac"/>
      <tc:entity class="GPE" tokenIDs="w5ae"/>
      <tc:entity class="GPE" tokenIDs="w5b0"/>
      <tc:entity class="ORG" tokenIDs="w5b2"/>
      <tc:entity class="PER" tokenIDs="w5b5"/>
      <tc:entity class="PER" tokenIDs="w5b7"/>
      <tc:entity class="PER" tokenIDs="w5b9"/>
      <tc:entity class="PER" tokenIDs="w5bb"/>
      <tc:entity class="PER" tokenIDs="w5bd"/>
      <tc:entity class="PER" tokenIDs="w5bf"/>
      <tc:entity class="OTH" tokenIDs="w5d1 w5d2 w5d3 w5d4 w5d5 w5d6 w5d7 w5d8 w5d9 w5da"/>
      <tc:entity class="LOC" tokenIDs="w5df"/>
      <tc:entity class="PER" tokenIDs="w5e6"/>
      <tc:entity class="PER" tokenIDs="w5e8 w5e9"/>
      <tc:entity class="OTH" tokenIDs="w5fd w5fe"/>
      <tc:entity class="PER" tokenIDs="w607"/>
      <tc:entity class="OTH" tokenIDs="w60d w60e w60f w610 w611 w612 w613 w614 w615"/>
      <tc:entity class="OTH" tokenIDs="w61a w61b w61c w61d w61e"/>
      <tc:entity class="PER" tokenIDs="w62b"/>
      <tc:entity class="PER" tokenIDs="w62d w62e"/>
      <tc:entity class="PER" tokenIDs="w630"/>
      <tc:entity class="PER" tokenIDs="w632"/>
      <tc:entity class="ORG" tokenIDs="w644 w645 w646 w647 w648 w649 w64a w64b w64c w64d"/>
      <tc:entity class="PER" tokenIDs="w654"/>
      <tc:entity class="PER" tokenIDs="w656"/>
      <tc:entity class="PER" tokenIDs="w659"/>
      <tc:entity class="PER" tokenIDs="w65b w65c"/>
      <tc:entity class="PER" tokenIDs="w65e"/>
      <tc:entity class="PER" tokenIDs="w660"/>
      <tc:entity class="OTH" tokenIDs="w66f w670 w671 w672 w673 w674 w675 w676 w677 w678 w679 w67a w67b w67c w67d w67e w67f w680"/>
      <tc:entity class="ORG" tokenIDs="w682 w683 w684 w685"/>
    </tc:namedEntities>
  </TextCorpus>
</D-Spin>