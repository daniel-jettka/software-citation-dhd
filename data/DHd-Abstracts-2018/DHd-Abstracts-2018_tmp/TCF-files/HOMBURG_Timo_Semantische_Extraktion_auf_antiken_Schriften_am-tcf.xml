<?xml version='1.0' encoding='UTF-8'?><D-Spin xmlns="http://www.dspin.de/data" version="5">
  <MetaData xmlns="http://www.dspin.de/data/metadata"><Services><cmd:CMD xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:cmd="http://www.clarin.eu/cmd/1" CMDVersion="1.2" xsi:schemaLocation="http://www.clarin.eu/cmd/1 http://catalog.clarin.eu/ds/ComponentRegistry/rest/registry/profiles/clarin.eu:cr1:p_1320657629623/xsd"><cmd:Resources><cmd:ResourceProxyList/><cmd:JournalFileProxyList/><cmd:ResourceRelationList/></cmd:Resources><cmd:Components><cmd:WebServiceToolChain><cmd:GeneralInfo><cmd:Descriptions><cmd:Description/></cmd:Descriptions><cmd:ResourceName>Custom chain</cmd:ResourceName><cmd:ResourceClass>Toolchain</cmd:ResourceClass></cmd:GeneralInfo><cmd:Toolchain><cmd:ToolInChain><cmd:PID>https://hdl.handle.net/21.11120/0000-0008-319A-3</cmd:PID><cmd:Parameter value="de" name="lang"/></cmd:ToolInChain><cmd:ToolInChain><cmd:PID>https://hdl.handle.net/21.11120/0000-0008-3183-C</cmd:PID><cmd:Parameter value="5" name="version"/></cmd:ToolInChain><cmd:ToolInChain><cmd:PID>http://hdl.handle.net/11022/0000-0007-DA29-6</cmd:PID><cmd:Parameter value="de" name="lang"/><cmd:Parameter value="5" name="version"/></cmd:ToolInChain></cmd:Toolchain></cmd:WebServiceToolChain></cmd:Components></cmd:CMD></Services></MetaData>
  <TextCorpus xmlns="http://www.dspin.de/data/textcorpus" lang="de">
    <textSource type="application/tei+xml;format-variant=tei-dta;tokenized=0">&lt;?xml version="1.0" encoding="UTF-8"?>
&lt;TEI xmlns="http://www.tei-c.org/ns/1.0"
     xml:id="HOMBURG_Timo_Semantische_Extraktion_auf_antiken_Schriften_am">
&lt;teiHeader>
&lt;fileDesc>
&lt;titleStmt>
&lt;title>Semantische Extraktion auf antiken Schriften am Beispiel von Keilschriftsprachen mithilfe semantischer Wörterbücher&lt;/title>
&lt;author>
&lt;persName>
&lt;surname>Homburg&lt;/surname>
&lt;forename>Timo&lt;/forename>
&lt;/persName>
&lt;affiliation>Hochschule Mainz, Deutschland&lt;/affiliation>
&lt;email>timo.homburg@gmx.de&lt;/email>
&lt;/author>
&lt;/titleStmt>
&lt;editionStmt>
&lt;edition>
&lt;date>2017-09-25T19:00:00Z&lt;/date>
&lt;/edition>
&lt;/editionStmt>
&lt;publicationStmt>
&lt;t:publisher xmlns:t="http://www.tei-c.org/ns/1.0">Georg Vogeler, im Auftrag des Verbands Digital Humanities im deutschaprachigen Raum e.V.&lt;/t:publisher>
&lt;t:address xmlns:t="http://www.tei-c.org/ns/1.0">
&lt;t:addrLine>Universität Graz&lt;/t:addrLine>
&lt;t:addrLine>Zentrum für Informationsmodellierung - Austrian Centre for Digital Humanities&lt;/t:addrLine>
&lt;t:addrLine>Elisabethstraße 59/III&lt;/t:addrLine>
&lt;t:addrLine>8010 Graz&lt;/t:addrLine>
&lt;/t:address>
&lt;/publicationStmt>
&lt;sourceDesc>
&lt;p>Converted from a Word document &lt;/p>
&lt;/sourceDesc>
&lt;/fileDesc>
&lt;encodingDesc>
&lt;appInfo>
&lt;application ident="DHCONVALIDATOR" version="1.17">
&lt;label>DHConvalidator&lt;/label>
&lt;/application>
&lt;/appInfo>
&lt;/encodingDesc>
&lt;profileDesc>
&lt;textClass>
&lt;keywords scheme="ConfTool" n="category">
&lt;term>Paper&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="subcategory">
&lt;term>Poster&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="keywords">
&lt;term>Keilschrift&lt;/term>
&lt;term>Semantik&lt;/term>
&lt;term>Wörterbuch&lt;/term>
&lt;term>Ontologie&lt;/term>
&lt;term>GIS&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="topics">
&lt;term>Datenerkennung&lt;/term>
&lt;term>Programmierung&lt;/term>
&lt;term>Inhaltsanalyse&lt;/term>
&lt;term>Modellierung&lt;/term>
&lt;term>Artefakte&lt;/term>
&lt;term>Text&lt;/term>
&lt;/keywords>
&lt;/textClass>
&lt;settingDesc>
&lt;ab n="conference">DHd2018 - "Kritik der Digitalen Vernunft", Köln&lt;/ab>
&lt;ab n="paperID">265&lt;/ab>
&lt;ab n="session_ID">60&lt;/ab>
&lt;ab n="session_numberInSession">10&lt;/ab&gt;
&lt;ab n="session_short">Poster_1&lt;/ab>
&lt;ab n="session_title">Postersession&lt;/ab>
&lt;ab n="session_start">2018-03-01 17:45&lt;/ab>
&lt;ab n="session_end">2018-03-01 23:00&lt;/ab>
&lt;/settingDesc>
&lt;/profileDesc>
&lt;/teiHeader>
&lt;text>
&lt;body>
&lt;div/>
&lt;div type="div1" rend="DH-Heading1">
&lt;head>Einleitung und Motivation&lt;/head>
&lt;p>Semantische Extraktionsmechanismen (z.B. Topic Modelling) werden seit vielen Jahren im Bereich des Semantic Web und Natural Language Processings sowie in den Digital Humanities als Verfahren zur Visualisierung und automatischen Kategorisierung von Dokumenten eingesetzt. Oft ergeben sich durch den Einsatz neue Aspekte der Interpretation von Dokumentensammlungen die vorher noch nicht ersichtlich waren. Als Beispiele solcher Verfahren kommen häufig Machine Learning Algorithmen zum Einsatz, welche eine Grobeinordnung von Texten vornehmen können. Gepaart mit Metadaten von Texten können anschließend beispielsweise thematische Übersichten von Dokumenten mit geographischem Bezug auf Kartenmaterialien in GIS Systemen oder mittels historischer Gazetteers zeitliche Zusammenhänge automatisiert dargestellt werden. In dieser Publikation möchten wir die Möglichkeiten der semantischen Extraktion nutzen und diese auf einer Sammlung von Texten in Keilschriftsprachen anwenden.&lt;/p>
&lt;/div>
&lt;div type="div1" rend="DH-Heading1">
&lt;head>Keilschriftsprachen&lt;/head>
&lt;p>Keilschriftsprachen haben in den letzten Jahren ein größeres Interesse in der Digital Humanities und Linguistik Community erfahren. (Inglese 2015, Homburg et. al. 2016, Homburg 2017, Sukhareva et. al. 2017). Neben der andauernden Standardisierung in Unicode werden unter anderem Part Of Speech Tagger und Mechanismen der automatisierten Übersetzung erprobt um Keilschrifttexte besser mit dem Computer zu erfassen und zu interpretieren. Desweiteren wurde die Erlernbarkeit der Keilschriftsprachen durch digitale Tools wie Eingabemethoden oder Karteikartenlernprogramme verbessert. (Homburg 2015) Trotz all der erreichten Fortschritte verbleiben jedoch zahlreiche Probleme bei der maschinellen Verarbeitung von Keilschriftsprachen, die unter anderem mit der geringen Verfügbarkeit annotierter Ressourcen und der fehlenden Verfügbarkeit maschinenlesbarer und semantisch sowie linguistisch annotierter Wörterbücher zusammenhängt. Diese Limitierungen hindern viele Natural Language Processing und semantische Extraktionsalgorithmen daran ein besseres Ergebnis zu erzielen. Wir möchten mit dieser Publikation einen Beitrag leisten diese Situation zu verbessern und stellen das "Semantic Dictionary for Ancient Languages" vor, welches ein Versuch ist durch Annotierung vorhandener in der Forschungscommunity anerkannter Wörterbuchressourcen mit Unicode Characters, Semantic Web Konzepten, etymologischen Daten, gemeinsamen Vokabularen und POSTags eine semantische Ressource in RDF für die Optimierung solcher Algorithmen auf Basis der Sprachen Hethitisch, Sumerisch und Akkadisch zu schaffen.Das Wörterbuch basiert auf dem Lemon-Standard, ein W3C Standard der es erlaubt ebenfalls multilinguale Resourcen abzubilden. So können Entwicklungen der Sprache und gemeinsame Vokabulare wie zum Beispiel Akkadogramme und Sumerogramme in Hethitisch mit erfasst werden.&lt;/p>
&lt;/div>
&lt;div type="div1" rend="DH-Heading1">
&lt;head>Semantisches Wörterbuch und Semantische Extraktion&lt;/head>
&lt;p>Wir testen die Performance des Wörterbuchs auf einer der größten Sammlungen von digitalen Keilschrifttexten, der CDLI, aus der wir repräsentative Texte in hethitischer, sumerischer und akkadischer Keilschrift aus verschiedenen Epochen extrahieren und mittels Machine Learning klassifizieren, sowie verschlagworten. Das Ergebnis der semantischen Extraktion ist eine Sammlung von Themen pro Keilschrifttafel, die sich wiederum in Überkategorien gruppieren lassen und in einen zeitlichen, sprachlichen, dialektischen, sowie örtlichen Kontext gestellt werden können. Anhand der verschiedenen Metadaten der CDLI war es uns möglich eine thematische Karte der Fundorte der Keilschrifttafeln sowie deren Inhalt pro Epoche darzustellen aus der das relevante Fachpublikum schließen kann welche Themen zu welcher Zeit an welchem Fundort relevant für die Schreiber der jeweiligen Epoche waren. Im Zuge einer Weiterentwicklung möchten wir diese Informationen mit weiteren Metadaten wie beispielsweise der Jurisdiktion, den Daten der jeweiligen Herrscher sowie rekonstruierten Orten aus der antiken Zeit vervollständigen um Rückschlüsse auf interessante historische Ereignisse zu ziehen.&lt;/p>
&lt;/div>
&lt;div type="div1" rend="DH-Heading1">
&lt;head>Aufbau des Posters&lt;/head>
&lt;p>Auf unserem Poster möchten wir gerne den Prozess des Aufbaus, sowie die Struktur des semantischen Wörterbuchs sowie die Karte die durch unsere semantische Extraktion entstanden ist präsentieren um die jeweiligen Fachwissenschaftler zur Diskussion über die Entwicklung eines Semantic Web von Keilschriftsprachen und Keilschriftartefakten einzuladen. Desweiteren soll unser Poster eine Reihe von Anwendungen demonstrieren die sich in Zukunft mit unserer semantischen Ressource entwickeln lassen können um einen Beitrag zu einem hoffentlich zukünftig existierenden LinkedData Datensatz für Keilschriftartefakte zur Dokumentation von Keilschrift zu leisten.&lt;/p>
&lt;/div>
&lt;/body>
&lt;back>
&lt;div type="bibliogr">
&lt;listBibl>
&lt;head>Bibliographie&lt;/head>
&lt;bibl>
&lt;hi rend="bold">Inglese, G.&lt;/hi> (2015): “Towards a hittite treebank. basic challenges and methodological remarks.” In: Corpus-Based Research in the Humanities (CRH) p. 59 1.1
                    &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Homburg, T.&lt;/hi> (2017): “Postagging and semantic dictionary creation for Hittite cuneiform.” In:DH2017 (2017)
                    &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Homburg, T., Chiarcos, C.&lt;/hi> (2016): “Word segmentation for Akkadian cuneiform.” In: LREC2016 1.1
                    &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Homburg, T., Chiarcos, C., Richter T., Wicke, D.&lt;/hi> (2015): “Learning Cuneiform the Modern Way.” In: DhD2015 
                    &lt;/bibl>
&lt;bibl>
&lt;hi rend="bold">Sukhareva, M., Fuscagni, F., Daxenberger, J., Görke, S., Prechel, D., Gurevych,I.&lt;/hi> (Aug 2017): “Distantly supervised pos tagging of low-resource languages under extreme data sparsity: The case of Hittite.” In: LaTeCH-CLfL ’17 Proceedings of the 11th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities. pp.95–104 1.1
                    &lt;/bibl>
&lt;/listBibl>
&lt;/div>
&lt;/back>
&lt;/text>
&lt;/TEI>
    </textSource>
    <text>


Semantische Extraktionsmechanismen (z.B. Topic Modelling) werden seit vielen Jahren im Bereich des Semantic Web und Natural Language Processings sowie in den Digital Humanities als Verfahren zur Visualisierung und automatischen Kategorisierung von Dokumenten eingesetzt. Oft ergeben sich durch den Einsatz neue Aspekte der Interpretation von Dokumentensammlungen die vorher noch nicht ersichtlich waren. Als Beispiele solcher Verfahren kommen häufig Machine Learning Algorithmen zum Einsatz, welche eine Grobeinordnung von Texten vornehmen können. Gepaart mit Metadaten von Texten können anschließend beispielsweise thematische Übersichten von Dokumenten mit geographischem Bezug auf Kartenmaterialien in GIS Systemen oder mittels historischer Gazetteers zeitliche Zusammenhänge automatisiert dargestellt werden. In dieser Publikation möchten wir die Möglichkeiten der semantischen Extraktion nutzen und diese auf einer Sammlung von Texten in Keilschriftsprachen anwenden.

  


Keilschriftsprachen haben in den letzten Jahren ein größeres Interesse in der Digital Humanities und Linguistik Community erfahren. (Inglese 2015, Homburg et. al. 2016, Homburg 2017, Sukhareva et. al. 2017). Neben der andauernden Standardisierung in Unicode werden unter anderem Part Of Speech Tagger und Mechanismen der automatisierten Übersetzung erprobt um Keilschrifttexte besser mit dem Computer zu erfassen und zu interpretieren. Desweiteren wurde die Erlernbarkeit der Keilschriftsprachen durch digitale Tools wie Eingabemethoden oder Karteikartenlernprogramme verbessert. (Homburg 2015) Trotz all der erreichten Fortschritte verbleiben jedoch zahlreiche Probleme bei der maschinellen Verarbeitung von Keilschriftsprachen, die unter anderem mit der geringen Verfügbarkeit annotierter Ressourcen und der fehlenden Verfügbarkeit maschinenlesbarer und semantisch sowie linguistisch annotierter Wörterbücher zusammenhängt. Diese Limitierungen hindern viele Natural Language Processing und semantische Extraktionsalgorithmen daran ein besseres Ergebnis zu erzielen. Wir möchten mit dieser Publikation einen Beitrag leisten diese Situation zu verbessern und stellen das "Semantic Dictionary for Ancient Languages" vor, welches ein Versuch ist durch Annotierung vorhandener in der Forschungscommunity anerkannter Wörterbuchressourcen mit Unicode Characters, Semantic Web Konzepten, etymologischen Daten, gemeinsamen Vokabularen und POSTags eine semantische Ressource in RDF für die Optimierung solcher Algorithmen auf Basis der Sprachen Hethitisch, Sumerisch und Akkadisch zu schaffen.Das Wörterbuch basiert auf dem Lemon-Standard, ein W3C Standard der es erlaubt ebenfalls multilinguale Resourcen abzubilden. So können Entwicklungen der Sprache und gemeinsame Vokabulare wie zum Beispiel Akkadogramme und Sumerogramme in Hethitisch mit erfasst werden.

  


Wir testen die Performance des Wörterbuchs auf einer der größten Sammlungen von digitalen Keilschrifttexten, der CDLI, aus der wir repräsentative Texte in hethitischer, sumerischer und akkadischer Keilschrift aus verschiedenen Epochen extrahieren und mittels Machine Learning klassifizieren, sowie verschlagworten. Das Ergebnis der semantischen Extraktion ist eine Sammlung von Themen pro Keilschrifttafel, die sich wiederum in Überkategorien gruppieren lassen und in einen zeitlichen, sprachlichen, dialektischen, sowie örtlichen Kontext gestellt werden können. Anhand der verschiedenen Metadaten der CDLI war es uns möglich eine thematische Karte der Fundorte der Keilschrifttafeln sowie deren Inhalt pro Epoche darzustellen aus der das relevante Fachpublikum schließen kann welche Themen zu welcher Zeit an welchem Fundort relevant für die Schreiber der jeweiligen Epoche waren. Im Zuge einer Weiterentwicklung möchten wir diese Informationen mit weiteren Metadaten wie beispielsweise der Jurisdiktion, den Daten der jeweiligen Herrscher sowie rekonstruierten Orten aus der antiken Zeit vervollständigen um Rückschlüsse auf interessante historische Ereignisse zu ziehen.

  


Auf unserem Poster möchten wir gerne den Prozess des Aufbaus, sowie die Struktur des semantischen Wörterbuchs sowie die Karte die durch unsere semantische Extraktion entstanden ist präsentieren um die jeweiligen Fachwissenschaftler zur Diskussion über die Entwicklung eines Semantic Web von Keilschriftsprachen und Keilschriftartefakten einzuladen. Desweiteren soll unser Poster eine Reihe von Anwendungen demonstrieren die sich in Zukunft mit unserer semantischen Ressource entwickeln lassen können um einen Beitrag zu einem hoffentlich zukünftig existierenden LinkedData Datensatz für Keilschriftartefakte zur Dokumentation von Keilschrift zu leisten.




Einleitung und Motivation



Keilschriftsprachen



Semantisches Wörterbuch und Semantische Extraktion



Aufbau des Posters



  

        Inglese, G. (2015): “Towards a hittite treebank. basic challenges and methodological remarks.” In: Corpus-Based Research in the Humanities (CRH) p. 59 1.1      Homburg, T. (2017): “Postagging and semantic dictionary creation for Hittite cuneiform.” In:DH2017 (2017)      Homburg, T., Chiarcos, C. (2016): “Word segmentation for Akkadian cuneiform.” In: LREC2016 1.1      Homburg, T., Chiarcos, C., Richter T., Wicke, D. (2015): “Learning Cuneiform the Modern Way.” In: DhD2015       Sukhareva, M., Fuscagni, F., Daxenberger, J., Görke, S., Prechel, D., Gurevych,I. (Aug 2017): “Distantly supervised pos tagging of low-resource languages under extreme data sparsity: The case of Hittite.” In: LaTeCH-CLfL ’17 Proceedings of the 11th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities. pp.95–104 1.1      

  



Bibliographie
    </text>
    <tc:tokens xmlns:tc="http://www.dspin.de/data/textcorpus">
      <tc:token ID="w1">Semantische</tc:token>
      <tc:token ID="w2">Extraktionsmechanismen</tc:token>
      <tc:token ID="w3">(</tc:token>
      <tc:token ID="w4">z.B.</tc:token>
      <tc:token ID="w5">Topic</tc:token>
      <tc:token ID="w6">Modelling</tc:token>
      <tc:token ID="w7">)</tc:token>
      <tc:token ID="w8">werden</tc:token>
      <tc:token ID="w9">seit</tc:token>
      <tc:token ID="wa">vielen</tc:token>
      <tc:token ID="wb">Jahren</tc:token>
      <tc:token ID="wc">im</tc:token>
      <tc:token ID="wd">Bereich</tc:token>
      <tc:token ID="we">des</tc:token>
      <tc:token ID="wf">Semantic</tc:token>
      <tc:token ID="w10">Web</tc:token>
      <tc:token ID="w11">und</tc:token>
      <tc:token ID="w12">Natural</tc:token>
      <tc:token ID="w13">Language</tc:token>
      <tc:token ID="w14">Processings</tc:token>
      <tc:token ID="w15">sowie</tc:token>
      <tc:token ID="w16">in</tc:token>
      <tc:token ID="w17">den</tc:token>
      <tc:token ID="w18">Digital</tc:token>
      <tc:token ID="w19">Humanities</tc:token>
      <tc:token ID="w1a">als</tc:token>
      <tc:token ID="w1b">Verfahren</tc:token>
      <tc:token ID="w1c">zur</tc:token>
      <tc:token ID="w1d">Visualisierung</tc:token>
      <tc:token ID="w1e">und</tc:token>
      <tc:token ID="w1f">automatischen</tc:token>
      <tc:token ID="w20">Kategorisierung</tc:token>
      <tc:token ID="w21">von</tc:token>
      <tc:token ID="w22">Dokumenten</tc:token>
      <tc:token ID="w23">eingesetzt</tc:token>
      <tc:token ID="w24">.</tc:token>
      <tc:token ID="w25">Oft</tc:token>
      <tc:token ID="w26">ergeben</tc:token>
      <tc:token ID="w27">sich</tc:token>
      <tc:token ID="w28">durch</tc:token>
      <tc:token ID="w29">den</tc:token>
      <tc:token ID="w2a">Einsatz</tc:token>
      <tc:token ID="w2b">neue</tc:token>
      <tc:token ID="w2c">Aspekte</tc:token>
      <tc:token ID="w2d">der</tc:token>
      <tc:token ID="w2e">Interpretation</tc:token>
      <tc:token ID="w2f">von</tc:token>
      <tc:token ID="w30">Dokumentensammlungen</tc:token>
      <tc:token ID="w31">die</tc:token>
      <tc:token ID="w32">vorher</tc:token>
      <tc:token ID="w33">noch</tc:token>
      <tc:token ID="w34">nicht</tc:token>
      <tc:token ID="w35">ersichtlich</tc:token>
      <tc:token ID="w36">waren</tc:token>
      <tc:token ID="w37">.</tc:token>
      <tc:token ID="w38">Als</tc:token>
      <tc:token ID="w39">Beispiele</tc:token>
      <tc:token ID="w3a">solcher</tc:token>
      <tc:token ID="w3b">Verfahren</tc:token>
      <tc:token ID="w3c">kommen</tc:token>
      <tc:token ID="w3d">häufig</tc:token>
      <tc:token ID="w3e">Machine</tc:token>
      <tc:token ID="w3f">Learning</tc:token>
      <tc:token ID="w40">Algorithmen</tc:token>
      <tc:token ID="w41">zum</tc:token>
      <tc:token ID="w42">Einsatz</tc:token>
      <tc:token ID="w43">,</tc:token>
      <tc:token ID="w44">welche</tc:token>
      <tc:token ID="w45">eine</tc:token>
      <tc:token ID="w46">Grobeinordnung</tc:token>
      <tc:token ID="w47">von</tc:token>
      <tc:token ID="w48">Texten</tc:token>
      <tc:token ID="w49">vornehmen</tc:token>
      <tc:token ID="w4a">können</tc:token>
      <tc:token ID="w4b">.</tc:token>
      <tc:token ID="w4c">Gepaart</tc:token>
      <tc:token ID="w4d">mit</tc:token>
      <tc:token ID="w4e">Metadaten</tc:token>
      <tc:token ID="w4f">von</tc:token>
      <tc:token ID="w50">Texten</tc:token>
      <tc:token ID="w51">können</tc:token>
      <tc:token ID="w52">anschließend</tc:token>
      <tc:token ID="w53">beispielsweise</tc:token>
      <tc:token ID="w54">thematische</tc:token>
      <tc:token ID="w55">Übersichten</tc:token>
      <tc:token ID="w56">von</tc:token>
      <tc:token ID="w57">Dokumenten</tc:token>
      <tc:token ID="w58">mit</tc:token>
      <tc:token ID="w59">geographischem</tc:token>
      <tc:token ID="w5a">Bezug</tc:token>
      <tc:token ID="w5b">auf</tc:token>
      <tc:token ID="w5c">Kartenmaterialien</tc:token>
      <tc:token ID="w5d">in</tc:token>
      <tc:token ID="w5e">GIS</tc:token>
      <tc:token ID="w5f">Systemen</tc:token>
      <tc:token ID="w60">oder</tc:token>
      <tc:token ID="w61">mittels</tc:token>
      <tc:token ID="w62">historischer</tc:token>
      <tc:token ID="w63">Gazetteers</tc:token>
      <tc:token ID="w64">zeitliche</tc:token>
      <tc:token ID="w65">Zusammenhänge</tc:token>
      <tc:token ID="w66">automatisiert</tc:token>
      <tc:token ID="w67">dargestellt</tc:token>
      <tc:token ID="w68">werden</tc:token>
      <tc:token ID="w69">.</tc:token>
      <tc:token ID="w6a">In</tc:token>
      <tc:token ID="w6b">dieser</tc:token>
      <tc:token ID="w6c">Publikation</tc:token>
      <tc:token ID="w6d">möchten</tc:token>
      <tc:token ID="w6e">wir</tc:token>
      <tc:token ID="w6f">die</tc:token>
      <tc:token ID="w70">Möglichkeiten</tc:token>
      <tc:token ID="w71">der</tc:token>
      <tc:token ID="w72">semantischen</tc:token>
      <tc:token ID="w73">Extraktion</tc:token>
      <tc:token ID="w74">nutzen</tc:token>
      <tc:token ID="w75">und</tc:token>
      <tc:token ID="w76">diese</tc:token>
      <tc:token ID="w77">auf</tc:token>
      <tc:token ID="w78">einer</tc:token>
      <tc:token ID="w79">Sammlung</tc:token>
      <tc:token ID="w7a">von</tc:token>
      <tc:token ID="w7b">Texten</tc:token>
      <tc:token ID="w7c">in</tc:token>
      <tc:token ID="w7d">Keilschriftsprachen</tc:token>
      <tc:token ID="w7e">anwenden</tc:token>
      <tc:token ID="w7f">.</tc:token>
      <tc:token ID="w80">Keilschriftsprachen</tc:token>
      <tc:token ID="w81">haben</tc:token>
      <tc:token ID="w82">in</tc:token>
      <tc:token ID="w83">den</tc:token>
      <tc:token ID="w84">letzten</tc:token>
      <tc:token ID="w85">Jahren</tc:token>
      <tc:token ID="w86">ein</tc:token>
      <tc:token ID="w87">größeres</tc:token>
      <tc:token ID="w88">Interesse</tc:token>
      <tc:token ID="w89">in</tc:token>
      <tc:token ID="w8a">der</tc:token>
      <tc:token ID="w8b">Digital</tc:token>
      <tc:token ID="w8c">Humanities</tc:token>
      <tc:token ID="w8d">und</tc:token>
      <tc:token ID="w8e">Linguistik</tc:token>
      <tc:token ID="w8f">Community</tc:token>
      <tc:token ID="w90">erfahren</tc:token>
      <tc:token ID="w91">.</tc:token>
      <tc:token ID="w92">(</tc:token>
      <tc:token ID="w93">Inglese</tc:token>
      <tc:token ID="w94">2015</tc:token>
      <tc:token ID="w95">,</tc:token>
      <tc:token ID="w96">Homburg</tc:token>
      <tc:token ID="w97">et.</tc:token>
      <tc:token ID="w98">al.</tc:token>
      <tc:token ID="w99">2016</tc:token>
      <tc:token ID="w9a">,</tc:token>
      <tc:token ID="w9b">Homburg</tc:token>
      <tc:token ID="w9c">2017</tc:token>
      <tc:token ID="w9d">,</tc:token>
      <tc:token ID="w9e">Sukhareva</tc:token>
      <tc:token ID="w9f">et.</tc:token>
      <tc:token ID="wa0">al.</tc:token>
      <tc:token ID="wa1">2017</tc:token>
      <tc:token ID="wa2">)</tc:token>
      <tc:token ID="wa3">.</tc:token>
      <tc:token ID="wa4">Neben</tc:token>
      <tc:token ID="wa5">der</tc:token>
      <tc:token ID="wa6">andauernden</tc:token>
      <tc:token ID="wa7">Standardisierung</tc:token>
      <tc:token ID="wa8">in</tc:token>
      <tc:token ID="wa9">Unicode</tc:token>
      <tc:token ID="waa">werden</tc:token>
      <tc:token ID="wab">unter</tc:token>
      <tc:token ID="wac">anderem</tc:token>
      <tc:token ID="wad">Part</tc:token>
      <tc:token ID="wae">Of</tc:token>
      <tc:token ID="waf">Speech</tc:token>
      <tc:token ID="wb0">Tagger</tc:token>
      <tc:token ID="wb1">und</tc:token>
      <tc:token ID="wb2">Mechanismen</tc:token>
      <tc:token ID="wb3">der</tc:token>
      <tc:token ID="wb4">automatisierten</tc:token>
      <tc:token ID="wb5">Übersetzung</tc:token>
      <tc:token ID="wb6">erprobt</tc:token>
      <tc:token ID="wb7">um</tc:token>
      <tc:token ID="wb8">Keilschrifttexte</tc:token>
      <tc:token ID="wb9">besser</tc:token>
      <tc:token ID="wba">mit</tc:token>
      <tc:token ID="wbb">dem</tc:token>
      <tc:token ID="wbc">Computer</tc:token>
      <tc:token ID="wbd">zu</tc:token>
      <tc:token ID="wbe">erfassen</tc:token>
      <tc:token ID="wbf">und</tc:token>
      <tc:token ID="wc0">zu</tc:token>
      <tc:token ID="wc1">interpretieren</tc:token>
      <tc:token ID="wc2">.</tc:token>
      <tc:token ID="wc3">Desweiteren</tc:token>
      <tc:token ID="wc4">wurde</tc:token>
      <tc:token ID="wc5">die</tc:token>
      <tc:token ID="wc6">Erlernbarkeit</tc:token>
      <tc:token ID="wc7">der</tc:token>
      <tc:token ID="wc8">Keilschriftsprachen</tc:token>
      <tc:token ID="wc9">durch</tc:token>
      <tc:token ID="wca">digitale</tc:token>
      <tc:token ID="wcb">Tools</tc:token>
      <tc:token ID="wcc">wie</tc:token>
      <tc:token ID="wcd">Eingabemethoden</tc:token>
      <tc:token ID="wce">oder</tc:token>
      <tc:token ID="wcf">Karteikartenlernprogramme</tc:token>
      <tc:token ID="wd0">verbessert</tc:token>
      <tc:token ID="wd1">.</tc:token>
      <tc:token ID="wd2">(</tc:token>
      <tc:token ID="wd3">Homburg</tc:token>
      <tc:token ID="wd4">2015</tc:token>
      <tc:token ID="wd5">)</tc:token>
      <tc:token ID="wd6">Trotz</tc:token>
      <tc:token ID="wd7">all</tc:token>
      <tc:token ID="wd8">der</tc:token>
      <tc:token ID="wd9">erreichten</tc:token>
      <tc:token ID="wda">Fortschritte</tc:token>
      <tc:token ID="wdb">verbleiben</tc:token>
      <tc:token ID="wdc">jedoch</tc:token>
      <tc:token ID="wdd">zahlreiche</tc:token>
      <tc:token ID="wde">Probleme</tc:token>
      <tc:token ID="wdf">bei</tc:token>
      <tc:token ID="we0">der</tc:token>
      <tc:token ID="we1">maschinellen</tc:token>
      <tc:token ID="we2">Verarbeitung</tc:token>
      <tc:token ID="we3">von</tc:token>
      <tc:token ID="we4">Keilschriftsprachen</tc:token>
      <tc:token ID="we5">,</tc:token>
      <tc:token ID="we6">die</tc:token>
      <tc:token ID="we7">unter</tc:token>
      <tc:token ID="we8">anderem</tc:token>
      <tc:token ID="we9">mit</tc:token>
      <tc:token ID="wea">der</tc:token>
      <tc:token ID="web">geringen</tc:token>
      <tc:token ID="wec">Verfügbarkeit</tc:token>
      <tc:token ID="wed">annotierter</tc:token>
      <tc:token ID="wee">Ressourcen</tc:token>
      <tc:token ID="wef">und</tc:token>
      <tc:token ID="wf0">der</tc:token>
      <tc:token ID="wf1">fehlenden</tc:token>
      <tc:token ID="wf2">Verfügbarkeit</tc:token>
      <tc:token ID="wf3">maschinenlesbarer</tc:token>
      <tc:token ID="wf4">und</tc:token>
      <tc:token ID="wf5">semantisch</tc:token>
      <tc:token ID="wf6">sowie</tc:token>
      <tc:token ID="wf7">linguistisch</tc:token>
      <tc:token ID="wf8">annotierter</tc:token>
      <tc:token ID="wf9">Wörterbücher</tc:token>
      <tc:token ID="wfa">zusammenhängt</tc:token>
      <tc:token ID="wfb">.</tc:token>
      <tc:token ID="wfc">Diese</tc:token>
      <tc:token ID="wfd">Limitierungen</tc:token>
      <tc:token ID="wfe">hindern</tc:token>
      <tc:token ID="wff">viele</tc:token>
      <tc:token ID="w100">Natural</tc:token>
      <tc:token ID="w101">Language</tc:token>
      <tc:token ID="w102">Processing</tc:token>
      <tc:token ID="w103">und</tc:token>
      <tc:token ID="w104">semantische</tc:token>
      <tc:token ID="w105">Extraktionsalgorithmen</tc:token>
      <tc:token ID="w106">daran</tc:token>
      <tc:token ID="w107">ein</tc:token>
      <tc:token ID="w108">besseres</tc:token>
      <tc:token ID="w109">Ergebnis</tc:token>
      <tc:token ID="w10a">zu</tc:token>
      <tc:token ID="w10b">erzielen</tc:token>
      <tc:token ID="w10c">.</tc:token>
      <tc:token ID="w10d">Wir</tc:token>
      <tc:token ID="w10e">möchten</tc:token>
      <tc:token ID="w10f">mit</tc:token>
      <tc:token ID="w110">dieser</tc:token>
      <tc:token ID="w111">Publikation</tc:token>
      <tc:token ID="w112">einen</tc:token>
      <tc:token ID="w113">Beitrag</tc:token>
      <tc:token ID="w114">leisten</tc:token>
      <tc:token ID="w115">diese</tc:token>
      <tc:token ID="w116">Situation</tc:token>
      <tc:token ID="w117">zu</tc:token>
      <tc:token ID="w118">verbessern</tc:token>
      <tc:token ID="w119">und</tc:token>
      <tc:token ID="w11a">stellen</tc:token>
      <tc:token ID="w11b">das</tc:token>
      <tc:token ID="w11c">"</tc:token>
      <tc:token ID="w11d">Semantic</tc:token>
      <tc:token ID="w11e">Dictionary</tc:token>
      <tc:token ID="w11f">for</tc:token>
      <tc:token ID="w120">Ancient</tc:token>
      <tc:token ID="w121">Languages</tc:token>
      <tc:token ID="w122">"</tc:token>
      <tc:token ID="w123">vor</tc:token>
      <tc:token ID="w124">,</tc:token>
      <tc:token ID="w125">welches</tc:token>
      <tc:token ID="w126">ein</tc:token>
      <tc:token ID="w127">Versuch</tc:token>
      <tc:token ID="w128">ist</tc:token>
      <tc:token ID="w129">durch</tc:token>
      <tc:token ID="w12a">Annotierung</tc:token>
      <tc:token ID="w12b">vorhandener</tc:token>
      <tc:token ID="w12c">in</tc:token>
      <tc:token ID="w12d">der</tc:token>
      <tc:token ID="w12e">Forschungscommunity</tc:token>
      <tc:token ID="w12f">anerkannter</tc:token>
      <tc:token ID="w130">Wörterbuchressourcen</tc:token>
      <tc:token ID="w131">mit</tc:token>
      <tc:token ID="w132">Unicode</tc:token>
      <tc:token ID="w133">Characters</tc:token>
      <tc:token ID="w134">,</tc:token>
      <tc:token ID="w135">Semantic</tc:token>
      <tc:token ID="w136">Web</tc:token>
      <tc:token ID="w137">Konzepten</tc:token>
      <tc:token ID="w138">,</tc:token>
      <tc:token ID="w139">etymologischen</tc:token>
      <tc:token ID="w13a">Daten</tc:token>
      <tc:token ID="w13b">,</tc:token>
      <tc:token ID="w13c">gemeinsamen</tc:token>
      <tc:token ID="w13d">Vokabularen</tc:token>
      <tc:token ID="w13e">und</tc:token>
      <tc:token ID="w13f">POSTags</tc:token>
      <tc:token ID="w140">eine</tc:token>
      <tc:token ID="w141">semantische</tc:token>
      <tc:token ID="w142">Ressource</tc:token>
      <tc:token ID="w143">in</tc:token>
      <tc:token ID="w144">RDF</tc:token>
      <tc:token ID="w145">für</tc:token>
      <tc:token ID="w146">die</tc:token>
      <tc:token ID="w147">Optimierung</tc:token>
      <tc:token ID="w148">solcher</tc:token>
      <tc:token ID="w149">Algorithmen</tc:token>
      <tc:token ID="w14a">auf</tc:token>
      <tc:token ID="w14b">Basis</tc:token>
      <tc:token ID="w14c">der</tc:token>
      <tc:token ID="w14d">Sprachen</tc:token>
      <tc:token ID="w14e">Hethitisch</tc:token>
      <tc:token ID="w14f">,</tc:token>
      <tc:token ID="w150">Sumerisch</tc:token>
      <tc:token ID="w151">und</tc:token>
      <tc:token ID="w152">Akkadisch</tc:token>
      <tc:token ID="w153">zu</tc:token>
      <tc:token ID="w154">schaffen</tc:token>
      <tc:token ID="w155">.</tc:token>
      <tc:token ID="w156">Das</tc:token>
      <tc:token ID="w157">Wörterbuch</tc:token>
      <tc:token ID="w158">basiert</tc:token>
      <tc:token ID="w159">auf</tc:token>
      <tc:token ID="w15a">dem</tc:token>
      <tc:token ID="w15b">Lemon-Standard</tc:token>
      <tc:token ID="w15c">,</tc:token>
      <tc:token ID="w15d">ein</tc:token>
      <tc:token ID="w15e">W3C</tc:token>
      <tc:token ID="w15f">Standard</tc:token>
      <tc:token ID="w160">der</tc:token>
      <tc:token ID="w161">es</tc:token>
      <tc:token ID="w162">erlaubt</tc:token>
      <tc:token ID="w163">ebenfalls</tc:token>
      <tc:token ID="w164">multilinguale</tc:token>
      <tc:token ID="w165">Resourcen</tc:token>
      <tc:token ID="w166">abzubilden</tc:token>
      <tc:token ID="w167">.</tc:token>
      <tc:token ID="w168">So</tc:token>
      <tc:token ID="w169">können</tc:token>
      <tc:token ID="w16a">Entwicklungen</tc:token>
      <tc:token ID="w16b">der</tc:token>
      <tc:token ID="w16c">Sprache</tc:token>
      <tc:token ID="w16d">und</tc:token>
      <tc:token ID="w16e">gemeinsame</tc:token>
      <tc:token ID="w16f">Vokabulare</tc:token>
      <tc:token ID="w170">wie</tc:token>
      <tc:token ID="w171">zum</tc:token>
      <tc:token ID="w172">Beispiel</tc:token>
      <tc:token ID="w173">Akkadogramme</tc:token>
      <tc:token ID="w174">und</tc:token>
      <tc:token ID="w175">Sumerogramme</tc:token>
      <tc:token ID="w176">in</tc:token>
      <tc:token ID="w177">Hethitisch</tc:token>
      <tc:token ID="w178">mit</tc:token>
      <tc:token ID="w179">erfasst</tc:token>
      <tc:token ID="w17a">werden</tc:token>
      <tc:token ID="w17b">.</tc:token>
      <tc:token ID="w17c">Wir</tc:token>
      <tc:token ID="w17d">testen</tc:token>
      <tc:token ID="w17e">die</tc:token>
      <tc:token ID="w17f">Performance</tc:token>
      <tc:token ID="w180">des</tc:token>
      <tc:token ID="w181">Wörterbuchs</tc:token>
      <tc:token ID="w182">auf</tc:token>
      <tc:token ID="w183">einer</tc:token>
      <tc:token ID="w184">der</tc:token>
      <tc:token ID="w185">größten</tc:token>
      <tc:token ID="w186">Sammlungen</tc:token>
      <tc:token ID="w187">von</tc:token>
      <tc:token ID="w188">digitalen</tc:token>
      <tc:token ID="w189">Keilschrifttexten</tc:token>
      <tc:token ID="w18a">,</tc:token>
      <tc:token ID="w18b">der</tc:token>
      <tc:token ID="w18c">CDLI</tc:token>
      <tc:token ID="w18d">,</tc:token>
      <tc:token ID="w18e">aus</tc:token>
      <tc:token ID="w18f">der</tc:token>
      <tc:token ID="w190">wir</tc:token>
      <tc:token ID="w191">repräsentative</tc:token>
      <tc:token ID="w192">Texte</tc:token>
      <tc:token ID="w193">in</tc:token>
      <tc:token ID="w194">hethitischer</tc:token>
      <tc:token ID="w195">,</tc:token>
      <tc:token ID="w196">sumerischer</tc:token>
      <tc:token ID="w197">und</tc:token>
      <tc:token ID="w198">akkadischer</tc:token>
      <tc:token ID="w199">Keilschrift</tc:token>
      <tc:token ID="w19a">aus</tc:token>
      <tc:token ID="w19b">verschiedenen</tc:token>
      <tc:token ID="w19c">Epochen</tc:token>
      <tc:token ID="w19d">extrahieren</tc:token>
      <tc:token ID="w19e">und</tc:token>
      <tc:token ID="w19f">mittels</tc:token>
      <tc:token ID="w1a0">Machine</tc:token>
      <tc:token ID="w1a1">Learning</tc:token>
      <tc:token ID="w1a2">klassifizieren</tc:token>
      <tc:token ID="w1a3">,</tc:token>
      <tc:token ID="w1a4">sowie</tc:token>
      <tc:token ID="w1a5">verschlagworten</tc:token>
      <tc:token ID="w1a6">.</tc:token>
      <tc:token ID="w1a7">Das</tc:token>
      <tc:token ID="w1a8">Ergebnis</tc:token>
      <tc:token ID="w1a9">der</tc:token>
      <tc:token ID="w1aa">semantischen</tc:token>
      <tc:token ID="w1ab">Extraktion</tc:token>
      <tc:token ID="w1ac">ist</tc:token>
      <tc:token ID="w1ad">eine</tc:token>
      <tc:token ID="w1ae">Sammlung</tc:token>
      <tc:token ID="w1af">von</tc:token>
      <tc:token ID="w1b0">Themen</tc:token>
      <tc:token ID="w1b1">pro</tc:token>
      <tc:token ID="w1b2">Keilschrifttafel</tc:token>
      <tc:token ID="w1b3">,</tc:token>
      <tc:token ID="w1b4">die</tc:token>
      <tc:token ID="w1b5">sich</tc:token>
      <tc:token ID="w1b6">wiederum</tc:token>
      <tc:token ID="w1b7">in</tc:token>
      <tc:token ID="w1b8">Überkategorien</tc:token>
      <tc:token ID="w1b9">gruppieren</tc:token>
      <tc:token ID="w1ba">lassen</tc:token>
      <tc:token ID="w1bb">und</tc:token>
      <tc:token ID="w1bc">in</tc:token>
      <tc:token ID="w1bd">einen</tc:token>
      <tc:token ID="w1be">zeitlichen</tc:token>
      <tc:token ID="w1bf">,</tc:token>
      <tc:token ID="w1c0">sprachlichen</tc:token>
      <tc:token ID="w1c1">,</tc:token>
      <tc:token ID="w1c2">dialektischen</tc:token>
      <tc:token ID="w1c3">,</tc:token>
      <tc:token ID="w1c4">sowie</tc:token>
      <tc:token ID="w1c5">örtlichen</tc:token>
      <tc:token ID="w1c6">Kontext</tc:token>
      <tc:token ID="w1c7">gestellt</tc:token>
      <tc:token ID="w1c8">werden</tc:token>
      <tc:token ID="w1c9">können</tc:token>
      <tc:token ID="w1ca">.</tc:token>
      <tc:token ID="w1cb">Anhand</tc:token>
      <tc:token ID="w1cc">der</tc:token>
      <tc:token ID="w1cd">verschiedenen</tc:token>
      <tc:token ID="w1ce">Metadaten</tc:token>
      <tc:token ID="w1cf">der</tc:token>
      <tc:token ID="w1d0">CDLI</tc:token>
      <tc:token ID="w1d1">war</tc:token>
      <tc:token ID="w1d2">es</tc:token>
      <tc:token ID="w1d3">uns</tc:token>
      <tc:token ID="w1d4">möglich</tc:token>
      <tc:token ID="w1d5">eine</tc:token>
      <tc:token ID="w1d6">thematische</tc:token>
      <tc:token ID="w1d7">Karte</tc:token>
      <tc:token ID="w1d8">der</tc:token>
      <tc:token ID="w1d9">Fundorte</tc:token>
      <tc:token ID="w1da">der</tc:token>
      <tc:token ID="w1db">Keilschrifttafeln</tc:token>
      <tc:token ID="w1dc">sowie</tc:token>
      <tc:token ID="w1dd">deren</tc:token>
      <tc:token ID="w1de">Inhalt</tc:token>
      <tc:token ID="w1df">pro</tc:token>
      <tc:token ID="w1e0">Epoche</tc:token>
      <tc:token ID="w1e1">darzustellen</tc:token>
      <tc:token ID="w1e2">aus</tc:token>
      <tc:token ID="w1e3">der</tc:token>
      <tc:token ID="w1e4">das</tc:token>
      <tc:token ID="w1e5">relevante</tc:token>
      <tc:token ID="w1e6">Fachpublikum</tc:token>
      <tc:token ID="w1e7">schließen</tc:token>
      <tc:token ID="w1e8">kann</tc:token>
      <tc:token ID="w1e9">welche</tc:token>
      <tc:token ID="w1ea">Themen</tc:token>
      <tc:token ID="w1eb">zu</tc:token>
      <tc:token ID="w1ec">welcher</tc:token>
      <tc:token ID="w1ed">Zeit</tc:token>
      <tc:token ID="w1ee">an</tc:token>
      <tc:token ID="w1ef">welchem</tc:token>
      <tc:token ID="w1f0">Fundort</tc:token>
      <tc:token ID="w1f1">relevant</tc:token>
      <tc:token ID="w1f2">für</tc:token>
      <tc:token ID="w1f3">die</tc:token>
      <tc:token ID="w1f4">Schreiber</tc:token>
      <tc:token ID="w1f5">der</tc:token>
      <tc:token ID="w1f6">jeweiligen</tc:token>
      <tc:token ID="w1f7">Epoche</tc:token>
      <tc:token ID="w1f8">waren</tc:token>
      <tc:token ID="w1f9">.</tc:token>
      <tc:token ID="w1fa">Im</tc:token>
      <tc:token ID="w1fb">Zuge</tc:token>
      <tc:token ID="w1fc">einer</tc:token>
      <tc:token ID="w1fd">Weiterentwicklung</tc:token>
      <tc:token ID="w1fe">möchten</tc:token>
      <tc:token ID="w1ff">wir</tc:token>
      <tc:token ID="w200">diese</tc:token>
      <tc:token ID="w201">Informationen</tc:token>
      <tc:token ID="w202">mit</tc:token>
      <tc:token ID="w203">weiteren</tc:token>
      <tc:token ID="w204">Metadaten</tc:token>
      <tc:token ID="w205">wie</tc:token>
      <tc:token ID="w206">beispielsweise</tc:token>
      <tc:token ID="w207">der</tc:token>
      <tc:token ID="w208">Jurisdiktion</tc:token>
      <tc:token ID="w209">,</tc:token>
      <tc:token ID="w20a">den</tc:token>
      <tc:token ID="w20b">Daten</tc:token>
      <tc:token ID="w20c">der</tc:token>
      <tc:token ID="w20d">jeweiligen</tc:token>
      <tc:token ID="w20e">Herrscher</tc:token>
      <tc:token ID="w20f">sowie</tc:token>
      <tc:token ID="w210">rekonstruierten</tc:token>
      <tc:token ID="w211">Orten</tc:token>
      <tc:token ID="w212">aus</tc:token>
      <tc:token ID="w213">der</tc:token>
      <tc:token ID="w214">antiken</tc:token>
      <tc:token ID="w215">Zeit</tc:token>
      <tc:token ID="w216">vervollständigen</tc:token>
      <tc:token ID="w217">um</tc:token>
      <tc:token ID="w218">Rückschlüsse</tc:token>
      <tc:token ID="w219">auf</tc:token>
      <tc:token ID="w21a">interessante</tc:token>
      <tc:token ID="w21b">historische</tc:token>
      <tc:token ID="w21c">Ereignisse</tc:token>
      <tc:token ID="w21d">zu</tc:token>
      <tc:token ID="w21e">ziehen</tc:token>
      <tc:token ID="w21f">.</tc:token>
      <tc:token ID="w220">Auf</tc:token>
      <tc:token ID="w221">unserem</tc:token>
      <tc:token ID="w222">Poster</tc:token>
      <tc:token ID="w223">möchten</tc:token>
      <tc:token ID="w224">wir</tc:token>
      <tc:token ID="w225">gerne</tc:token>
      <tc:token ID="w226">den</tc:token>
      <tc:token ID="w227">Prozess</tc:token>
      <tc:token ID="w228">des</tc:token>
      <tc:token ID="w229">Aufbaus</tc:token>
      <tc:token ID="w22a">,</tc:token>
      <tc:token ID="w22b">sowie</tc:token>
      <tc:token ID="w22c">die</tc:token>
      <tc:token ID="w22d">Struktur</tc:token>
      <tc:token ID="w22e">des</tc:token>
      <tc:token ID="w22f">semantischen</tc:token>
      <tc:token ID="w230">Wörterbuchs</tc:token>
      <tc:token ID="w231">sowie</tc:token>
      <tc:token ID="w232">die</tc:token>
      <tc:token ID="w233">Karte</tc:token>
      <tc:token ID="w234">die</tc:token>
      <tc:token ID="w235">durch</tc:token>
      <tc:token ID="w236">unsere</tc:token>
      <tc:token ID="w237">semantische</tc:token>
      <tc:token ID="w238">Extraktion</tc:token>
      <tc:token ID="w239">entstanden</tc:token>
      <tc:token ID="w23a">ist</tc:token>
      <tc:token ID="w23b">präsentieren</tc:token>
      <tc:token ID="w23c">um</tc:token>
      <tc:token ID="w23d">die</tc:token>
      <tc:token ID="w23e">jeweiligen</tc:token>
      <tc:token ID="w23f">Fachwissenschaftler</tc:token>
      <tc:token ID="w240">zur</tc:token>
      <tc:token ID="w241">Diskussion</tc:token>
      <tc:token ID="w242">über</tc:token>
      <tc:token ID="w243">die</tc:token>
      <tc:token ID="w244">Entwicklung</tc:token>
      <tc:token ID="w245">eines</tc:token>
      <tc:token ID="w246">Semantic</tc:token>
      <tc:token ID="w247">Web</tc:token>
      <tc:token ID="w248">von</tc:token>
      <tc:token ID="w249">Keilschriftsprachen</tc:token>
      <tc:token ID="w24a">und</tc:token>
      <tc:token ID="w24b">Keilschriftartefakten</tc:token>
      <tc:token ID="w24c">einzuladen</tc:token>
      <tc:token ID="w24d">.</tc:token>
      <tc:token ID="w24e">Desweiteren</tc:token>
      <tc:token ID="w24f">soll</tc:token>
      <tc:token ID="w250">unser</tc:token>
      <tc:token ID="w251">Poster</tc:token>
      <tc:token ID="w252">eine</tc:token>
      <tc:token ID="w253">Reihe</tc:token>
      <tc:token ID="w254">von</tc:token>
      <tc:token ID="w255">Anwendungen</tc:token>
      <tc:token ID="w256">demonstrieren</tc:token>
      <tc:token ID="w257">die</tc:token>
      <tc:token ID="w258">sich</tc:token>
      <tc:token ID="w259">in</tc:token>
      <tc:token ID="w25a">Zukunft</tc:token>
      <tc:token ID="w25b">mit</tc:token>
      <tc:token ID="w25c">unserer</tc:token>
      <tc:token ID="w25d">semantischen</tc:token>
      <tc:token ID="w25e">Ressource</tc:token>
      <tc:token ID="w25f">entwickeln</tc:token>
      <tc:token ID="w260">lassen</tc:token>
      <tc:token ID="w261">können</tc:token>
      <tc:token ID="w262">um</tc:token>
      <tc:token ID="w263">einen</tc:token>
      <tc:token ID="w264">Beitrag</tc:token>
      <tc:token ID="w265">zu</tc:token>
      <tc:token ID="w266">einem</tc:token>
      <tc:token ID="w267">hoffentlich</tc:token>
      <tc:token ID="w268">zukünftig</tc:token>
      <tc:token ID="w269">existierenden</tc:token>
      <tc:token ID="w26a">LinkedData</tc:token>
      <tc:token ID="w26b">Datensatz</tc:token>
      <tc:token ID="w26c">für</tc:token>
      <tc:token ID="w26d">Keilschriftartefakte</tc:token>
      <tc:token ID="w26e">zur</tc:token>
      <tc:token ID="w26f">Dokumentation</tc:token>
      <tc:token ID="w270">von</tc:token>
      <tc:token ID="w271">Keilschrift</tc:token>
      <tc:token ID="w272">zu</tc:token>
      <tc:token ID="w273">leisten</tc:token>
      <tc:token ID="w274">.</tc:token>
      <tc:token ID="w275">Einleitung</tc:token>
      <tc:token ID="w276">und</tc:token>
      <tc:token ID="w277">Motivation</tc:token>
      <tc:token ID="w278">Keilschriftsprachen</tc:token>
      <tc:token ID="w279">Semantisches</tc:token>
      <tc:token ID="w27a">Wörterbuch</tc:token>
      <tc:token ID="w27b">und</tc:token>
      <tc:token ID="w27c">Semantische</tc:token>
      <tc:token ID="w27d">Extraktion</tc:token>
      <tc:token ID="w27e">Aufbau</tc:token>
      <tc:token ID="w27f">des</tc:token>
      <tc:token ID="w280">Posters</tc:token>
      <tc:token ID="w281">Inglese</tc:token>
      <tc:token ID="w282">,</tc:token>
      <tc:token ID="w283">G.</tc:token>
      <tc:token ID="w284">(</tc:token>
      <tc:token ID="w285">2015</tc:token>
      <tc:token ID="w286">)</tc:token>
      <tc:token ID="w287">:</tc:token>
      <tc:token ID="w288">“</tc:token>
      <tc:token ID="w289">Towards</tc:token>
      <tc:token ID="w28a">a</tc:token>
      <tc:token ID="w28b">hittite</tc:token>
      <tc:token ID="w28c">treebank</tc:token>
      <tc:token ID="w28d">.</tc:token>
      <tc:token ID="w28e">basic</tc:token>
      <tc:token ID="w28f">challenges</tc:token>
      <tc:token ID="w290">and</tc:token>
      <tc:token ID="w291">methodological</tc:token>
      <tc:token ID="w292">remarks</tc:token>
      <tc:token ID="w293">.</tc:token>
      <tc:token ID="w294">”</tc:token>
      <tc:token ID="w295">In</tc:token>
      <tc:token ID="w296">:</tc:token>
      <tc:token ID="w297">Corpus-Based</tc:token>
      <tc:token ID="w298">Research</tc:token>
      <tc:token ID="w299">in</tc:token>
      <tc:token ID="w29a">the</tc:token>
      <tc:token ID="w29b">Humanities</tc:token>
      <tc:token ID="w29c">(</tc:token>
      <tc:token ID="w29d">CRH</tc:token>
      <tc:token ID="w29e">)</tc:token>
      <tc:token ID="w29f">p.</tc:token>
      <tc:token ID="w2a0">59</tc:token>
      <tc:token ID="w2a1">1.1</tc:token>
      <tc:token ID="w2a2">Homburg</tc:token>
      <tc:token ID="w2a3">,</tc:token>
      <tc:token ID="w2a4">T.</tc:token>
      <tc:token ID="w2a5">(</tc:token>
      <tc:token ID="w2a6">2017</tc:token>
      <tc:token ID="w2a7">)</tc:token>
      <tc:token ID="w2a8">:</tc:token>
      <tc:token ID="w2a9">“</tc:token>
      <tc:token ID="w2aa">Postagging</tc:token>
      <tc:token ID="w2ab">and</tc:token>
      <tc:token ID="w2ac">semantic</tc:token>
      <tc:token ID="w2ad">dictionary</tc:token>
      <tc:token ID="w2ae">creation</tc:token>
      <tc:token ID="w2af">for</tc:token>
      <tc:token ID="w2b0">Hittite</tc:token>
      <tc:token ID="w2b1">cuneiform</tc:token>
      <tc:token ID="w2b2">.</tc:token>
      <tc:token ID="w2b3">”</tc:token>
      <tc:token ID="w2b4">In</tc:token>
      <tc:token ID="w2b5">:</tc:token>
      <tc:token ID="w2b6">DH2017</tc:token>
      <tc:token ID="w2b7">(</tc:token>
      <tc:token ID="w2b8">2017</tc:token>
      <tc:token ID="w2b9">)</tc:token>
      <tc:token ID="w2ba">Homburg</tc:token>
      <tc:token ID="w2bb">,</tc:token>
      <tc:token ID="w2bc">T.</tc:token>
      <tc:token ID="w2bd">,</tc:token>
      <tc:token ID="w2be">Chiarcos</tc:token>
      <tc:token ID="w2bf">,</tc:token>
      <tc:token ID="w2c0">C.</tc:token>
      <tc:token ID="w2c1">(</tc:token>
      <tc:token ID="w2c2">2016</tc:token>
      <tc:token ID="w2c3">)</tc:token>
      <tc:token ID="w2c4">:</tc:token>
      <tc:token ID="w2c5">“</tc:token>
      <tc:token ID="w2c6">Word</tc:token>
      <tc:token ID="w2c7">segmentation</tc:token>
      <tc:token ID="w2c8">for</tc:token>
      <tc:token ID="w2c9">Akkadian</tc:token>
      <tc:token ID="w2ca">cuneiform</tc:token>
      <tc:token ID="w2cb">.</tc:token>
      <tc:token ID="w2cc">”</tc:token>
      <tc:token ID="w2cd">In</tc:token>
      <tc:token ID="w2ce">:</tc:token>
      <tc:token ID="w2cf">LREC</tc:token>
      <tc:token ID="w2d0">2016</tc:token>
      <tc:token ID="w2d1">1.1</tc:token>
      <tc:token ID="w2d2">Homburg</tc:token>
      <tc:token ID="w2d3">,</tc:token>
      <tc:token ID="w2d4">T.</tc:token>
      <tc:token ID="w2d5">,</tc:token>
      <tc:token ID="w2d6">Chiarcos</tc:token>
      <tc:token ID="w2d7">,</tc:token>
      <tc:token ID="w2d8">C.</tc:token>
      <tc:token ID="w2d9">,</tc:token>
      <tc:token ID="w2da">Richter</tc:token>
      <tc:token ID="w2db">T.</tc:token>
      <tc:token ID="w2dc">,</tc:token>
      <tc:token ID="w2dd">Wicke</tc:token>
      <tc:token ID="w2de">,</tc:token>
      <tc:token ID="w2df">D.</tc:token>
      <tc:token ID="w2e0">(</tc:token>
      <tc:token ID="w2e1">2015</tc:token>
      <tc:token ID="w2e2">)</tc:token>
      <tc:token ID="w2e3">:</tc:token>
      <tc:token ID="w2e4">“</tc:token>
      <tc:token ID="w2e5">Learning</tc:token>
      <tc:token ID="w2e6">Cuneiform</tc:token>
      <tc:token ID="w2e7">the</tc:token>
      <tc:token ID="w2e8">Modern</tc:token>
      <tc:token ID="w2e9">Way</tc:token>
      <tc:token ID="w2ea">.</tc:token>
      <tc:token ID="w2eb">”</tc:token>
      <tc:token ID="w2ec">In</tc:token>
      <tc:token ID="w2ed">:</tc:token>
      <tc:token ID="w2ee">DhD2015</tc:token>
      <tc:token ID="w2ef">Sukhareva</tc:token>
      <tc:token ID="w2f0">,</tc:token>
      <tc:token ID="w2f1">M.</tc:token>
      <tc:token ID="w2f2">,</tc:token>
      <tc:token ID="w2f3">Fuscagni</tc:token>
      <tc:token ID="w2f4">,</tc:token>
      <tc:token ID="w2f5">F.</tc:token>
      <tc:token ID="w2f6">,</tc:token>
      <tc:token ID="w2f7">Daxenberger</tc:token>
      <tc:token ID="w2f8">,</tc:token>
      <tc:token ID="w2f9">J.</tc:token>
      <tc:token ID="w2fa">,</tc:token>
      <tc:token ID="w2fb">Görke</tc:token>
      <tc:token ID="w2fc">,</tc:token>
      <tc:token ID="w2fd">S.</tc:token>
      <tc:token ID="w2fe">,</tc:token>
      <tc:token ID="w2ff">Prechel</tc:token>
      <tc:token ID="w300">,</tc:token>
      <tc:token ID="w301">D.</tc:token>
      <tc:token ID="w302">,</tc:token>
      <tc:token ID="w303">Gurevych</tc:token>
      <tc:token ID="w304">,</tc:token>
      <tc:token ID="w305">I.</tc:token>
      <tc:token ID="w306">(</tc:token>
      <tc:token ID="w307">Aug</tc:token>
      <tc:token ID="w308">2017</tc:token>
      <tc:token ID="w309">)</tc:token>
      <tc:token ID="w30a">:</tc:token>
      <tc:token ID="w30b">“</tc:token>
      <tc:token ID="w30c">Distantly</tc:token>
      <tc:token ID="w30d">supervised</tc:token>
      <tc:token ID="w30e">pos</tc:token>
      <tc:token ID="w30f">tagging</tc:token>
      <tc:token ID="w310">of</tc:token>
      <tc:token ID="w311">low-resource</tc:token>
      <tc:token ID="w312">languages</tc:token>
      <tc:token ID="w313">under</tc:token>
      <tc:token ID="w314">extreme</tc:token>
      <tc:token ID="w315">data</tc:token>
      <tc:token ID="w316">sparsity</tc:token>
      <tc:token ID="w317">:</tc:token>
      <tc:token ID="w318">The</tc:token>
      <tc:token ID="w319">case</tc:token>
      <tc:token ID="w31a">of</tc:token>
      <tc:token ID="w31b">Hittite</tc:token>
      <tc:token ID="w31c">.</tc:token>
      <tc:token ID="w31d">”</tc:token>
      <tc:token ID="w31e">In</tc:token>
      <tc:token ID="w31f">:</tc:token>
      <tc:token ID="w320">LaTeCH-CLfL</tc:token>
      <tc:token ID="w321">’17</tc:token>
      <tc:token ID="w322">Proceedings</tc:token>
      <tc:token ID="w323">of</tc:token>
      <tc:token ID="w324">the</tc:token>
      <tc:token ID="w325">11th</tc:token>
      <tc:token ID="w326">Workshop</tc:token>
      <tc:token ID="w327">on</tc:token>
      <tc:token ID="w328">Language</tc:token>
      <tc:token ID="w329">Technology</tc:token>
      <tc:token ID="w32a">for</tc:token>
      <tc:token ID="w32b">Cultural</tc:token>
      <tc:token ID="w32c">Heritage</tc:token>
      <tc:token ID="w32d">,</tc:token>
      <tc:token ID="w32e">Social</tc:token>
      <tc:token ID="w32f">Sciences</tc:token>
      <tc:token ID="w330">,</tc:token>
      <tc:token ID="w331">and</tc:token>
      <tc:token ID="w332">Humanities.</tc:token>
      <tc:token ID="w333">pp.95–104</tc:token>
      <tc:token ID="w334">1.1</tc:token>
      <tc:token ID="w335">Bibliographie</tc:token>
    </tc:tokens>
    <tc:sentences xmlns:tc="http://www.dspin.de/data/textcorpus">
      <tc:sentence tokenIDs="w1 w2 w3 w4 w5 w6 w7 w8 w9 wa wb wc wd we wf w10 w11 w12 w13 w14 w15 w16 w17 w18 w19 w1a w1b w1c w1d w1e w1f w20 w21 w22 w23 w24" ID="s1"/>
      <tc:sentence tokenIDs="w25 w26 w27 w28 w29 w2a w2b w2c w2d w2e w2f w30 w31 w32 w33 w34 w35 w36 w37" ID="s2"/>
      <tc:sentence tokenIDs="w38 w39 w3a w3b w3c w3d w3e w3f w40 w41 w42 w43 w44 w45 w46 w47 w48 w49 w4a w4b" ID="s3"/>
      <tc:sentence tokenIDs="w4c w4d w4e w4f w50 w51 w52 w53 w54 w55 w56 w57 w58 w59 w5a w5b w5c w5d w5e w5f w60 w61 w62 w63 w64 w65 w66 w67 w68 w69" ID="s4"/>
      <tc:sentence tokenIDs="w6a w6b w6c w6d w6e w6f w70 w71 w72 w73 w74 w75 w76 w77 w78 w79 w7a w7b w7c w7d w7e w7f" ID="s5"/>
      <tc:sentence tokenIDs="w80 w81 w82 w83 w84 w85 w86 w87 w88 w89 w8a w8b w8c w8d w8e w8f w90 w91" ID="s6"/>
      <tc:sentence tokenIDs="w92 w93 w94 w95 w96 w97 w98 w99 w9a w9b w9c w9d w9e w9f wa0 wa1 wa2 wa3" ID="s7"/>
      <tc:sentence tokenIDs="wa4 wa5 wa6 wa7 wa8 wa9 waa wab wac wad wae waf wb0 wb1 wb2 wb3 wb4 wb5 wb6 wb7 wb8 wb9 wba wbb wbc wbd wbe wbf wc0 wc1 wc2" ID="s8"/>
      <tc:sentence tokenIDs="wc3 wc4 wc5 wc6 wc7 wc8 wc9 wca wcb wcc wcd wce wcf wd0 wd1" ID="s9"/>
      <tc:sentence tokenIDs="wd2 wd3 wd4 wd5 wd6 wd7 wd8 wd9 wda wdb wdc wdd wde wdf we0 we1 we2 we3 we4 we5 we6 we7 we8 we9 wea web wec wed wee wef wf0 wf1 wf2 wf3 wf4 wf5 wf6 wf7 wf8 wf9 wfa wfb" ID="sa"/>
      <tc:sentence tokenIDs="wfc wfd wfe wff w100 w101 w102 w103 w104 w105 w106 w107 w108 w109 w10a w10b w10c" ID="sb"/>
      <tc:sentence tokenIDs="w10d w10e w10f w110 w111 w112 w113 w114 w115 w116 w117 w118 w119 w11a w11b w11c w11d w11e w11f w120 w121 w122 w123 w124 w125 w126 w127 w128 w129 w12a w12b w12c w12d w12e w12f w130 w131 w132 w133 w134 w135 w136 w137 w138 w139 w13a w13b w13c w13d w13e w13f w140 w141 w142 w143 w144 w145 w146 w147 w148 w149 w14a w14b w14c w14d w14e w14f w150 w151 w152 w153 w154 w155 w156 w157 w158 w159 w15a w15b w15c w15d w15e w15f w160 w161 w162 w163 w164 w165 w166 w167" ID="sc"/>
      <tc:sentence tokenIDs="w168 w169 w16a w16b w16c w16d w16e w16f w170 w171 w172 w173 w174 w175 w176 w177 w178 w179 w17a w17b" ID="sd"/>
      <tc:sentence tokenIDs="w17c w17d w17e w17f w180 w181 w182 w183 w184 w185 w186 w187 w188 w189 w18a w18b w18c w18d w18e w18f w190 w191 w192 w193 w194 w195 w196 w197 w198 w199 w19a w19b w19c w19d w19e w19f w1a0 w1a1 w1a2 w1a3 w1a4 w1a5 w1a6" ID="se"/>
      <tc:sentence tokenIDs="w1a7 w1a8 w1a9 w1aa w1ab w1ac w1ad w1ae w1af w1b0 w1b1 w1b2 w1b3 w1b4 w1b5 w1b6 w1b7 w1b8 w1b9 w1ba w1bb w1bc w1bd w1be w1bf w1c0 w1c1 w1c2 w1c3 w1c4 w1c5 w1c6 w1c7 w1c8 w1c9 w1ca" ID="sf"/>
      <tc:sentence tokenIDs="w1cb w1cc w1cd w1ce w1cf w1d0 w1d1 w1d2 w1d3 w1d4 w1d5 w1d6 w1d7 w1d8 w1d9 w1da w1db w1dc w1dd w1de w1df w1e0 w1e1 w1e2 w1e3 w1e4 w1e5 w1e6 w1e7 w1e8 w1e9 w1ea w1eb w1ec w1ed w1ee w1ef w1f0 w1f1 w1f2 w1f3 w1f4 w1f5 w1f6 w1f7 w1f8 w1f9" ID="s10"/>
      <tc:sentence tokenIDs="w1fa w1fb w1fc w1fd w1fe w1ff w200 w201 w202 w203 w204 w205 w206 w207 w208 w209 w20a w20b w20c w20d w20e w20f w210 w211 w212 w213 w214 w215 w216 w217 w218 w219 w21a w21b w21c w21d w21e w21f" ID="s11"/>
      <tc:sentence tokenIDs="w220 w221 w222 w223 w224 w225 w226 w227 w228 w229 w22a w22b w22c w22d w22e w22f w230 w231 w232 w233 w234 w235 w236 w237 w238 w239 w23a w23b w23c w23d w23e w23f w240 w241 w242 w243 w244 w245 w246 w247 w248 w249 w24a w24b w24c w24d" ID="s12"/>
      <tc:sentence tokenIDs="w24e w24f w250 w251 w252 w253 w254 w255 w256 w257 w258 w259 w25a w25b w25c w25d w25e w25f w260 w261 w262 w263 w264 w265 w266 w267 w268 w269 w26a w26b w26c w26d w26e w26f w270 w271 w272 w273 w274" ID="s13"/>
      <tc:sentence tokenIDs="w275 w276 w277 w278 w279 w27a w27b w27c w27d w27e w27f w280 w281 w282 w283 w284 w285 w286 w287" ID="s14"/>
      <tc:sentence tokenIDs="w288 w289 w28a w28b w28c w28d w28e w28f w290 w291 w292 w293 w294" ID="s15"/>
      <tc:sentence tokenIDs="w295 w296 w297 w298 w299 w29a w29b w29c w29d w29e w29f w2a0 w2a1 w2a2 w2a3 w2a4 w2a5 w2a6 w2a7 w2a8 w2a9 w2aa w2ab w2ac w2ad w2ae w2af w2b0 w2b1 w2b2 w2b3" ID="s16"/>
      <tc:sentence tokenIDs="w2b4 w2b5 w2b6 w2b7 w2b8 w2b9 w2ba w2bb w2bc w2bd w2be w2bf w2c0 w2c1 w2c2 w2c3 w2c4" ID="s17"/>
      <tc:sentence tokenIDs="w2c5 w2c6 w2c7 w2c8 w2c9 w2ca w2cb w2cc" ID="s18"/>
      <tc:sentence tokenIDs="w2cd w2ce w2cf w2d0 w2d1 w2d2 w2d3 w2d4 w2d5 w2d6 w2d7 w2d8 w2d9 w2da w2db w2dc w2dd w2de w2df w2e0 w2e1 w2e2 w2e3" ID="s19"/>
      <tc:sentence tokenIDs="w2e4 w2e5 w2e6 w2e7 w2e8 w2e9 w2ea w2eb" ID="s1a"/>
      <tc:sentence tokenIDs="w2ec w2ed w2ee w2ef w2f0 w2f1 w2f2 w2f3 w2f4 w2f5 w2f6 w2f7 w2f8 w2f9 w2fa w2fb w2fc w2fd w2fe w2ff w300 w301 w302 w303 w304 w305 w306 w307 w308 w309 w30a" ID="s1b"/>
      <tc:sentence tokenIDs="w30b w30c w30d w30e w30f w310 w311 w312 w313 w314 w315 w316 w317" ID="s1c"/>
      <tc:sentence tokenIDs="w318 w319 w31a w31b w31c w31d" ID="s1d"/>
      <tc:sentence tokenIDs="w31e w31f w320 w321 w322 w323 w324 w325 w326 w327 w328 w329 w32a w32b w32c w32d w32e w32f w330 w331 w332 w333 w334 w335" ID="s1e"/>
    </tc:sentences>
    <tc:namedEntities xmlns:tc="http://www.dspin.de/data/textcorpus" type="tuebadz8">
      <tc:entity class="PER" tokenIDs="w93"/>
      <tc:entity class="GPE" tokenIDs="w96"/>
      <tc:entity class="GPE" tokenIDs="w9b"/>
      <tc:entity class="PER" tokenIDs="w9e"/>
      <tc:entity class="OTH" tokenIDs="wad wae waf wb0"/>
      <tc:entity class="GPE" tokenIDs="wd3"/>
      <tc:entity class="OTH" tokenIDs="w11d w11e w11f w120 w121"/>
      <tc:entity class="ORG" tokenIDs="w18c"/>
      <tc:entity class="ORG" tokenIDs="w1d0"/>
      <tc:entity class="PER" tokenIDs="w281"/>
      <tc:entity class="PER" tokenIDs="w283"/>
      <tc:entity class="OTH" tokenIDs="w297 w298 w299 w29a w29b"/>
      <tc:entity class="ORG" tokenIDs="w29d"/>
      <tc:entity class="GPE" tokenIDs="w2a2"/>
      <tc:entity class="GPE" tokenIDs="w2ba"/>
      <tc:entity class="PER" tokenIDs="w2bc"/>
      <tc:entity class="PER" tokenIDs="w2be"/>
      <tc:entity class="PER" tokenIDs="w2c0"/>
      <tc:entity class="GPE" tokenIDs="w2d2"/>
      <tc:entity class="PER" tokenIDs="w2d4"/>
      <tc:entity class="PER" tokenIDs="w2d6"/>
      <tc:entity class="PER" tokenIDs="w2d8"/>
      <tc:entity class="PER" tokenIDs="w2db"/>
      <tc:entity class="PER" tokenIDs="w2dd"/>
      <tc:entity class="PER" tokenIDs="w2df"/>
      <tc:entity class="OTH" tokenIDs="w2e5 w2e6 w2e7 w2e8 w2e9"/>
      <tc:entity class="PER" tokenIDs="w2ee w2ef"/>
      <tc:entity class="PER" tokenIDs="w2f1"/>
      <tc:entity class="PER" tokenIDs="w2f3"/>
      <tc:entity class="PER" tokenIDs="w2f5"/>
      <tc:entity class="PER" tokenIDs="w2f7"/>
      <tc:entity class="PER" tokenIDs="w2f9"/>
      <tc:entity class="PER" tokenIDs="w2fb"/>
      <tc:entity class="PER" tokenIDs="w2fd"/>
      <tc:entity class="PER" tokenIDs="w2ff"/>
      <tc:entity class="PER" tokenIDs="w301"/>
      <tc:entity class="PER" tokenIDs="w303"/>
      <tc:entity class="PER" tokenIDs="w305"/>
      <tc:entity class="OTH" tokenIDs="w318 w319 w31a w31b"/>
      <tc:entity class="ORG" tokenIDs="w320 w321 w322 w323 w324 w325 w326 w327 w328 w329 w32a w32b w32c"/>
      <tc:entity class="OTH" tokenIDs="w32e"/>
    </tc:namedEntities>
  </TextCorpus>
</D-Spin>