<?xml version='1.0' encoding='UTF-8'?><D-Spin xmlns="http://www.dspin.de/data" version="5">
  <MetaData xmlns="http://www.dspin.de/data/metadata"><Services><cmd:CMD xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:cmd="http://www.clarin.eu/cmd/1" CMDVersion="1.2" xsi:schemaLocation="http://www.clarin.eu/cmd/1 http://catalog.clarin.eu/ds/ComponentRegistry/rest/registry/profiles/clarin.eu:cr1:p_1320657629623/xsd"><cmd:Resources><cmd:ResourceProxyList/><cmd:JournalFileProxyList/><cmd:ResourceRelationList/></cmd:Resources><cmd:Components><cmd:WebServiceToolChain><cmd:GeneralInfo><cmd:Descriptions><cmd:Description/></cmd:Descriptions><cmd:ResourceName>Custom chain</cmd:ResourceName><cmd:ResourceClass>Toolchain</cmd:ResourceClass></cmd:GeneralInfo><cmd:Toolchain><cmd:ToolInChain><cmd:PID>https://hdl.handle.net/21.11120/0000-0008-319A-3</cmd:PID><cmd:Parameter value="de" name="lang"/></cmd:ToolInChain><cmd:ToolInChain><cmd:PID>https://hdl.handle.net/21.11120/0000-0008-3183-C</cmd:PID><cmd:Parameter value="5" name="version"/></cmd:ToolInChain><cmd:ToolInChain><cmd:PID>http://hdl.handle.net/11022/0000-0007-DA29-6</cmd:PID><cmd:Parameter value="de" name="lang"/><cmd:Parameter value="5" name="version"/></cmd:ToolInChain></cmd:Toolchain></cmd:WebServiceToolChain></cmd:Components></cmd:CMD></Services></MetaData>
  <TextCorpus xmlns="http://www.dspin.de/data/textcorpus" lang="de">
    <textSource type="application/tei+xml;format-variant=tei-dta;tokenized=0">&lt;?xml version="1.0" encoding="UTF-8"?>
&lt;TEI xmlns="http://www.tei-c.org/ns/1.0"
     xml:id="LIU_Keynote">
&lt;teiHeader>
&lt;fileDesc>
&lt;titleStmt>
&lt;title type="full">
&lt;title type="main">Humans in the Loop: &lt;/title>
&lt;title type="sub">Humanities Hermeneutics and Machine
		Learning&lt;/title>
&lt;/title>
&lt;author>
&lt;persName>
&lt;surname>Liu&lt;/surname>
&lt;forename>Alan&lt;/forename>
&lt;/persName>
&lt;affiliation>English Department at the University
		    of California, USA&lt;/affiliation>
&lt;/author>
&lt;/titleStmt>
&lt;sourceDesc>
&lt;p>via E-Mail from the author&lt;/p>
&lt;/sourceDesc>
&lt;/fileDesc>
&lt;profileDesc>
&lt;textClass>
&lt;keywords scheme="ConfTool" n="category">
&lt;term>Paper&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="subcategory">
&lt;term>Keynote&lt;/term>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="keywords">
&lt;term/>
&lt;/keywords>
&lt;keywords scheme="ConfTool" n="topics">
&lt;term/>
&lt;/keywords>
&lt;/textClass>
&lt;/profileDesc>
&lt;/teiHeader>
&lt;text>
&lt;body>
&lt;div type="div2" rend="DH-Heading2">
&lt;head> Abstract &lt;/head>
&lt;p>
              	As indicated by the emergent research fields of computational “interpretability” and “explainability,” machine learning creates fundamental hermeneutical problems. One of the least understood aspects of machine learning is how humans learn from 	machine learning. How does an individual, team, organization, or society “read” computational “distant reading” when it is performed by complex algorithms on immense datasets? Can methods of interpretation familiar to the humanities (e.g., traditional 	or poststructuralist ways of relating the general and the specific, the abstract and the concrete, the structure and the event, or the same and the different) be applied to machine learning? Further, can such traditions be applied with the explicitness, 		standardization, and reproducibility needed to engage meaningfully with the different Spielraum – scope for “play” (as in the “play of a rope,” “wiggle room”, or machine-part “tolerance”) – of computation? If so, how might that change the hermeneutics of 	the humanities themselves?
        	&lt;/p>
&lt;p>
	      In his keynote lecture, Alan Liu uses the example of the formalized “interpretation protocol” for topic models he is developing for the Mellon Foundation funded WhatEvery1Says project (which is text-analyzing millions of newspaper articles mentioning the humanities) to reflect on how humanistic traditions of interpretation can contribute to machine learning. But he also suggests how machine learning changes humanistic interpretation through fresh ideas about wholes and parts, mimetic representation and probabilistic modeling, and similarity and difference (or identity and culture).
            &lt;/p>
&lt;/div>
&lt;/body>
&lt;/text>
&lt;/TEI>
    </textSource>
    <text>


               	As indicated by the emergent research fields of computational “interpretability” and “explainability,” machine learning creates fundamental hermeneutical problems. One of the least understood aspects of machine learning is how humans learn from 	machine learning. How does an individual, team, organization, or society “read” computational “distant reading” when it is performed by complex algorithms on immense datasets? Can methods of interpretation familiar to the humanities (e.g., traditional 	or poststructuralist ways of relating the general and the specific, the abstract and the concrete, the structure and the event, or the same and the different) be applied to machine learning? Further, can such traditions be applied with the explicitness, 		standardization, and reproducibility needed to engage meaningfully with the different Spielraum – scope for “play” (as in the “play of a rope,” “wiggle room”, or machine-part “tolerance”) – of computation? If so, how might that change the hermeneutics of 	the humanities themselves?  

  

 	      In his keynote lecture, Alan Liu uses the example of the formalized “interpretation protocol” for topic models he is developing for the Mellon Foundation funded WhatEvery1Says project (which is text-analyzing millions of newspaper articles mentioning the humanities) to reflect on how humanistic traditions of interpretation can contribute to machine learning. But he also suggests how machine learning changes humanistic interpretation through fresh ideas about wholes and parts, mimetic representation and probabilistic modeling, and similarity and difference (or identity and culture).  

  

  



 Abstract 
    </text>
    <tc:tokens xmlns:tc="http://www.dspin.de/data/textcorpus">
      <tc:token ID="w1">As</tc:token>
      <tc:token ID="w2">indicated</tc:token>
      <tc:token ID="w3">by</tc:token>
      <tc:token ID="w4">the</tc:token>
      <tc:token ID="w5">emergent</tc:token>
      <tc:token ID="w6">research</tc:token>
      <tc:token ID="w7">fields</tc:token>
      <tc:token ID="w8">of</tc:token>
      <tc:token ID="w9">computational</tc:token>
      <tc:token ID="wa">“</tc:token>
      <tc:token ID="wb">interpretability</tc:token>
      <tc:token ID="wc">”</tc:token>
      <tc:token ID="wd">and</tc:token>
      <tc:token ID="we">“</tc:token>
      <tc:token ID="wf">explainability</tc:token>
      <tc:token ID="w10">,</tc:token>
      <tc:token ID="w11">”</tc:token>
      <tc:token ID="w12">machine</tc:token>
      <tc:token ID="w13">learning</tc:token>
      <tc:token ID="w14">creates</tc:token>
      <tc:token ID="w15">fundamental</tc:token>
      <tc:token ID="w16">hermeneutical</tc:token>
      <tc:token ID="w17">problems</tc:token>
      <tc:token ID="w18">.</tc:token>
      <tc:token ID="w19">One</tc:token>
      <tc:token ID="w1a">of</tc:token>
      <tc:token ID="w1b">the</tc:token>
      <tc:token ID="w1c">least</tc:token>
      <tc:token ID="w1d">understood</tc:token>
      <tc:token ID="w1e">aspects</tc:token>
      <tc:token ID="w1f">of</tc:token>
      <tc:token ID="w20">machine</tc:token>
      <tc:token ID="w21">learning</tc:token>
      <tc:token ID="w22">is</tc:token>
      <tc:token ID="w23">how</tc:token>
      <tc:token ID="w24">humans</tc:token>
      <tc:token ID="w25">learn</tc:token>
      <tc:token ID="w26">from</tc:token>
      <tc:token ID="w27">machine</tc:token>
      <tc:token ID="w28">learning</tc:token>
      <tc:token ID="w29">.</tc:token>
      <tc:token ID="w2a">How</tc:token>
      <tc:token ID="w2b">does</tc:token>
      <tc:token ID="w2c">an</tc:token>
      <tc:token ID="w2d">individual</tc:token>
      <tc:token ID="w2e">,</tc:token>
      <tc:token ID="w2f">team</tc:token>
      <tc:token ID="w30">,</tc:token>
      <tc:token ID="w31">organization</tc:token>
      <tc:token ID="w32">,</tc:token>
      <tc:token ID="w33">or</tc:token>
      <tc:token ID="w34">society</tc:token>
      <tc:token ID="w35">“</tc:token>
      <tc:token ID="w36">read</tc:token>
      <tc:token ID="w37">”</tc:token>
      <tc:token ID="w38">computational</tc:token>
      <tc:token ID="w39">“</tc:token>
      <tc:token ID="w3a">distant</tc:token>
      <tc:token ID="w3b">reading</tc:token>
      <tc:token ID="w3c">”</tc:token>
      <tc:token ID="w3d">when</tc:token>
      <tc:token ID="w3e">it</tc:token>
      <tc:token ID="w3f">is</tc:token>
      <tc:token ID="w40">performed</tc:token>
      <tc:token ID="w41">by</tc:token>
      <tc:token ID="w42">complex</tc:token>
      <tc:token ID="w43">algorithms</tc:token>
      <tc:token ID="w44">on</tc:token>
      <tc:token ID="w45">immense</tc:token>
      <tc:token ID="w46">datasets</tc:token>
      <tc:token ID="w47">?</tc:token>
      <tc:token ID="w48">Can</tc:token>
      <tc:token ID="w49">methods</tc:token>
      <tc:token ID="w4a">of</tc:token>
      <tc:token ID="w4b">interpretation</tc:token>
      <tc:token ID="w4c">familiar</tc:token>
      <tc:token ID="w4d">to</tc:token>
      <tc:token ID="w4e">the</tc:token>
      <tc:token ID="w4f">humanities</tc:token>
      <tc:token ID="w50">(</tc:token>
      <tc:token ID="w51">e.g.</tc:token>
      <tc:token ID="w52">,</tc:token>
      <tc:token ID="w53">traditional</tc:token>
      <tc:token ID="w54">or</tc:token>
      <tc:token ID="w55">poststructuralist</tc:token>
      <tc:token ID="w56">ways</tc:token>
      <tc:token ID="w57">of</tc:token>
      <tc:token ID="w58">relating</tc:token>
      <tc:token ID="w59">the</tc:token>
      <tc:token ID="w5a">general</tc:token>
      <tc:token ID="w5b">and</tc:token>
      <tc:token ID="w5c">the</tc:token>
      <tc:token ID="w5d">specific</tc:token>
      <tc:token ID="w5e">,</tc:token>
      <tc:token ID="w5f">the</tc:token>
      <tc:token ID="w60">abstract</tc:token>
      <tc:token ID="w61">and</tc:token>
      <tc:token ID="w62">the</tc:token>
      <tc:token ID="w63">concrete</tc:token>
      <tc:token ID="w64">,</tc:token>
      <tc:token ID="w65">the</tc:token>
      <tc:token ID="w66">structure</tc:token>
      <tc:token ID="w67">and</tc:token>
      <tc:token ID="w68">the</tc:token>
      <tc:token ID="w69">event</tc:token>
      <tc:token ID="w6a">,</tc:token>
      <tc:token ID="w6b">or</tc:token>
      <tc:token ID="w6c">the</tc:token>
      <tc:token ID="w6d">same</tc:token>
      <tc:token ID="w6e">and</tc:token>
      <tc:token ID="w6f">the</tc:token>
      <tc:token ID="w70">different</tc:token>
      <tc:token ID="w71">)</tc:token>
      <tc:token ID="w72">be</tc:token>
      <tc:token ID="w73">applied</tc:token>
      <tc:token ID="w74">to</tc:token>
      <tc:token ID="w75">machine</tc:token>
      <tc:token ID="w76">learning</tc:token>
      <tc:token ID="w77">?</tc:token>
      <tc:token ID="w78">Further</tc:token>
      <tc:token ID="w79">,</tc:token>
      <tc:token ID="w7a">can</tc:token>
      <tc:token ID="w7b">such</tc:token>
      <tc:token ID="w7c">traditions</tc:token>
      <tc:token ID="w7d">be</tc:token>
      <tc:token ID="w7e">applied</tc:token>
      <tc:token ID="w7f">with</tc:token>
      <tc:token ID="w80">the</tc:token>
      <tc:token ID="w81">explicitness</tc:token>
      <tc:token ID="w82">,</tc:token>
      <tc:token ID="w83">standardization</tc:token>
      <tc:token ID="w84">,</tc:token>
      <tc:token ID="w85">and</tc:token>
      <tc:token ID="w86">reproducibility</tc:token>
      <tc:token ID="w87">needed</tc:token>
      <tc:token ID="w88">to</tc:token>
      <tc:token ID="w89">engage</tc:token>
      <tc:token ID="w8a">meaningfully</tc:token>
      <tc:token ID="w8b">with</tc:token>
      <tc:token ID="w8c">the</tc:token>
      <tc:token ID="w8d">different</tc:token>
      <tc:token ID="w8e">Spielraum</tc:token>
      <tc:token ID="w8f">–</tc:token>
      <tc:token ID="w90">scope</tc:token>
      <tc:token ID="w91">for</tc:token>
      <tc:token ID="w92">“</tc:token>
      <tc:token ID="w93">play</tc:token>
      <tc:token ID="w94">”</tc:token>
      <tc:token ID="w95">(</tc:token>
      <tc:token ID="w96">as</tc:token>
      <tc:token ID="w97">in</tc:token>
      <tc:token ID="w98">the</tc:token>
      <tc:token ID="w99">“</tc:token>
      <tc:token ID="w9a">play</tc:token>
      <tc:token ID="w9b">of</tc:token>
      <tc:token ID="w9c">a</tc:token>
      <tc:token ID="w9d">rope</tc:token>
      <tc:token ID="w9e">,</tc:token>
      <tc:token ID="w9f">”</tc:token>
      <tc:token ID="wa0">“</tc:token>
      <tc:token ID="wa1">wiggle</tc:token>
      <tc:token ID="wa2">room</tc:token>
      <tc:token ID="wa3">”</tc:token>
      <tc:token ID="wa4">,</tc:token>
      <tc:token ID="wa5">or</tc:token>
      <tc:token ID="wa6">machine-part</tc:token>
      <tc:token ID="wa7">“</tc:token>
      <tc:token ID="wa8">tolerance</tc:token>
      <tc:token ID="wa9">”</tc:token>
      <tc:token ID="waa">)</tc:token>
      <tc:token ID="wab">–</tc:token>
      <tc:token ID="wac">of</tc:token>
      <tc:token ID="wad">computation</tc:token>
      <tc:token ID="wae">?</tc:token>
      <tc:token ID="waf">If</tc:token>
      <tc:token ID="wb0">so</tc:token>
      <tc:token ID="wb1">,</tc:token>
      <tc:token ID="wb2">how</tc:token>
      <tc:token ID="wb3">might</tc:token>
      <tc:token ID="wb4">that</tc:token>
      <tc:token ID="wb5">change</tc:token>
      <tc:token ID="wb6">the</tc:token>
      <tc:token ID="wb7">hermeneutics</tc:token>
      <tc:token ID="wb8">of</tc:token>
      <tc:token ID="wb9">the</tc:token>
      <tc:token ID="wba">humanities</tc:token>
      <tc:token ID="wbb">themselves</tc:token>
      <tc:token ID="wbc">?</tc:token>
      <tc:token ID="wbd">In</tc:token>
      <tc:token ID="wbe">his</tc:token>
      <tc:token ID="wbf">keynote</tc:token>
      <tc:token ID="wc0">lecture</tc:token>
      <tc:token ID="wc1">,</tc:token>
      <tc:token ID="wc2">Alan</tc:token>
      <tc:token ID="wc3">Liu</tc:token>
      <tc:token ID="wc4">uses</tc:token>
      <tc:token ID="wc5">the</tc:token>
      <tc:token ID="wc6">example</tc:token>
      <tc:token ID="wc7">of</tc:token>
      <tc:token ID="wc8">the</tc:token>
      <tc:token ID="wc9">formalized</tc:token>
      <tc:token ID="wca">“</tc:token>
      <tc:token ID="wcb">interpretation</tc:token>
      <tc:token ID="wcc">protocol</tc:token>
      <tc:token ID="wcd">”</tc:token>
      <tc:token ID="wce">for</tc:token>
      <tc:token ID="wcf">topic</tc:token>
      <tc:token ID="wd0">models</tc:token>
      <tc:token ID="wd1">he</tc:token>
      <tc:token ID="wd2">is</tc:token>
      <tc:token ID="wd3">developing</tc:token>
      <tc:token ID="wd4">for</tc:token>
      <tc:token ID="wd5">the</tc:token>
      <tc:token ID="wd6">Mellon</tc:token>
      <tc:token ID="wd7">Foundation</tc:token>
      <tc:token ID="wd8">funded</tc:token>
      <tc:token ID="wd9">WhatEvery1Says</tc:token>
      <tc:token ID="wda">project</tc:token>
      <tc:token ID="wdb">(</tc:token>
      <tc:token ID="wdc">which</tc:token>
      <tc:token ID="wdd">is</tc:token>
      <tc:token ID="wde">text-analyzing</tc:token>
      <tc:token ID="wdf">millions</tc:token>
      <tc:token ID="we0">of</tc:token>
      <tc:token ID="we1">newspaper</tc:token>
      <tc:token ID="we2">articles</tc:token>
      <tc:token ID="we3">mentioning</tc:token>
      <tc:token ID="we4">the</tc:token>
      <tc:token ID="we5">humanities</tc:token>
      <tc:token ID="we6">)</tc:token>
      <tc:token ID="we7">to</tc:token>
      <tc:token ID="we8">reflect</tc:token>
      <tc:token ID="we9">on</tc:token>
      <tc:token ID="wea">how</tc:token>
      <tc:token ID="web">humanistic</tc:token>
      <tc:token ID="wec">traditions</tc:token>
      <tc:token ID="wed">of</tc:token>
      <tc:token ID="wee">interpretation</tc:token>
      <tc:token ID="wef">can</tc:token>
      <tc:token ID="wf0">contribute</tc:token>
      <tc:token ID="wf1">to</tc:token>
      <tc:token ID="wf2">machine</tc:token>
      <tc:token ID="wf3">learning</tc:token>
      <tc:token ID="wf4">.</tc:token>
      <tc:token ID="wf5">But</tc:token>
      <tc:token ID="wf6">he</tc:token>
      <tc:token ID="wf7">also</tc:token>
      <tc:token ID="wf8">suggests</tc:token>
      <tc:token ID="wf9">how</tc:token>
      <tc:token ID="wfa">machine</tc:token>
      <tc:token ID="wfb">learning</tc:token>
      <tc:token ID="wfc">changes</tc:token>
      <tc:token ID="wfd">humanistic</tc:token>
      <tc:token ID="wfe">interpretation</tc:token>
      <tc:token ID="wff">through</tc:token>
      <tc:token ID="w100">fresh</tc:token>
      <tc:token ID="w101">ideas</tc:token>
      <tc:token ID="w102">about</tc:token>
      <tc:token ID="w103">wholes</tc:token>
      <tc:token ID="w104">and</tc:token>
      <tc:token ID="w105">parts</tc:token>
      <tc:token ID="w106">,</tc:token>
      <tc:token ID="w107">mimetic</tc:token>
      <tc:token ID="w108">representation</tc:token>
      <tc:token ID="w109">and</tc:token>
      <tc:token ID="w10a">probabilistic</tc:token>
      <tc:token ID="w10b">modeling</tc:token>
      <tc:token ID="w10c">,</tc:token>
      <tc:token ID="w10d">and</tc:token>
      <tc:token ID="w10e">similarity</tc:token>
      <tc:token ID="w10f">and</tc:token>
      <tc:token ID="w110">difference</tc:token>
      <tc:token ID="w111">(</tc:token>
      <tc:token ID="w112">or</tc:token>
      <tc:token ID="w113">identity</tc:token>
      <tc:token ID="w114">and</tc:token>
      <tc:token ID="w115">culture</tc:token>
      <tc:token ID="w116">)</tc:token>
      <tc:token ID="w117">.</tc:token>
      <tc:token ID="w118">Abstract</tc:token>
    </tc:tokens>
    <tc:sentences xmlns:tc="http://www.dspin.de/data/textcorpus">
      <tc:sentence tokenIDs="w1 w2 w3 w4 w5 w6 w7 w8 w9 wa wb wc wd we wf w10 w11 w12 w13 w14 w15 w16 w17 w18" ID="s1"/>
      <tc:sentence tokenIDs="w19 w1a w1b w1c w1d w1e w1f w20 w21 w22 w23 w24 w25 w26 w27 w28 w29" ID="s2"/>
      <tc:sentence tokenIDs="w2a w2b w2c w2d w2e w2f w30 w31 w32 w33 w34 w35 w36 w37 w38 w39 w3a w3b w3c w3d w3e w3f w40 w41 w42 w43 w44 w45 w46 w47 w48 w49 w4a w4b w4c w4d w4e w4f w50 w51 w52 w53 w54 w55 w56 w57 w58 w59 w5a w5b w5c w5d w5e w5f w60 w61 w62 w63 w64 w65 w66 w67 w68 w69 w6a w6b w6c w6d w6e w6f w70 w71 w72 w73 w74 w75 w76 w77" ID="s3"/>
      <tc:sentence tokenIDs="w78 w79 w7a w7b w7c w7d w7e w7f w80 w81 w82 w83 w84 w85 w86 w87 w88 w89 w8a w8b w8c w8d w8e w8f w90 w91 w92 w93 w94 w95 w96 w97 w98 w99 w9a w9b w9c w9d w9e w9f wa0 wa1 wa2 wa3 wa4 wa5 wa6 wa7 wa8 wa9 waa wab wac wad wae" ID="s4"/>
      <tc:sentence tokenIDs="waf wb0 wb1 wb2 wb3 wb4 wb5 wb6 wb7 wb8 wb9 wba wbb wbc" ID="s5"/>
      <tc:sentence tokenIDs="wbd wbe wbf wc0 wc1 wc2 wc3 wc4 wc5 wc6 wc7 wc8 wc9 wca wcb wcc wcd wce wcf wd0 wd1 wd2 wd3 wd4 wd5 wd6 wd7 wd8 wd9 wda wdb wdc wdd wde wdf we0 we1 we2 we3 we4 we5 we6 we7 we8 we9 wea web wec wed wee wef wf0 wf1 wf2 wf3 wf4" ID="s6"/>
      <tc:sentence tokenIDs="wf5 wf6 wf7 wf8 wf9 wfa wfb wfc wfd wfe wff w100 w101 w102 w103 w104 w105 w106 w107 w108 w109 w10a w10b w10c w10d w10e w10f w110 w111 w112 w113 w114 w115 w116 w117" ID="s7"/>
      <tc:sentence tokenIDs="w118" ID="s8"/>
    </tc:sentences>
    <tc:namedEntities xmlns:tc="http://www.dspin.de/data/textcorpus" type="tuebadz8">
      <tc:entity class="PER" tokenIDs="wc2 wc3"/>
    </tc:namedEntities>
  </TextCorpus>
</D-Spin>